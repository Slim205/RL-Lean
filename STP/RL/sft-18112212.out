2025-06-06 03:35:43,646	INFO scripts.py:1186 -- Did not find any active Ray processes.
DEBUG:draccus.wrappers.field_metavar:Metavar for type None: None
DEBUG:draccus.help_formatter:action type: None, Result: , nargs: 0, default metavar: None
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.seed has a default value of 0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.mp has a default value of p=full,c=full,o=full
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.log_dir has a default value of logs
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.run_base_dir has a default value of runs
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.id has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.tracker has a default value of WandbConfig(entity=None, project=None, name=None, tags=[], id=None, group=None, mode=None, resume='allow', save_code=True, save_xla_dumps=False)
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler_start_step has a default value of 5
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler_num_steps has a default value of 100
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler_perfetto_link has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.batch_axis has a default value of batch
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fsdp_axis has a default value of embed
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.tensor_parallel_axes has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.axis_resources has a default value of {}
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.parameter_axis_resources has a default value of {}
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.replica_ici_axis_size has a default value of 1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.model_axis_size has a default value of 1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.replica_dcn_axis_size has a default value of 1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.train_batch_size has a default value of 512
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.per_device_parallelism has a default value of -1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.per_device_eval_parallelism has a default value of -1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.num_train_steps has a default value of 400000
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.steps_per_eval has a default value of 1000
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.max_eval_batches has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.checkpointer.base_path has a default value of checkpoints/
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.checkpointer.save_interval has a default value of 1:00:00
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.checkpointer.keep has a default value of [{'every': 10000}]
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.load_checkpoint has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.load_checkpoint_path has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.initialize_from has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.jax_config has a default value of {'jax_threefry_partitionable': True, 'jax_softmax_custom_jvp': True}
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.coordinator_address has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.num_processes has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.process_id has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.local_device_ids has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.ray.address has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.ray.start_workers has a default value of True
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.ray.auto_start_cluster has a default value of True
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.require_accelerator has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.shutdown_at_exit has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at max_tune_length has a default value of 2048
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at train_data has a default value of tatsu-lab/alpaca
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at train_data_cache_dir has a default value of cache/
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at eval_data has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at eval_data_cache_dir has a default value of cache/
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at model_name_or_path has a default value of meta-llama/Llama-2-7b-hf
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at tokenizer_name_or_path has a default value of meta-llama/Llama-2-7b-hf
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trust_remote_code has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at model_cache_dir has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at hf_save_path has a default value of alpaca_hf_ckpts
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at save_freq has a default value of None
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.learning_rate has a default value of 0.0006
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.min_lr_ratio has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup_ratio has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup has a default value of 0.01
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.stable has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.cooldown has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.lr_schedule has a default value of cosine
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay_modules has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.default_weight_decay_mask has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta1 has a default value of 0.9
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta2 has a default value of 0.999
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.epsilon has a default value of 1e-08
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.max_grad_norm has a default value of 1.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.learning_rate has a default value of 0.0006
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.min_lr_ratio has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup_ratio has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup has a default value of 0.01
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.stable has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.cooldown has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.lr_schedule has a default value of cosine
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay_modules has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.default_weight_decay_mask has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.update_interval has a default value of 10
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta1 has a default value of 0.96
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta2 has a default value of 0.99
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.epsilon has a default value of 1e-12
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.clip_threshold has a default value of 1.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.rng_seed has a default value of 0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.gamma has a default value of 0.01
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'learning_rate': {'required': False, 'dest': 'optimizer.learning_rate', 'default': 0.0006, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay': {'required': False, 'dest': 'optimizer.weight_decay', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'min_lr_ratio': {'required': False, 'dest': 'optimizer.min_lr_ratio', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup_ratio': {'required': False, 'dest': 'optimizer.warmup_ratio', 'default': None, 'help': 'Deprecated. fraction of training steps to use as warmup', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup': {'required': False, 'dest': 'optimizer.warmup', 'default': 0.01, 'help': 'fraction of training steps to use as warmup, or steps to use. 0.0 means no warmup', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'stable': {'required': False, 'dest': 'optimizer.stable', 'default': 0.0, 'help': 'fraction of training steps to use as stable, or steps to use. 0.0 means no stable', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'cooldown': {'required': False, 'dest': 'optimizer.cooldown', 'default': 0.0, 'help': 'fraction of training steps to use as cooldown, or steps to use. 0.0 means no cooldown', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'lr_schedule': {'required': False, 'dest': 'optimizer.lr_schedule', 'default': 'cosine', 'help': 'constant, cosine, linear', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay_modules': {'required': False, 'dest': 'optimizer.weight_decay_modules', 'default': None, 'help': 'A regex or a list of strings to identify where to mask weight.\nFor nano-GPT, this field can be set as `r".*attn.*weight|.*mlp.*weight|.*token_embeddings|.*position_embeddings"`', 'type': typing.Union[typing.List[str], str, NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'default_weight_decay_mask': {'required': False, 'dest': 'optimizer.default_weight_decay_mask', 'default': None, 'help': 'Whether to apply a default reasonable weight decay to modules not explicitly masked. None means it will if\nno weight_decay_modules are set. False means it will not. True means it will regardless of weight_decay_modules.', 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta1': {'required': False, 'dest': 'optimizer.beta1', 'default': 0.9, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta2': {'required': False, 'dest': 'optimizer.beta2', 'default': 0.999, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'epsilon': {'required': False, 'dest': 'optimizer.epsilon', 'default': 1e-08, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'max_grad_norm': {'required': False, 'dest': 'optimizer.max_grad_norm', 'default': 1.0, 'help': ' ', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'learning_rate': {'required': False, 'dest': 'optimizer.learning_rate', 'default': 0.0006, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay': {'required': False, 'dest': 'optimizer.weight_decay', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'min_lr_ratio': {'required': False, 'dest': 'optimizer.min_lr_ratio', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup_ratio': {'required': False, 'dest': 'optimizer.warmup_ratio', 'default': None, 'help': 'Deprecated. fraction of training steps to use as warmup', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup': {'required': False, 'dest': 'optimizer.warmup', 'default': 0.01, 'help': 'fraction of training steps to use as warmup, or steps to use. 0.0 means no warmup', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'stable': {'required': False, 'dest': 'optimizer.stable', 'default': 0.0, 'help': 'fraction of training steps to use as stable, or steps to use. 0.0 means no stable', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'cooldown': {'required': False, 'dest': 'optimizer.cooldown', 'default': 0.0, 'help': 'fraction of training steps to use as cooldown, or steps to use. 0.0 means no cooldown', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'lr_schedule': {'required': False, 'dest': 'optimizer.lr_schedule', 'default': 'cosine', 'help': 'constant, cosine, linear', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay_modules': {'required': False, 'dest': 'optimizer.weight_decay_modules', 'default': None, 'help': 'A regex or a list of strings to identify where to mask weight.\nFor nano-GPT, this field can be set as `r".*attn.*weight|.*mlp.*weight|.*token_embeddings|.*position_embeddings"`', 'type': typing.Union[typing.List[str], str, NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'default_weight_decay_mask': {'required': False, 'dest': 'optimizer.default_weight_decay_mask', 'default': None, 'help': 'Whether to apply a default reasonable weight decay to modules not explicitly masked. None means it will if\nno weight_decay_modules are set. False means it will not. True means it will regardless of weight_decay_modules.', 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'update_interval': {'required': False, 'dest': 'optimizer.update_interval', 'default': 10, 'help': 'How often to update the hessian approximation.', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta1': {'required': False, 'dest': 'optimizer.beta1', 'default': 0.96, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta2': {'required': False, 'dest': 'optimizer.beta2', 'default': 0.99, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'epsilon': {'required': False, 'dest': 'optimizer.epsilon', 'default': 1e-12, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'clip_threshold': {'required': False, 'dest': 'optimizer.clip_threshold', 'default': 1.0, 'help': ' ', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:     @abc.abstractmethod
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'rng_seed': {'required': False, 'dest': 'optimizer.rng_seed', 'default': 0, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:     def compute_hessian(self, fn, model, *batch, hess_key: PRNGKey, **batch_kwargs):
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'gamma': {'required': False, 'dest': 'optimizer.gamma', 'default': 0.01, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'seed': {'required': False, 'dest': 'trainer.seed', 'default': 0, 'help': 'random seed', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'mp': {'required': False, 'dest': 'trainer.mp', 'default': Policy(param_dtype=<class 'jax.numpy.float32'>, compute_dtype=<class 'jax.numpy.float32'>, output_dtype=<class 'jax.numpy.float32'>), 'help': 'mixed precision policy', 'type': <class 'jmp._src.policy.Policy'>}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fp8.amax_history_length has a default value of 1024
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fp8.compute_dtype has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fp8.targets has a default value of None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'amax_history_length': {'required': False, 'dest': 'trainer.fp8.amax_history_length', 'default': 1024, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'compute_dtype': {'required': False, 'dest': 'trainer.fp8.compute_dtype', 'default': None, 'type': typing.Union[str, type[typing.Any], numpy.dtype, jax._src.typing.SupportsDType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'targets': {'required': False, 'dest': 'trainer.fp8.targets', 'default': None, 'help': '\nIf provided, only modules with names in this list will be quantized. If a single string, will be treated as a regex\n', 'type': typing.Union[typing.List[str], str, NoneType]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.entity has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.project has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.name has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.tags has a default value of []
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.id has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.group has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.mode has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.resume has a default value of allow
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.save_code has a default value of True
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.save_xla_dumps has a default value of False
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'entity': {'required': False, 'dest': 'trainer.wandb.entity', 'default': None, 'help': 'An entity is a username or team name where you send runs', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'project': {'required': False, 'dest': 'trainer.wandb.project', 'default': None, 'help': 'The name of the project where you are sending the enw run.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'name': {'required': False, 'dest': 'trainer.wandb.name', 'default': None, 'help': "A short display name for this run, which is how you'll identify this run in the UI.", 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tags': {'required': False, 'dest': 'trainer.wandb.tags', 'default': [], 'help': 'Will populate the list of tags on this run in the UI.', 'type': typing.List[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'id': {'required': False, 'dest': 'trainer.wandb.id', 'default': None, 'help': 'A unique ID for this run, used for resuming. It must be unique in the project', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'group': {'required': False, 'dest': 'trainer.wandb.group', 'default': None, 'help': 'Specify a group to organize individual runs into a larger experiment.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'mode': {'required': False, 'dest': 'trainer.wandb.mode', 'default': None, 'help': 'Can be "online", "offline" or "disabled". If None, it will be whatever W&B decides.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'resume': {'required': False, 'dest': 'trainer.wandb.resume', 'default': 'allow', 'help': '\nSet the resume behavior. Options: "allow", "must", "never", "auto" or None.\nBy default, if the new run has the same ID as a previous run, this run overwrites that data.\nPlease refer to [init](https://docs.wandb.ai/ref/python/init) and [resume](https://docs.wandb.ai/guides/runs/resuming)\ndocument for more details.\n', 'type': typing.Union[bool, str, NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_code': {'required': False, 'dest': 'trainer.wandb.save_code', 'default': True, 'help': "If string, will save code from that directory. If True, will attempt to sniff out the main directory (since we\ntypically don't run from the root of the repo).", 'type': typing.Union[bool, str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_xla_dumps': {'required': False, 'dest': 'trainer.wandb.save_xla_dumps', 'default': False, 'help': 'If True, will save the XLA code to wandb (as configured by XLA_FLAGS). This is useful for debugging.', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'log_dir': {'required': False, 'dest': 'trainer.log_dir', 'default': PosixPath('logs'), 'help': ' ', 'type': <class 'pathlib.Path'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'run_base_dir': {'required': False, 'dest': 'trainer.run_base_dir', 'default': PosixPath('runs'), 'help': ' ', 'type': <class 'pathlib.Path'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'id': {'required': False, 'dest': 'trainer.id', 'default': None, 'help': 'run id. if None, will be set to a random string', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tracker': {'required': False, 'dest': 'trainer.tracker', 'default': WandbConfig(entity=None, project=None, name=None, tags=[], id=None, group=None, mode=None, resume='allow', save_code=True, save_xla_dumps=False), 'help': ' ', 'type': typing.Union[levanter.tracker.tracker.TrackerConfig, typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler': {'required': False, 'dest': 'trainer.profiler', 'default': False, 'help': 'TODO: refactor callbacks', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler_start_step': {'required': False, 'dest': 'trainer.profiler_start_step', 'default': 5, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler_num_steps': {'required': False, 'dest': 'trainer.profiler_num_steps', 'default': 100, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler_perfetto_link': {'required': False, 'dest': 'trainer.profiler_perfetto_link', 'default': False, 'help': ' ', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'batch_axis': {'required': False, 'dest': 'trainer.batch_axis', 'default': 'batch', 'help': 'Batch axis for data parallel.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'fsdp_axis': {'required': False, 'dest': 'trainer.fsdp_axis', 'default': 'embed', 'help': 'Axis/Axes to use for FSDP', 'type': typing.Union[str, typing.List[str], NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tensor_parallel_axes': {'required': False, 'dest': 'trainer.tensor_parallel_axes', 'default': None, 'help': 'Axes, if any, to use for tensor parallelism', 'type': typing.Optional[typing.List[str]]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'axis_resources': {'required': False, 'dest': 'trainer.axis_resources', 'default': {}, 'help': 'mapping from logical axis to physical axis. batch_axis, fsdp_axis, and tensor_parallel_axes are preferred', 'type': collections.abc.Mapping[str, typing.Union[typing.Tuple[str], str]]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:         default_factory=dict
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'parameter_axis_resources': {'required': False, 'dest': 'trainer.parameter_axis_resources', 'default': {}, 'help': ' ', 'type': collections.abc.Mapping[str, typing.Union[typing.Tuple[str], str]]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'replica_ici_axis_size': {'required': False, 'dest': 'trainer.replica_ici_axis_size', 'default': 1, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'model_axis_size': {'required': False, 'dest': 'trainer.model_axis_size', 'default': 1, 'help': 'how many devices within each slice for sharding with DP. Fix TP=1, the rest of the devices is for FSDP.', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'replica_dcn_axis_size': {'required': False, 'dest': 'trainer.replica_dcn_axis_size', 'default': 1, 'help': 'how many slices in the multislice scheme for sharding with DP and TP. The rest of the devices is for FSDP.', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'train_batch_size': {'required': False, 'dest': 'trainer.train_batch_size', 'default': 512, 'help': 'Config related to batch sizes', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'per_device_parallelism': {'required': False, 'dest': 'trainer.per_device_parallelism', 'default': -1, 'help': 'how many examples to process in parallel on each device. -1 (default) means train_batch_size/num_devices', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'per_device_eval_parallelism': {'required': False, 'dest': 'trainer.per_device_eval_parallelism', 'default': -1, 'help': 'how many examples to process in parallel on each device. -1 (default) means same as per_device_parallelism', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'num_train_steps': {'required': False, 'dest': 'trainer.num_train_steps', 'default': 400000, 'help': 'number of training steps', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'steps_per_eval': {'required': False, 'dest': 'trainer.steps_per_eval', 'default': 1000, 'help': 'how often to evaluate', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'max_eval_batches': {'required': False, 'dest': 'trainer.max_eval_batches', 'default': None, 'help': 'max number of batches to evaluate on. None means all batches', 'type': typing.Optional[int]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'base_path': {'required': False, 'dest': 'trainer.checkpointer.base_path', 'default': 'checkpoints/', 'help': ' ', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_interval': {'required': False, 'dest': 'trainer.checkpointer.save_interval', 'default': datetime.timedelta(seconds=3600), 'help': ' ', 'type': <class 'datetime.timedelta'>}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:         default_factory=lambda: [dict(every=10000)]
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'keep': {'required': False, 'dest': 'trainer.checkpointer.keep', 'default': [{'every': 10000}], 'help': "TODO: I'd like to write this, but it's not supported by draccus\nkeep: List[CheckpointInterval] = field(default_factory=lambda: [CheckpointInterval(every=1000)])", 'type': typing.List[dict]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'load_checkpoint': {'required': False, 'dest': 'trainer.load_checkpoint', 'default': None, 'help': "if None (default), we'll load a checkpoint if it exists. If true, we must load a checkpoint", 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'load_checkpoint_path': {'required': False, 'dest': 'trainer.load_checkpoint_path', 'default': None, 'help': 'can be a parent (to find latest) or a specific checkpoint. if None, will set to checkpointer.base_path.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'initialize_from': {'required': False, 'dest': 'trainer.initialize_from', 'default': None, 'help': 'Levanter trainer checkpoint to initialize from', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:         default_factory=lambda: copy.deepcopy(DEFAULT_JAX_CONFIG)
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'jax_config': {'required': False, 'dest': 'trainer.jax_config', 'default': {'jax_threefry_partitionable': True, 'jax_softmax_custom_jvp': True}, 'help': ' ', 'type': typing.Dict[str, typing.Union[str, int, float, bool, NoneType]]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'coordinator_address': {'required': False, 'dest': 'trainer.distributed.coordinator_address', 'default': None, 'help': "if None, we'll use the default coordinator address (for TPU or GPU)", 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'num_processes': {'required': False, 'dest': 'trainer.distributed.num_processes', 'default': None, 'type': typing.Optional[int]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'process_id': {'required': False, 'dest': 'trainer.distributed.process_id', 'default': None, 'type': typing.Optional[int]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'local_device_ids': {'required': False, 'dest': 'trainer.distributed.local_device_ids', 'default': None, 'type': typing.Union[int, typing.List[int], NoneType]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'address': {'required': False, 'dest': 'trainer.ray.address', 'default': None, 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'start_workers': {'required': False, 'dest': 'trainer.ray.start_workers', 'default': True, 'help': ' ', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'auto_start_cluster': {'required': False, 'dest': 'trainer.ray.auto_start_cluster', 'default': True, 'help': ' ', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'require_accelerator': {'required': False, 'dest': 'trainer.require_accelerator', 'default': None, 'help': 'whether or not to require an accelerator (e.g. TPU or GPU).\ndefault depends on the platform: on macos False, else True', 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:     @property
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'shutdown_at_exit': {'required': False, 'dest': 'trainer.shutdown_at_exit', 'default': False, 'help': 'whether or not to shutdown the tpu at exit. If a float, shutdown after that many seconds. True = 5 minutes', 'type': typing.Union[bool, float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'max_tune_length': {'required': False, 'dest': 'max_tune_length', 'default': 2048, 'help': 'maximum length of the input to the model during tuning', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'train_data': {'required': False, 'dest': 'train_data', 'default': 'tatsu-lab/alpaca', 'help': 'Path to the training data, or huggingface dataset name.', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'train_data_cache_dir': {'required': False, 'dest': 'train_data_cache_dir', 'default': 'cache/', 'help': 'Path to cache the tokenized data. can be gcs', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'eval_data': {'required': False, 'dest': 'eval_data', 'default': None, 'help': 'Path to the training data, or huggingface dataset name.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'eval_data_cache_dir': {'required': False, 'dest': 'eval_data_cache_dir', 'default': 'cache/', 'help': 'Path to cache the tokenized data. can be gcs', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'model_name_or_path': {'required': False, 'dest': 'model_name_or_path', 'default': 'meta-llama/Llama-2-7b-hf', 'help': ' ', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tokenizer_name_or_path': {'required': False, 'dest': 'tokenizer_name_or_path', 'default': 'meta-llama/Llama-2-7b-hf', 'help': ' ', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'trust_remote_code': {'required': False, 'dest': 'trust_remote_code', 'default': False, 'help': 'Trust remote code when loading from HuggingFace checkpoints.', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'model_cache_dir': {'required': False, 'dest': 'model_cache_dir', 'default': None, 'help': 'Path to cache the model. must be local.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'hf_save_path': {'required': False, 'dest': 'hf_save_path', 'default': 'alpaca_hf_ckpts', 'help': 'Path to save the HuggingFace checkpoint, can be gcs', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_freq': {'required': False, 'dest': 'save_freq', 'default': None, 'type': typing.Optional[int]}
DEBUG:draccus.argparsing:
POST PROCESSING

DEBUG:draccus.argparsing:(raw) parsed args: Namespace(hf_save_path='/n/netscratch/amin_lab/Lab/slim/STP/storage/SFT', train_data='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/mathlib_leanworkbook.json', train_data_cache_dir='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/mathlib_leanworkbook_cache', eval_data='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/eval.json', eval_data_cache_dir='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/eval_cache', **{'trainer.checkpointer.base_path': '/n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt'})
DEBUG:draccus.parsers.decoding:from_dict for <class '__main__.TrainArgs'>
DEBUG:draccus.parsers.decoding:Decode name = optimizer, type = <class 'levanter.optim.config.OptimizerConfig'>
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.optim.config.AdamConfig'>
DEBUG:draccus.parsers.decoding:Decode name = learning_rate, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = weight_decay, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = min_lr_ratio, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = warmup, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = beta1, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = beta2, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = epsilon, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = trainer, type = <class 'levanter.trainer.TrainerConfig'>
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.trainer.TrainerConfig'>
DEBUG:draccus.parsers.decoding:Decode name = mp, type = <class 'jmp._src.policy.Policy'>
DEBUG:draccus.parsers.decoding:Decode name = tracker, type = typing.Union[levanter.tracker.tracker.TrackerConfig, typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Union[levanter.tracker.tracker.TrackerConfig, typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]]
DEBUG:draccus.parsers.decoding:Decoding a Tuple field: typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.tracker.wandb.WandbConfig'>
DEBUG:draccus.parsers.decoding:Decode name = project, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = name, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = tags, type = typing.List[str]
DEBUG:draccus.parsers.decoding:Decoding a List field: typing.List[str]
DEBUG:draccus.parsers.decoding:Decode name = tensor_parallel_axes, type = typing.Optional[typing.List[str]]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Optional[typing.List[str]]
DEBUG:draccus.parsers.decoding:Decode name = train_batch_size, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = per_device_parallelism, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = per_device_eval_parallelism, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = num_train_steps, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = steps_per_eval, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = checkpointer, type = <class 'levanter.checkpoint.CheckpointerConfig'>
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.checkpoint.CheckpointerConfig'>
DEBUG:draccus.parsers.decoding:Decode name = base_path, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = max_tune_length, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = train_data, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = train_data_cache_dir, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = eval_data, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = eval_data_cache_dir, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = model_name_or_path, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = tokenizer_name_or_path, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = trust_remote_code, type = <class 'bool'>
DEBUG:draccus.parsers.decoding:Decode name = hf_save_path, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = save_freq, type = typing.Optional[int]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Optional[int]
DEBUG:jax._src.clusters.cluster:Initializing distributed JAX environment via SlurmCluster
INFO:jax._src.distributed:JAX distributed initialized with visible devices: 0
INFO:jax._src.distributed:Starting JAX distributed service on [::]:65236
INFO:jax._src.distributed:Connecting to JAX distributed service on holygpu8a22204:65236
DEBUG:jax._src.xla_bridge:No jax_plugins namespace packages available
DEBUG:jax._src.xla_bridge:Initializing backend 'cpu'
DEBUG:jax._src.xla_bridge:Backend 'cpu' initialized
DEBUG:jax._src.xla_bridge:Initializing backend 'cuda'
DEBUG:jax._src.xla_bridge:Backend 'cuda' initialized
DEBUG:jax._src.xla_bridge:Initializing backend 'rocm'
DEBUG:jaxlib.xla_client:Custom call handler for CUDA is already register. Will not register a new one
DEBUG:jaxlib.xla_client:Custom call handler for ROCM is already register. Will not register a new one
INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
DEBUG:jax._src.xla_bridge:Initializing backend 'tpu'
INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
INFO:levanter.distributed:Initialized jax.distributed with 1 devices, 1 processes, coordinator_address=holygpu8a22204:65236, process_id=None, my device_ids=[0].
DEBUG:jax._src.dispatch:Finished tracing + transforming convert_element_type for pjit in 0.00043702125549316406 sec
DEBUG:jax._src.interpreters.pxla:Compiling convert_element_type with global shapes and types [ShapedArray(int32[])]. Argument mapping: [UnspecifiedValue].
DEBUG:jax._src.dispatch:Finished jaxpr to MLIR module conversion jit(convert_element_type) in 0.10739731788635254 sec
DEBUG:jax._src.compiler:get_compile_options: num_replicas=1 num_partitions=1 device_assignment=[[cuda(id=0)]]
DEBUG:jax._src.compiler:get_compile_options XLA-AutoFDO profile: using XLA-AutoFDO profile version -1
DEBUG:jax._src.cache_key:get_cache_key hash of serialized computation: aaf26a1934941f9d5fc23bdd157aef9ad1e5b44e65088cf0f5026039585eb737
DEBUG:jax._src.cache_key:get_cache_key hash after serializing computation: aaf26a1934941f9d5fc23bdd157aef9ad1e5b44e65088cf0f5026039585eb737
DEBUG:jax._src.cache_key:get_cache_key hash of serialized jax_lib version: 93d9f249493a97c6a6b25282a73d3b88948ba77ae0f96ace478fafc61ea5e60a
DEBUG:jax._src.cache_key:get_cache_key hash after serializing jax_lib version: e7361916a5017f57eecdfe1d12edd043b599916dc09f6e68d252c2af2b9bece8
DEBUG:jax._src.cache_key:get_cache_key hash of serialized XLA flags: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
DEBUG:jax._src.cache_key:get_cache_key hash after serializing XLA flags: e7361916a5017f57eecdfe1d12edd043b599916dc09f6e68d252c2af2b9bece8
DEBUG:jax._src.cache_key:get_cache_key hash of serialized compile_options: 9bd5e65cbfe093c53b1a2c63e42e7494a6f2a4a29438cb64a4f455f096c4a5dd
DEBUG:jax._src.cache_key:get_cache_key hash after serializing compile_options: c2aa6cb924f759bf83a41328985b0416ed6ae309c3bc48689b30da626aee3a86
DEBUG:jax._src.cache_key:get_cache_key hash of serialized accelerator_config: 8f2291eeb1fbc53122481bc160a27677710f49ce98bb1b900bb5ccf2a483e902
DEBUG:jax._src.cache_key:get_cache_key hash after serializing accelerator_config: 11f998895d99f5716f8f4a9d36bcc252082573861ae5f68d89a7223dec89ae18
DEBUG:jax._src.cache_key:get_cache_key hash of serialized compression: 5c4a59db52b7103852ed48a22fcd2cf336a48c7a4de3211294af3477ef82f814
DEBUG:jax._src.cache_key:get_cache_key hash after serializing compression: 916326f1f6358bc020d907d80ef5249fa72079fac6432bba102e155d6c7e65df
DEBUG:jax._src.cache_key:get_cache_key hash of serialized custom_hook: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
DEBUG:jax._src.cache_key:get_cache_key hash after serializing custom_hook: 916326f1f6358bc020d907d80ef5249fa72079fac6432bba102e155d6c7e65df
DEBUG:jax._src.compilation_cache:get_executable_and_time: cache is disabled/not initialized
DEBUG:jax._src.compiler:Not writing persistent cache entry for 'jit_convert_element_type' because it took < 1.00 seconds to compile (0.43s)
DEBUG:jax._src.dispatch:Finished XLA compilation of jit(convert_element_type) in 0.43596673011779785 sec
DEBUG:jax._src.dispatch:Finished tracing + transforming _reduce_sum for pjit in 0.0027403831481933594 sec
DEBUG:jax._src.dispatch:Finished tracing + transforming _psum for pjit in 0.0033445358276367188 sec
DEBUG:jax._src.interpreters.pxla:Compiling _psum with global shapes and types [ShapedArray(int32[1])]. Argument mapping: [GSPMDSharding({replicated})].
DEBUG:jax._src.dispatch:Finished jaxpr to MLIR module conversion jit(_psum) in 0.02285599708557129 sec
DEBUG:jax._src.compiler:get_compile_options: num_replicas=1 num_partitions=1 device_assignment=[[cuda(id=0)]]
DEBUG:jax._src.compiler:get_compile_options XLA-AutoFDO profile: using XLA-AutoFDO profile version -1
DEBUG:jax._src.cache_key:get_cache_key hash of serialized computation: 669c9b58d3ed8f3f9952c9b027e3b2bc4b6c8bc83d29756ae88f12f274a44ce9
DEBUG:jax._src.cache_key:get_cache_key hash after serializing computation: 669c9b58d3ed8f3f9952c9b027e3b2bc4b6c8bc83d29756ae88f12f274a44ce9
DEBUG:jax._src.cache_key:get_cache_key hash of serialized jax_lib version: 93d9f249493a97c6a6b25282a73d3b88948ba77ae0f96ace478fafc61ea5e60a
DEBUG:jax._src.cache_key:get_cache_key hash after serializing jax_lib version: a28a6e89ed6b729d13e8a0eae7428e4850df27738998badbeaea7fb20ff11927
DEBUG:jax._src.cache_key:get_cache_key hash of serialized XLA flags: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
DEBUG:jax._src.cache_key:get_cache_key hash after serializing XLA flags: a28a6e89ed6b729d13e8a0eae7428e4850df27738998badbeaea7fb20ff11927
DEBUG:jax._src.cache_key:get_cache_key hash of serialized compile_options: e83ac251dfb9d671e63e8f06f2a0d5af132c220f5065a75223e03404a2e8857a
DEBUG:jax._src.cache_key:get_cache_key hash after serializing compile_options: 9cf1b36e8ec523238d86137cf7a3235bd3af1f5ebd9a8db5cdcf2cce90950f9e
DEBUG:jax._src.cache_key:get_cache_key hash of serialized accelerator_config: 8f2291eeb1fbc53122481bc160a27677710f49ce98bb1b900bb5ccf2a483e902
DEBUG:jax._src.cache_key:get_cache_key hash after serializing accelerator_config: 2ffe876e8fb45f55522ea74b9695cc7e9ffa785e48c092a3f3a88c541affaf80
DEBUG:jax._src.cache_key:get_cache_key hash of serialized compression: 5c4a59db52b7103852ed48a22fcd2cf336a48c7a4de3211294af3477ef82f814
DEBUG:jax._src.cache_key:get_cache_key hash after serializing compression: d9d23483ca7e15c19da0c34faaa710f172c8930aec86ea0ee42a379734355350
DEBUG:jax._src.cache_key:get_cache_key hash of serialized custom_hook: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
DEBUG:jax._src.cache_key:get_cache_key hash after serializing custom_hook: d9d23483ca7e15c19da0c34faaa710f172c8930aec86ea0ee42a379734355350
DEBUG:jax._src.compilation_cache:get_executable_and_time: cache is disabled/not initialized
DEBUG:jax._src.compiler:Not writing persistent cache entry for 'jit__psum' because it took < 1.00 seconds to compile (0.03s)
DEBUG:jax._src.dispatch:Finished XLA compilation of jit(_psum) in 0.029932498931884766 sec
INFO:levanter.trainer:Setting run id to c1t074pm
2025-06-06T03:36:05 - 0 - levanter.tracker.wandb - wandb.py:200 - INFO :: Setting wandb code_dir to /n/netscratch/amin_lab/Lab/slim
wandb: Currently logged in as: slimbarkallah23 (slimbarkallah23-CentraleSupélec). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.20.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /n/netscratch/amin_lab/Lab/slim/STP/wandb/run-20250606_033606-c1t074pm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Kimina-sft
wandb: ⭐️ View project at https://wandb.ai/slimbarkallah23-CentraleSup%C3%A9lec/Kimina
wandb: 🚀 View run at https://wandb.ai/slimbarkallah23-CentraleSup%C3%A9lec/Kimina/runs/c1t074pm
2025-06-06T03:36:11 - 0 - levanter.distributed - distributed.py:218 - INFO :: Auto-discovered ray address using JAX coordinator address: holygpu8a22204:65236
2025-06-06T03:36:11 - 0 - levanter.distributed - distributed.py:232 - INFO :: Starting ray head on port 65476. We are process the coordinator holygpu8a22204.
2025-06-06T03:36:11 - 0 - levanter.distributed - distributed.py:233 - INFO :: Starting ray head with num_cpus set to 16.
2025-06-06 03:36:13,447	INFO usage_lib.py:472 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2025-06-06 03:36:13,447	INFO scripts.py:767 -- [37mLocal node IP[39m: [1m10.31.146.114[22m
2025-06-06 03:36:16,265	SUCC scripts.py:804 -- [32m--------------------[39m
2025-06-06 03:36:16,265	SUCC scripts.py:805 -- [32mRay runtime started.[39m
2025-06-06 03:36:16,265	SUCC scripts.py:806 -- [32m--------------------[39m
2025-06-06 03:36:16,265	INFO scripts.py:808 -- [36mNext steps[39m
2025-06-06 03:36:16,265	INFO scripts.py:811 -- To add another node to this Ray cluster, run
2025-06-06 03:36:16,265	INFO scripts.py:814 -- [1m  ray start --address='10.31.146.114:65476'[22m
2025-06-06 03:36:16,265	INFO scripts.py:823 -- To connect to this Ray cluster:
2025-06-06 03:36:16,265	INFO scripts.py:825 -- [35mimport[39m[26m ray
2025-06-06 03:36:16,265	INFO scripts.py:826 -- ray[35m.[39m[26minit()
2025-06-06 03:36:16,266	INFO scripts.py:838 -- To submit a Ray job using the Ray Jobs CLI:
2025-06-06 03:36:16,266	INFO scripts.py:839 -- [1m  RAY_ADDRESS='http://10.31.146.114:8265' ray job submit --working-dir . -- python my_script.py[22m
2025-06-06 03:36:16,266	INFO scripts.py:848 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html 
2025-06-06 03:36:16,266	INFO scripts.py:852 -- for more information on submitting Ray jobs to the Ray cluster.
2025-06-06 03:36:16,266	INFO scripts.py:857 -- To terminate the Ray runtime, run
2025-06-06 03:36:16,266	INFO scripts.py:858 -- [1m  ray stop[22m
2025-06-06 03:36:16,266	INFO scripts.py:861 -- To view the status of the cluster, use
2025-06-06 03:36:16,266	INFO scripts.py:862 --   [1mray status[22m[26m
2025-06-06 03:36:16,266	INFO scripts.py:866 -- To monitor and debug Ray, view the dashboard at 
2025-06-06 03:36:16,266	INFO scripts.py:867 --   [1m10.31.146.114:8265[22m[26m
2025-06-06 03:36:16,266	INFO scripts.py:874 -- [4mIf connection to the dashboard fails, check your firewall settings and network configuration.[24m
2025-06-06T03:36:16 - 0 - levanter.distributed - distributed.py:252 - INFO :: Successfully started ray head on port 65476.
2025-06-06T03:36:16 - 0 - levanter.distributed - distributed.py:267 - INFO :: ray.init(address='holygpu8a22204:65476', namespace='levanter', **{})
2025-06-06 03:36:16,452	INFO worker.py:1596 -- Connecting to existing Ray cluster at address: holygpu8a22204:65476...
2025-06-06 03:36:16,459	INFO worker.py:1772 -- Connected to Ray cluster. View the dashboard at [1m[32mhttp://10.31.146.114:8265 [39m[22m
2025-06-06T03:36:18 - 0 - __main__ - weighted_lm.py:183 - INFO :: Added 2 new tokens
Traceback (most recent call last):
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_http.py", line 406, in hf_raise_for_status
    response.raise_for_status()
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1232, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1339, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1854, in _raise_on_head_call_error
    raise head_call_error
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1746, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1666, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 364, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 388, in _request_wrapper
    hf_raise_for_status(response)
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_http.py", line 423, in hf_raise_for_status
    raise _format(GatedRepoError, message, response) from e
huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-68429a78-4b7996570b7898833dd281cf;7ee820ab-c4d3-47cc-b5a7-be6bef1bf3ac)

Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.
Access to model mistralai/Mistral-7B-v0.1 is restricted and you are not in the authorized list. Visit https://huggingface.co/mistralai/Mistral-7B-v0.1 to ask for access.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/examples/weighted_lm.py", line 317, in <module>
    levanter.config.main(train)()
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/config.py", line 84, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/examples/weighted_lm.py", line 187, in train
    converter = HFCheckpointConverter.from_hf(config.model_name_or_path, trust_remote_code=config.trust_remote_code)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 282, in from_hf
    if v().hf_checkpoint_converter().HfConfigClass.__name__ == config_class.__name__:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/models/mistral.py", line 85, in hf_checkpoint_converter
    return HFCheckpointConverter(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 258, in __init__
    tokenizer = HFCheckpointConverter._infer_tokenizer(tokenizer, ref, trust_remote_code)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 359, in _infer_tokenizer
    tokenizer = load_tokenizer(
                ^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 895, in load_tokenizer
    return arbitrary_load_from_hf(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 888, in arbitrary_load_from_hf
    return from_pretrained_lambda(model_name_or_path, revision=revision, trust_remote_code=trust_remote_code)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 864, in from_pretrained
    config = AutoConfig.from_pretrained(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1006, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/configuration_utils.py", line 570, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/configuration_utils.py", line 629, in _get_config_dict
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/utils/hub.py", line 421, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/mistralai/Mistral-7B-v0.1.
403 Client Error. (Request ID: Root=1-68429a78-4b7996570b7898833dd281cf;7ee820ab-c4d3-47cc-b5a7-be6bef1bf3ac)

Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.
Access to model mistralai/Mistral-7B-v0.1 is restricted and you are not in the authorized list. Visit https://huggingface.co/mistralai/Mistral-7B-v0.1 to ask for access.
Traceback (most recent call last):
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_http.py", line 406, in hf_raise_for_status
    response.raise_for_status()
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1232, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1339, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1854, in _raise_on_head_call_error
    raise head_call_error
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1746, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1666, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 364, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 388, in _request_wrapper
    hf_raise_for_status(response)
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/huggingface_hub/utils/_http.py", line 423, in hf_raise_for_status
    raise _format(GatedRepoError, message, response) from e
huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-68429a78-4b7996570b7898833dd281cf;7ee820ab-c4d3-47cc-b5a7-be6bef1bf3ac)

Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.
Access to model mistralai/Mistral-7B-v0.1 is restricted and you are not in the authorized list. Visit https://huggingface.co/mistralai/Mistral-7B-v0.1 to ask for access.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/examples/weighted_lm.py", line 317, in <module>
    levanter.config.main(train)()
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/config.py", line 84, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/examples/weighted_lm.py", line 187, in train
    converter = HFCheckpointConverter.from_hf(config.model_name_or_path, trust_remote_code=config.trust_remote_code)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 282, in from_hf
    if v().hf_checkpoint_converter().HfConfigClass.__name__ == config_class.__name__:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/models/mistral.py", line 85, in hf_checkpoint_converter
    return HFCheckpointConverter(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 258, in __init__
    tokenizer = HFCheckpointConverter._infer_tokenizer(tokenizer, ref, trust_remote_code)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 359, in _infer_tokenizer
    tokenizer = load_tokenizer(
                ^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 895, in load_tokenizer
    return arbitrary_load_from_hf(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/compat/hf_checkpoints.py", line 888, in arbitrary_load_from_hf
    return from_pretrained_lambda(model_name_or_path, revision=revision, trust_remote_code=trust_remote_code)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 864, in from_pretrained
    config = AutoConfig.from_pretrained(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1006, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/configuration_utils.py", line 570, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/configuration_utils.py", line 629, in _get_config_dict
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/transformers/utils/hub.py", line 421, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/mistralai/Mistral-7B-v0.1.
403 Client Error. (Request ID: Root=1-68429a78-4b7996570b7898833dd281cf;7ee820ab-c4d3-47cc-b5a7-be6bef1bf3ac)

Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.
Access to model mistralai/Mistral-7B-v0.1 is restricted and you are not in the authorized list. Visit https://huggingface.co/mistralai/Mistral-7B-v0.1 to ask for access.
2025-06-06 03:36:26,215	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/raylet --store_socket_name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_id=212b3fa40255a3ad881b85343bd7fd52fc58f2875b0f86bdd8b15509 --node_ip_address=10.31.146.114 --maximum_startup_concurrency=16 --static_resource_list=node:10.31.146.114,1.0,node:__internal_head__,1.0,accelerator_type:A100,1,CPU,16,GPU,1,memory,795027180544,object_store_memory,200000000000 "--python_worker_command=/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/workers/setup_worker.py -s /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.31.146.114 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/plasma_store --raylet-name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/raylet --redis-address=None --metrics-agent-port=64977 --runtime-env-agent-port=64632 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=64632 --gcs-address=10.31.146.114:65476 --session-name=session_2025-06-06_03-36-13_447834_699591 --temp-dir=/tmp/ray --webui=10.31.146.114:8265 --cluster-id=91bebb1e903e15e1223c538e98cd0b97ec22709ddefcf87f6e49e8a0 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.31.146.114:65476 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/plasma_store -Dray.raylet.socket-name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.31.146.114 -Dray.home=/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/../.. -Dray.logging.dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs -Dray.session-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/cpp/lib --temp_dir=/tmp/ray --session_dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591 --log_dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --resource_dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/runtime_resources --metrics-agent-port=64977 --metrics_export_port=59706 --runtime_env_agent_port=64632 --object_store_memory=200000000000 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.31.146.114:65476 --session-name=session_2025-06-06_03-36-13_447834_699591 --labels= --cluster-id=91bebb1e903e15e1223c538e98cd0b97ec22709ddefcf87f6e49e8a0 --head --num_prestart_python_workers=16 "--dashboard_agent_command=/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/dashboard/agent.py --node-ip-address=10.31.146.114 --metrics-export-port=59706 --dashboard-agent-port=64977 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/plasma_store --raylet-name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/raylet --temp-dir=/tmp/ray --session-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591 --log-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2025-06-06_03-36-13_447834_699591 --gcs-address=10.31.146.114:65476" "--runtime_env_agent_command=/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/runtime_env/agent/main.py --node-ip-address=10.31.146.114 --runtime-env-agent-port=64632 --gcs-address=10.31.146.114:65476 --runtime-env-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/runtime_resources --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --log-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --temp-dir=/tmp/ray"[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,222	INFO scripts.py:1144 -- 1/1 stopped.2025-06-06 03:36:26,307	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/autoscaler/_private/monitor.py --logs-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.31.146.114:65476 --monitor-ip=10.31.146.114[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,307	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591 --logs-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --gcs-address=10.31.146.114:65476 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,311	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -m ray.util.client.server --address=10.31.146.114:65476 --host=0.0.0.0 --port=10001 --mode=proxy --runtime-env-agent-address=http://10.31.146.114:64632[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,321	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,321	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,322	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,322	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,323	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,323	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,323	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,324	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,324	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,325	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,325	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,325	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,326	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,326	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,326	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,336	VINFO scripts.py:1122 -- Attempted to stop `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591 --logs-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --gcs-address=10.31.146.114:65476 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5[22m[26m`, but process was already dead.
2025-06-06 03:36:26,345	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/dashboard/agent.py --node-ip-address=10.31.146.114 --metrics-export-port=59706 --dashboard-agent-port=64977 --listen-port=52365 --node-manager-port=34783 --object-store-name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/plasma_store --raylet-name=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/sockets/raylet --temp-dir=/tmp/ray --session-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591 --log-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2025-06-06_03-36-13_447834_699591 --gcs-address=10.31.146.114:65476 --agent-id 424238335[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,350	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/dashboard/dashboard.py --host=0.0.0.0 --port=8265 --port-retries=0 --temp-dir=/tmp/ray --log-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --session-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.31.146.114:65476 --node-ip-address=10.31.146.114[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,354	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/runtime_env/agent/main.py --node-ip-address=10.31.146.114 --runtime-env-agent-port=64632 --gcs-address=10.31.146.114:65476 --runtime-env-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/runtime_resources --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --log-dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --temp-dir=/tmp/ray[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,359	INFO scripts.py:1144 -- 1/21 stopped.2025-06-06 03:36:26,359	INFO scripts.py:1144 -- 2/21 stopped.2025-06-06 03:36:26,359	INFO scripts.py:1144 -- 3/21 stopped.2025-06-06 03:36:26,359	INFO scripts.py:1144 -- 4/21 stopped.2025-06-06 03:36:26,359	INFO scripts.py:1144 -- 5/21 stopped.2025-06-06 03:36:26,359	INFO scripts.py:1144 -- 6/21 stopped.2025-06-06 03:36:26,359	INFO scripts.py:1144 -- 7/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 8/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 9/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 10/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 11/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 12/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 13/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 14/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 15/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 16/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 17/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 18/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 19/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 20/21 stopped.2025-06-06 03:36:26,360	INFO scripts.py:1144 -- 21/21 stopped.2025-06-06 03:36:26,438	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/session_2025-06-06_03-36-13_447834_699591/logs --config_list=eyJvYmplY3Rfc3BpbGxpbmdfY29uZmlnIjogIntcInR5cGVcIjogXCJmaWxlc3lzdGVtXCIsIFwicGFyYW1zXCI6IHtcImRpcmVjdG9yeV9wYXRoXCI6IFwiL3RtcC9yYXkvc2Vzc2lvbl8yMDI1LTA2LTA2XzAzLTM2LTEzXzQ0NzgzNF82OTk1OTFcIn19IiwgImlzX2V4dGVybmFsX3N0b3JhZ2VfdHlwZV9mcyI6IHRydWV9 --gcs_server_port=65476 --metrics-agent-port=64977 --node-ip-address=10.31.146.114 --session-name=session_2025-06-06_03-36-13_447834_699591 --ray-commit=fc87217e031b4e551cbb3d3ffc75f8c0fb57886a[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-06-06 03:36:26,442	INFO scripts.py:1144 -- 1/1 stopped.2025-06-06 03:36:26,442	SUCC scripts.py:1189 -- [32mStopped all 23 Ray processes.[39m
wandb: - 0.034 MB of 0.064 MB uploadedwandb: 
wandb: Run summary:
wandb:     backend gpu
wandb: num_devices 1
wandb:   num_hosts 1
wandb: 
wandb: 🚀 View run Kimina-sft at: https://wandb.ai/slimbarkallah23-CentraleSup%C3%A9lec/Kimina/runs/c1t074pm
wandb: ⭐️ View project at: https://wandb.ai/slimbarkallah23-CentraleSup%C3%A9lec/Kimina
wandb: Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250606_033606-c1t074pm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
