2025-06-05 09:49:52,918	INFO scripts.py:1186 -- Did not find any active Ray processes.
DEBUG:draccus.wrappers.field_metavar:Metavar for type None: None
DEBUG:draccus.help_formatter:action type: None, Result: , nargs: 0, default metavar: None
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.seed has a default value of 0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.mp has a default value of p=full,c=full,o=full
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.log_dir has a default value of logs
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.run_base_dir has a default value of runs
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.id has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.tracker has a default value of WandbConfig(entity=None, project=None, name=None, tags=[], id=None, group=None, mode=None, resume='allow', save_code=True, save_xla_dumps=False)
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler_start_step has a default value of 5
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler_num_steps has a default value of 100
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler_perfetto_link has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.batch_axis has a default value of batch
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fsdp_axis has a default value of embed
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.tensor_parallel_axes has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.axis_resources has a default value of {}
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.parameter_axis_resources has a default value of {}
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.replica_ici_axis_size has a default value of 1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.model_axis_size has a default value of 1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.replica_dcn_axis_size has a default value of 1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.train_batch_size has a default value of 512
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.per_device_parallelism has a default value of -1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.per_device_eval_parallelism has a default value of -1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.num_train_steps has a default value of 400000
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.steps_per_eval has a default value of 1000
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.max_eval_batches has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.checkpointer.base_path has a default value of checkpoints/
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.checkpointer.save_interval has a default value of 1:00:00
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.checkpointer.keep has a default value of [{'every': 10000}]
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.load_checkpoint has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.load_checkpoint_path has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.initialize_from has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.jax_config has a default value of {'jax_threefry_partitionable': True, 'jax_softmax_custom_jvp': True}
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.coordinator_address has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.num_processes has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.process_id has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.local_device_ids has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.ray.address has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.ray.start_workers has a default value of True
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.ray.auto_start_cluster has a default value of True
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.require_accelerator has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.shutdown_at_exit has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at max_tune_length has a default value of 2048
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at train_data has a default value of tatsu-lab/alpaca
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at train_data_cache_dir has a default value of cache/
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at eval_data has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at eval_data_cache_dir has a default value of cache/
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at model_name_or_path has a default value of meta-llama/Llama-2-7b-hf
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at tokenizer_name_or_path has a default value of meta-llama/Llama-2-7b-hf
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trust_remote_code has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at model_cache_dir has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at hf_save_path has a default value of alpaca_hf_ckpts
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at save_freq has a default value of None
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.learning_rate has a default value of 0.0006
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.min_lr_ratio has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup_ratio has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup has a default value of 0.01
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.stable has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.cooldown has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.lr_schedule has a default value of cosine
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay_modules has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.default_weight_decay_mask has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta1 has a default value of 0.9
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta2 has a default value of 0.999
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.epsilon has a default value of 1e-08
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.max_grad_norm has a default value of 1.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.learning_rate has a default value of 0.0006
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.min_lr_ratio has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup_ratio has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup has a default value of 0.01
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.stable has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.cooldown has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.lr_schedule has a default value of cosine
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay_modules has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.default_weight_decay_mask has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.update_interval has a default value of 10
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta1 has a default value of 0.96
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta2 has a default value of 0.99
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.epsilon has a default value of 1e-12
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.clip_threshold has a default value of 1.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.rng_seed has a default value of 0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.gamma has a default value of 0.01
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'learning_rate': {'required': False, 'dest': 'optimizer.learning_rate', 'default': 0.0006, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay': {'required': False, 'dest': 'optimizer.weight_decay', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'min_lr_ratio': {'required': False, 'dest': 'optimizer.min_lr_ratio', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup_ratio': {'required': False, 'dest': 'optimizer.warmup_ratio', 'default': None, 'help': 'Deprecated. fraction of training steps to use as warmup', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup': {'required': False, 'dest': 'optimizer.warmup', 'default': 0.01, 'help': 'fraction of training steps to use as warmup, or steps to use. 0.0 means no warmup', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'stable': {'required': False, 'dest': 'optimizer.stable', 'default': 0.0, 'help': 'fraction of training steps to use as stable, or steps to use. 0.0 means no stable', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'cooldown': {'required': False, 'dest': 'optimizer.cooldown', 'default': 0.0, 'help': 'fraction of training steps to use as cooldown, or steps to use. 0.0 means no cooldown', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'lr_schedule': {'required': False, 'dest': 'optimizer.lr_schedule', 'default': 'cosine', 'help': 'constant, cosine, linear', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay_modules': {'required': False, 'dest': 'optimizer.weight_decay_modules', 'default': None, 'help': 'A regex or a list of strings to identify where to mask weight.\nFor nano-GPT, this field can be set as `r".*attn.*weight|.*mlp.*weight|.*token_embeddings|.*position_embeddings"`', 'type': typing.Union[typing.List[str], str, NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'default_weight_decay_mask': {'required': False, 'dest': 'optimizer.default_weight_decay_mask', 'default': None, 'help': 'Whether to apply a default reasonable weight decay to modules not explicitly masked. None means it will if\nno weight_decay_modules are set. False means it will not. True means it will regardless of weight_decay_modules.', 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta1': {'required': False, 'dest': 'optimizer.beta1', 'default': 0.9, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta2': {'required': False, 'dest': 'optimizer.beta2', 'default': 0.999, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'epsilon': {'required': False, 'dest': 'optimizer.epsilon', 'default': 1e-08, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'max_grad_norm': {'required': False, 'dest': 'optimizer.max_grad_norm', 'default': 1.0, 'help': ' ', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'learning_rate': {'required': False, 'dest': 'optimizer.learning_rate', 'default': 0.0006, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay': {'required': False, 'dest': 'optimizer.weight_decay', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'min_lr_ratio': {'required': False, 'dest': 'optimizer.min_lr_ratio', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup_ratio': {'required': False, 'dest': 'optimizer.warmup_ratio', 'default': None, 'help': 'Deprecated. fraction of training steps to use as warmup', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup': {'required': False, 'dest': 'optimizer.warmup', 'default': 0.01, 'help': 'fraction of training steps to use as warmup, or steps to use. 0.0 means no warmup', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'stable': {'required': False, 'dest': 'optimizer.stable', 'default': 0.0, 'help': 'fraction of training steps to use as stable, or steps to use. 0.0 means no stable', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'cooldown': {'required': False, 'dest': 'optimizer.cooldown', 'default': 0.0, 'help': 'fraction of training steps to use as cooldown, or steps to use. 0.0 means no cooldown', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'lr_schedule': {'required': False, 'dest': 'optimizer.lr_schedule', 'default': 'cosine', 'help': 'constant, cosine, linear', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay_modules': {'required': False, 'dest': 'optimizer.weight_decay_modules', 'default': None, 'help': 'A regex or a list of strings to identify where to mask weight.\nFor nano-GPT, this field can be set as `r".*attn.*weight|.*mlp.*weight|.*token_embeddings|.*position_embeddings"`', 'type': typing.Union[typing.List[str], str, NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'default_weight_decay_mask': {'required': False, 'dest': 'optimizer.default_weight_decay_mask', 'default': None, 'help': 'Whether to apply a default reasonable weight decay to modules not explicitly masked. None means it will if\nno weight_decay_modules are set. False means it will not. True means it will regardless of weight_decay_modules.', 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'update_interval': {'required': False, 'dest': 'optimizer.update_interval', 'default': 10, 'help': 'How often to update the hessian approximation.', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta1': {'required': False, 'dest': 'optimizer.beta1', 'default': 0.96, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta2': {'required': False, 'dest': 'optimizer.beta2', 'default': 0.99, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'epsilon': {'required': False, 'dest': 'optimizer.epsilon', 'default': 1e-12, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'clip_threshold': {'required': False, 'dest': 'optimizer.clip_threshold', 'default': 1.0, 'help': ' ', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:     @abc.abstractmethod
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'rng_seed': {'required': False, 'dest': 'optimizer.rng_seed', 'default': 0, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:     def compute_hessian(self, fn, model, *batch, hess_key: PRNGKey, **batch_kwargs):
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'gamma': {'required': False, 'dest': 'optimizer.gamma', 'default': 0.01, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'seed': {'required': False, 'dest': 'trainer.seed', 'default': 0, 'help': 'random seed', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'mp': {'required': False, 'dest': 'trainer.mp', 'default': Policy(param_dtype=<class 'jax.numpy.float32'>, compute_dtype=<class 'jax.numpy.float32'>, output_dtype=<class 'jax.numpy.float32'>), 'help': 'mixed precision policy', 'type': <class 'jmp._src.policy.Policy'>}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fp8.amax_history_length has a default value of 1024
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fp8.compute_dtype has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fp8.targets has a default value of None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'amax_history_length': {'required': False, 'dest': 'trainer.fp8.amax_history_length', 'default': 1024, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'compute_dtype': {'required': False, 'dest': 'trainer.fp8.compute_dtype', 'default': None, 'type': typing.Union[str, type[typing.Any], numpy.dtype, jax._src.typing.SupportsDType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'targets': {'required': False, 'dest': 'trainer.fp8.targets', 'default': None, 'help': '\nIf provided, only modules with names in this list will be quantized. If a single string, will be treated as a regex\n', 'type': typing.Union[typing.List[str], str, NoneType]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.entity has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.project has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.name has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.tags has a default value of []
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.id has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.group has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.mode has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.resume has a default value of allow
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.save_code has a default value of True
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.save_xla_dumps has a default value of False
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'entity': {'required': False, 'dest': 'trainer.wandb.entity', 'default': None, 'help': 'An entity is a username or team name where you send runs', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'project': {'required': False, 'dest': 'trainer.wandb.project', 'default': None, 'help': 'The name of the project where you are sending the enw run.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'name': {'required': False, 'dest': 'trainer.wandb.name', 'default': None, 'help': "A short display name for this run, which is how you'll identify this run in the UI.", 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tags': {'required': False, 'dest': 'trainer.wandb.tags', 'default': [], 'help': 'Will populate the list of tags on this run in the UI.', 'type': typing.List[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'id': {'required': False, 'dest': 'trainer.wandb.id', 'default': None, 'help': 'A unique ID for this run, used for resuming. It must be unique in the project', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'group': {'required': False, 'dest': 'trainer.wandb.group', 'default': None, 'help': 'Specify a group to organize individual runs into a larger experiment.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'mode': {'required': False, 'dest': 'trainer.wandb.mode', 'default': None, 'help': 'Can be "online", "offline" or "disabled". If None, it will be whatever W&B decides.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'resume': {'required': False, 'dest': 'trainer.wandb.resume', 'default': 'allow', 'help': '\nSet the resume behavior. Options: "allow", "must", "never", "auto" or None.\nBy default, if the new run has the same ID as a previous run, this run overwrites that data.\nPlease refer to [init](https://docs.wandb.ai/ref/python/init) and [resume](https://docs.wandb.ai/guides/runs/resuming)\ndocument for more details.\n', 'type': typing.Union[bool, str, NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_code': {'required': False, 'dest': 'trainer.wandb.save_code', 'default': True, 'help': "If string, will save code from that directory. If True, will attempt to sniff out the main directory (since we\ntypically don't run from the root of the repo).", 'type': typing.Union[bool, str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_xla_dumps': {'required': False, 'dest': 'trainer.wandb.save_xla_dumps', 'default': False, 'help': 'If True, will save the XLA code to wandb (as configured by XLA_FLAGS). This is useful for debugging.', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'log_dir': {'required': False, 'dest': 'trainer.log_dir', 'default': PosixPath('logs'), 'help': ' ', 'type': <class 'pathlib.Path'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'run_base_dir': {'required': False, 'dest': 'trainer.run_base_dir', 'default': PosixPath('runs'), 'help': ' ', 'type': <class 'pathlib.Path'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'id': {'required': False, 'dest': 'trainer.id', 'default': None, 'help': 'run id. if None, will be set to a random string', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tracker': {'required': False, 'dest': 'trainer.tracker', 'default': WandbConfig(entity=None, project=None, name=None, tags=[], id=None, group=None, mode=None, resume='allow', save_code=True, save_xla_dumps=False), 'help': ' ', 'type': typing.Union[levanter.tracker.tracker.TrackerConfig, typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler': {'required': False, 'dest': 'trainer.profiler', 'default': False, 'help': 'TODO: refactor callbacks', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler_start_step': {'required': False, 'dest': 'trainer.profiler_start_step', 'default': 5, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler_num_steps': {'required': False, 'dest': 'trainer.profiler_num_steps', 'default': 100, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler_perfetto_link': {'required': False, 'dest': 'trainer.profiler_perfetto_link', 'default': False, 'help': ' ', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'batch_axis': {'required': False, 'dest': 'trainer.batch_axis', 'default': 'batch', 'help': 'Batch axis for data parallel.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'fsdp_axis': {'required': False, 'dest': 'trainer.fsdp_axis', 'default': 'embed', 'help': 'Axis/Axes to use for FSDP', 'type': typing.Union[str, typing.List[str], NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tensor_parallel_axes': {'required': False, 'dest': 'trainer.tensor_parallel_axes', 'default': None, 'help': 'Axes, if any, to use for tensor parallelism', 'type': typing.Optional[typing.List[str]]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'axis_resources': {'required': False, 'dest': 'trainer.axis_resources', 'default': {}, 'help': 'mapping from logical axis to physical axis. batch_axis, fsdp_axis, and tensor_parallel_axes are preferred', 'type': collections.abc.Mapping[str, typing.Union[typing.Tuple[str], str]]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:         default_factory=dict
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'parameter_axis_resources': {'required': False, 'dest': 'trainer.parameter_axis_resources', 'default': {}, 'help': ' ', 'type': collections.abc.Mapping[str, typing.Union[typing.Tuple[str], str]]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'replica_ici_axis_size': {'required': False, 'dest': 'trainer.replica_ici_axis_size', 'default': 1, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'model_axis_size': {'required': False, 'dest': 'trainer.model_axis_size', 'default': 1, 'help': 'how many devices within each slice for sharding with DP. Fix TP=1, the rest of the devices is for FSDP.', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'replica_dcn_axis_size': {'required': False, 'dest': 'trainer.replica_dcn_axis_size', 'default': 1, 'help': 'how many slices in the multislice scheme for sharding with DP and TP. The rest of the devices is for FSDP.', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'train_batch_size': {'required': False, 'dest': 'trainer.train_batch_size', 'default': 512, 'help': 'Config related to batch sizes', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'per_device_parallelism': {'required': False, 'dest': 'trainer.per_device_parallelism', 'default': -1, 'help': 'how many examples to process in parallel on each device. -1 (default) means train_batch_size/num_devices', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'per_device_eval_parallelism': {'required': False, 'dest': 'trainer.per_device_eval_parallelism', 'default': -1, 'help': 'how many examples to process in parallel on each device. -1 (default) means same as per_device_parallelism', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'num_train_steps': {'required': False, 'dest': 'trainer.num_train_steps', 'default': 400000, 'help': 'number of training steps', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'steps_per_eval': {'required': False, 'dest': 'trainer.steps_per_eval', 'default': 1000, 'help': 'how often to evaluate', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'max_eval_batches': {'required': False, 'dest': 'trainer.max_eval_batches', 'default': None, 'help': 'max number of batches to evaluate on. None means all batches', 'type': typing.Optional[int]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'base_path': {'required': False, 'dest': 'trainer.checkpointer.base_path', 'default': 'checkpoints/', 'help': ' ', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_interval': {'required': False, 'dest': 'trainer.checkpointer.save_interval', 'default': datetime.timedelta(seconds=3600), 'help': ' ', 'type': <class 'datetime.timedelta'>}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:         default_factory=lambda: [dict(every=10000)]
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'keep': {'required': False, 'dest': 'trainer.checkpointer.keep', 'default': [{'every': 10000}], 'help': "TODO: I'd like to write this, but it's not supported by draccus\nkeep: List[CheckpointInterval] = field(default_factory=lambda: [CheckpointInterval(every=1000)])", 'type': typing.List[dict]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'load_checkpoint': {'required': False, 'dest': 'trainer.load_checkpoint', 'default': None, 'help': "if None (default), we'll load a checkpoint if it exists. If true, we must load a checkpoint", 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'load_checkpoint_path': {'required': False, 'dest': 'trainer.load_checkpoint_path', 'default': None, 'help': 'can be a parent (to find latest) or a specific checkpoint. if None, will set to checkpointer.base_path.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'initialize_from': {'required': False, 'dest': 'trainer.initialize_from', 'default': None, 'help': 'Levanter trainer checkpoint to initialize from', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:         default_factory=lambda: copy.deepcopy(DEFAULT_JAX_CONFIG)
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'jax_config': {'required': False, 'dest': 'trainer.jax_config', 'default': {'jax_threefry_partitionable': True, 'jax_softmax_custom_jvp': True}, 'help': ' ', 'type': typing.Dict[str, typing.Union[str, int, float, bool, NoneType]]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'coordinator_address': {'required': False, 'dest': 'trainer.distributed.coordinator_address', 'default': None, 'help': "if None, we'll use the default coordinator address (for TPU or GPU)", 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'num_processes': {'required': False, 'dest': 'trainer.distributed.num_processes', 'default': None, 'type': typing.Optional[int]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'process_id': {'required': False, 'dest': 'trainer.distributed.process_id', 'default': None, 'type': typing.Optional[int]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'local_device_ids': {'required': False, 'dest': 'trainer.distributed.local_device_ids', 'default': None, 'type': typing.Union[int, typing.List[int], NoneType]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'address': {'required': False, 'dest': 'trainer.ray.address', 'default': None, 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'start_workers': {'required': False, 'dest': 'trainer.ray.start_workers', 'default': True, 'help': ' ', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'auto_start_cluster': {'required': False, 'dest': 'trainer.ray.auto_start_cluster', 'default': True, 'help': ' ', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'require_accelerator': {'required': False, 'dest': 'trainer.require_accelerator', 'default': None, 'help': 'whether or not to require an accelerator (e.g. TPU or GPU).\ndefault depends on the platform: on macos False, else True', 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:     @property
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'shutdown_at_exit': {'required': False, 'dest': 'trainer.shutdown_at_exit', 'default': False, 'help': 'whether or not to shutdown the tpu at exit. If a float, shutdown after that many seconds. True = 5 minutes', 'type': typing.Union[bool, float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'max_tune_length': {'required': False, 'dest': 'max_tune_length', 'default': 2048, 'help': 'maximum length of the input to the model during tuning', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'train_data': {'required': False, 'dest': 'train_data', 'default': 'tatsu-lab/alpaca', 'help': 'Path to the training data, or huggingface dataset name.', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'train_data_cache_dir': {'required': False, 'dest': 'train_data_cache_dir', 'default': 'cache/', 'help': 'Path to cache the tokenized data. can be gcs', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'eval_data': {'required': False, 'dest': 'eval_data', 'default': None, 'help': 'Path to the training data, or huggingface dataset name.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'eval_data_cache_dir': {'required': False, 'dest': 'eval_data_cache_dir', 'default': 'cache/', 'help': 'Path to cache the tokenized data. can be gcs', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'model_name_or_path': {'required': False, 'dest': 'model_name_or_path', 'default': 'meta-llama/Llama-2-7b-hf', 'help': ' ', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tokenizer_name_or_path': {'required': False, 'dest': 'tokenizer_name_or_path', 'default': 'meta-llama/Llama-2-7b-hf', 'help': ' ', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'trust_remote_code': {'required': False, 'dest': 'trust_remote_code', 'default': False, 'help': 'Trust remote code when loading from HuggingFace checkpoints.', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'model_cache_dir': {'required': False, 'dest': 'model_cache_dir', 'default': None, 'help': 'Path to cache the model. must be local.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'hf_save_path': {'required': False, 'dest': 'hf_save_path', 'default': 'alpaca_hf_ckpts', 'help': 'Path to save the HuggingFace checkpoint, can be gcs', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_freq': {'required': False, 'dest': 'save_freq', 'default': None, 'type': typing.Optional[int]}
DEBUG:draccus.argparsing:
POST PROCESSING

DEBUG:draccus.argparsing:(raw) parsed args: Namespace(hf_save_path='/n/netscratch/amin_lab/Lab/slim/STP/storage/SFT', train_data='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/mathlib_leanworkbook.json', train_data_cache_dir='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/mathlib_leanworkbook_cache', eval_data='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/eval.json', eval_data_cache_dir='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/eval_cache', **{'trainer.checkpointer.base_path': '/n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt'})
DEBUG:draccus.parsers.decoding:from_dict for <class '__main__.TrainArgs'>
DEBUG:draccus.parsers.decoding:Decode name = optimizer, type = <class 'levanter.optim.config.OptimizerConfig'>
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.optim.config.AdamConfig'>
DEBUG:draccus.parsers.decoding:Decode name = learning_rate, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = weight_decay, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = min_lr_ratio, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = warmup, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = beta1, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = beta2, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = epsilon, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = trainer, type = <class 'levanter.trainer.TrainerConfig'>
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.trainer.TrainerConfig'>
DEBUG:draccus.parsers.decoding:Decode name = mp, type = <class 'jmp._src.policy.Policy'>
DEBUG:draccus.parsers.decoding:Decode name = tracker, type = typing.Union[levanter.tracker.tracker.TrackerConfig, typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Union[levanter.tracker.tracker.TrackerConfig, typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]]
DEBUG:draccus.parsers.decoding:Decoding a Tuple field: typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.tracker.wandb.WandbConfig'>
DEBUG:draccus.parsers.decoding:Decode name = project, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = name, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = tags, type = typing.List[str]
DEBUG:draccus.parsers.decoding:Decoding a List field: typing.List[str]
DEBUG:draccus.parsers.decoding:Decode name = tensor_parallel_axes, type = typing.Optional[typing.List[str]]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Optional[typing.List[str]]
DEBUG:draccus.parsers.decoding:Decode name = train_batch_size, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = per_device_parallelism, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = per_device_eval_parallelism, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = num_train_steps, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = steps_per_eval, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = checkpointer, type = <class 'levanter.checkpoint.CheckpointerConfig'>
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.checkpoint.CheckpointerConfig'>
DEBUG:draccus.parsers.decoding:Decode name = base_path, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = max_tune_length, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = train_data, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = train_data_cache_dir, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = eval_data, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = eval_data_cache_dir, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = model_name_or_path, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = tokenizer_name_or_path, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = trust_remote_code, type = <class 'bool'>
DEBUG:draccus.parsers.decoding:Decode name = hf_save_path, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = save_freq, type = typing.Optional[int]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Optional[int]
Traceback (most recent call last):
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/examples/weighted_lm.py", line 317, in <module>
    levanter.config.main(train)()
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/config.py", line 84, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/examples/weighted_lm.py", line 170, in train
    levanter.initialize(config)
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/trainer.py", line 798, in initialize
    trainer_config.initialize()
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/trainer.py", line 624, in initialize
    self.distributed.initialize()
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/distributed.py", line 313, in initialize
    device_ids = LevanterSlurmCluster.get_local_device_ids_for_process()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/distributed.py", line 85, in get_local_device_ids_for_process
    all_visible_devices = [int(x) for x in os.environ[_VISIBLE_DEVICES].split(",")]
                           ^^^^^^
ValueError: invalid literal for int() with base 10: 'MIG-37e22da3-01d1-5528-ad44-005d3158089a'
