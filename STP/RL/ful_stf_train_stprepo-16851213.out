2025-05-24 03:51:35,759	INFO scripts.py:1186 -- Did not find any active Ray processes.
DEBUG:draccus.wrappers.field_metavar:Metavar for type None: None
DEBUG:draccus.help_formatter:action type: None, Result: , nargs: 0, default metavar: None
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.seed has a default value of 0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.mp has a default value of p=full,c=full,o=full
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.log_dir has a default value of logs
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.run_base_dir has a default value of runs
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.id has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.tracker has a default value of WandbConfig(entity=None, project=None, name=None, tags=[], id=None, group=None, mode=None, resume='allow', save_code=True, save_xla_dumps=False)
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler_start_step has a default value of 5
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler_num_steps has a default value of 100
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.profiler_perfetto_link has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.batch_axis has a default value of batch
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fsdp_axis has a default value of embed
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.tensor_parallel_axes has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.axis_resources has a default value of {}
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.parameter_axis_resources has a default value of {}
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.replica_ici_axis_size has a default value of 1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.model_axis_size has a default value of 1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.replica_dcn_axis_size has a default value of 1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.train_batch_size has a default value of 512
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.per_device_parallelism has a default value of -1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.per_device_eval_parallelism has a default value of -1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.num_train_steps has a default value of 400000
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.steps_per_eval has a default value of 1000
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.max_eval_batches has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.checkpointer.base_path has a default value of checkpoints/
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.checkpointer.save_interval has a default value of 1:00:00
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.checkpointer.keep has a default value of [{'every': 10000}]
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.load_checkpoint has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.load_checkpoint_path has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.initialize_from has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.jax_config has a default value of {'jax_threefry_partitionable': True, 'jax_softmax_custom_jvp': True}
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.coordinator_address has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.num_processes has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.process_id has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.distributed.local_device_ids has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.ray.address has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.ray.start_workers has a default value of True
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.ray.auto_start_cluster has a default value of True
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.require_accelerator has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.shutdown_at_exit has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at max_tune_length has a default value of 2048
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at train_data has a default value of tatsu-lab/alpaca
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at train_data_cache_dir has a default value of cache/
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at eval_data has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at eval_data_cache_dir has a default value of cache/
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at model_name_or_path has a default value of meta-llama/Llama-2-7b-hf
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at tokenizer_name_or_path has a default value of meta-llama/Llama-2-7b-hf
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trust_remote_code has a default value of False
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at model_cache_dir has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at hf_save_path has a default value of alpaca_hf_ckpts
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at save_freq has a default value of None
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.learning_rate has a default value of 0.0006
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.min_lr_ratio has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup_ratio has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup has a default value of 0.01
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.stable has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.cooldown has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.lr_schedule has a default value of cosine
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay_modules has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.default_weight_decay_mask has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta1 has a default value of 0.9
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta2 has a default value of 0.999
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.epsilon has a default value of 1e-08
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.max_grad_norm has a default value of 1.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.learning_rate has a default value of 0.0006
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.min_lr_ratio has a default value of 0.1
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup_ratio has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.warmup has a default value of 0.01
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.stable has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.cooldown has a default value of 0.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.lr_schedule has a default value of cosine
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.weight_decay_modules has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.default_weight_decay_mask has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.update_interval has a default value of 10
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta1 has a default value of 0.96
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.beta2 has a default value of 0.99
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.epsilon has a default value of 1e-12
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.clip_threshold has a default value of 1.0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.rng_seed has a default value of 0
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at optimizer.gamma has a default value of 0.01
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'learning_rate': {'required': False, 'dest': 'optimizer.learning_rate', 'default': 0.0006, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay': {'required': False, 'dest': 'optimizer.weight_decay', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'min_lr_ratio': {'required': False, 'dest': 'optimizer.min_lr_ratio', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup_ratio': {'required': False, 'dest': 'optimizer.warmup_ratio', 'default': None, 'help': 'Deprecated. fraction of training steps to use as warmup', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup': {'required': False, 'dest': 'optimizer.warmup', 'default': 0.01, 'help': 'fraction of training steps to use as warmup, or steps to use. 0.0 means no warmup', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'stable': {'required': False, 'dest': 'optimizer.stable', 'default': 0.0, 'help': 'fraction of training steps to use as stable, or steps to use. 0.0 means no stable', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'cooldown': {'required': False, 'dest': 'optimizer.cooldown', 'default': 0.0, 'help': 'fraction of training steps to use as cooldown, or steps to use. 0.0 means no cooldown', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'lr_schedule': {'required': False, 'dest': 'optimizer.lr_schedule', 'default': 'cosine', 'help': 'constant, cosine, linear', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay_modules': {'required': False, 'dest': 'optimizer.weight_decay_modules', 'default': None, 'help': 'A regex or a list of strings to identify where to mask weight.\nFor nano-GPT, this field can be set as `r".*attn.*weight|.*mlp.*weight|.*token_embeddings|.*position_embeddings"`', 'type': typing.Union[typing.List[str], str, NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'default_weight_decay_mask': {'required': False, 'dest': 'optimizer.default_weight_decay_mask', 'default': None, 'help': 'Whether to apply a default reasonable weight decay to modules not explicitly masked. None means it will if\nno weight_decay_modules are set. False means it will not. True means it will regardless of weight_decay_modules.', 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta1': {'required': False, 'dest': 'optimizer.beta1', 'default': 0.9, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta2': {'required': False, 'dest': 'optimizer.beta2', 'default': 0.999, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'epsilon': {'required': False, 'dest': 'optimizer.epsilon', 'default': 1e-08, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'max_grad_norm': {'required': False, 'dest': 'optimizer.max_grad_norm', 'default': 1.0, 'help': ' ', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'learning_rate': {'required': False, 'dest': 'optimizer.learning_rate', 'default': 0.0006, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay': {'required': False, 'dest': 'optimizer.weight_decay', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'min_lr_ratio': {'required': False, 'dest': 'optimizer.min_lr_ratio', 'default': 0.1, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup_ratio': {'required': False, 'dest': 'optimizer.warmup_ratio', 'default': None, 'help': 'Deprecated. fraction of training steps to use as warmup', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'warmup': {'required': False, 'dest': 'optimizer.warmup', 'default': 0.01, 'help': 'fraction of training steps to use as warmup, or steps to use. 0.0 means no warmup', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'stable': {'required': False, 'dest': 'optimizer.stable', 'default': 0.0, 'help': 'fraction of training steps to use as stable, or steps to use. 0.0 means no stable', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'cooldown': {'required': False, 'dest': 'optimizer.cooldown', 'default': 0.0, 'help': 'fraction of training steps to use as cooldown, or steps to use. 0.0 means no cooldown', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'lr_schedule': {'required': False, 'dest': 'optimizer.lr_schedule', 'default': 'cosine', 'help': 'constant, cosine, linear', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'weight_decay_modules': {'required': False, 'dest': 'optimizer.weight_decay_modules', 'default': None, 'help': 'A regex or a list of strings to identify where to mask weight.\nFor nano-GPT, this field can be set as `r".*attn.*weight|.*mlp.*weight|.*token_embeddings|.*position_embeddings"`', 'type': typing.Union[typing.List[str], str, NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'default_weight_decay_mask': {'required': False, 'dest': 'optimizer.default_weight_decay_mask', 'default': None, 'help': 'Whether to apply a default reasonable weight decay to modules not explicitly masked. None means it will if\nno weight_decay_modules are set. False means it will not. True means it will regardless of weight_decay_modules.', 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'update_interval': {'required': False, 'dest': 'optimizer.update_interval', 'default': 10, 'help': 'How often to update the hessian approximation.', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta1': {'required': False, 'dest': 'optimizer.beta1', 'default': 0.96, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'beta2': {'required': False, 'dest': 'optimizer.beta2', 'default': 0.99, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'epsilon': {'required': False, 'dest': 'optimizer.epsilon', 'default': 1e-12, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'clip_threshold': {'required': False, 'dest': 'optimizer.clip_threshold', 'default': 1.0, 'help': ' ', 'type': typing.Optional[float]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:     @abc.abstractmethod
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'rng_seed': {'required': False, 'dest': 'optimizer.rng_seed', 'default': 0, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:     def compute_hessian(self, fn, model, *batch, hess_key: PRNGKey, **batch_kwargs):
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'gamma': {'required': False, 'dest': 'optimizer.gamma', 'default': 0.01, 'help': ' ', 'type': <class 'float'>}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'seed': {'required': False, 'dest': 'trainer.seed', 'default': 0, 'help': 'random seed', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'mp': {'required': False, 'dest': 'trainer.mp', 'default': Policy(param_dtype=<class 'jax.numpy.float32'>, compute_dtype=<class 'jax.numpy.float32'>, output_dtype=<class 'jax.numpy.float32'>), 'help': 'mixed precision policy', 'type': <class 'jmp._src.policy.Policy'>}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fp8.amax_history_length has a default value of 1024
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fp8.compute_dtype has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.fp8.targets has a default value of None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'amax_history_length': {'required': False, 'dest': 'trainer.fp8.amax_history_length', 'default': 1024, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'compute_dtype': {'required': False, 'dest': 'trainer.fp8.compute_dtype', 'default': None, 'type': typing.Union[str, type[typing.Any], numpy.dtype, jax._src.typing.SupportsDType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'targets': {'required': False, 'dest': 'trainer.fp8.targets', 'default': None, 'help': '\nIf provided, only modules with names in this list will be quantized. If a single string, will be treated as a regex\n', 'type': typing.Union[typing.List[str], str, NoneType]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.entity has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.project has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.name has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.tags has a default value of []
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.id has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.group has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.mode has a default value of None
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.resume has a default value of allow
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.save_code has a default value of True
DEBUG:draccus.wrappers.dataclass_wrapper:wrapped field at trainer.wandb.save_xla_dumps has a default value of False
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'entity': {'required': False, 'dest': 'trainer.wandb.entity', 'default': None, 'help': 'An entity is a username or team name where you send runs', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'project': {'required': False, 'dest': 'trainer.wandb.project', 'default': None, 'help': 'The name of the project where you are sending the enw run.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'name': {'required': False, 'dest': 'trainer.wandb.name', 'default': None, 'help': "A short display name for this run, which is how you'll identify this run in the UI.", 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tags': {'required': False, 'dest': 'trainer.wandb.tags', 'default': [], 'help': 'Will populate the list of tags on this run in the UI.', 'type': typing.List[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'id': {'required': False, 'dest': 'trainer.wandb.id', 'default': None, 'help': 'A unique ID for this run, used for resuming. It must be unique in the project', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'group': {'required': False, 'dest': 'trainer.wandb.group', 'default': None, 'help': 'Specify a group to organize individual runs into a larger experiment.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'mode': {'required': False, 'dest': 'trainer.wandb.mode', 'default': None, 'help': 'Can be "online", "offline" or "disabled". If None, it will be whatever W&B decides.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'resume': {'required': False, 'dest': 'trainer.wandb.resume', 'default': 'allow', 'help': '\nSet the resume behavior. Options: "allow", "must", "never", "auto" or None.\nBy default, if the new run has the same ID as a previous run, this run overwrites that data.\nPlease refer to [init](https://docs.wandb.ai/ref/python/init) and [resume](https://docs.wandb.ai/guides/runs/resuming)\ndocument for more details.\n', 'type': typing.Union[bool, str, NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_code': {'required': False, 'dest': 'trainer.wandb.save_code', 'default': True, 'help': "If string, will save code from that directory. If True, will attempt to sniff out the main directory (since we\ntypically don't run from the root of the repo).", 'type': typing.Union[bool, str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_xla_dumps': {'required': False, 'dest': 'trainer.wandb.save_xla_dumps', 'default': False, 'help': 'If True, will save the XLA code to wandb (as configured by XLA_FLAGS). This is useful for debugging.', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'log_dir': {'required': False, 'dest': 'trainer.log_dir', 'default': PosixPath('logs'), 'help': ' ', 'type': <class 'pathlib.Path'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'run_base_dir': {'required': False, 'dest': 'trainer.run_base_dir', 'default': PosixPath('runs'), 'help': ' ', 'type': <class 'pathlib.Path'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'id': {'required': False, 'dest': 'trainer.id', 'default': None, 'help': 'run id. if None, will be set to a random string', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tracker': {'required': False, 'dest': 'trainer.tracker', 'default': WandbConfig(entity=None, project=None, name=None, tags=[], id=None, group=None, mode=None, resume='allow', save_code=True, save_xla_dumps=False), 'help': ' ', 'type': typing.Union[levanter.tracker.tracker.TrackerConfig, typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler': {'required': False, 'dest': 'trainer.profiler', 'default': False, 'help': 'TODO: refactor callbacks', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler_start_step': {'required': False, 'dest': 'trainer.profiler_start_step', 'default': 5, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler_num_steps': {'required': False, 'dest': 'trainer.profiler_num_steps', 'default': 100, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'profiler_perfetto_link': {'required': False, 'dest': 'trainer.profiler_perfetto_link', 'default': False, 'help': ' ', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'batch_axis': {'required': False, 'dest': 'trainer.batch_axis', 'default': 'batch', 'help': 'Batch axis for data parallel.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'fsdp_axis': {'required': False, 'dest': 'trainer.fsdp_axis', 'default': 'embed', 'help': 'Axis/Axes to use for FSDP', 'type': typing.Union[str, typing.List[str], NoneType]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tensor_parallel_axes': {'required': False, 'dest': 'trainer.tensor_parallel_axes', 'default': None, 'help': 'Axes, if any, to use for tensor parallelism', 'type': typing.Optional[typing.List[str]]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'axis_resources': {'required': False, 'dest': 'trainer.axis_resources', 'default': {}, 'help': 'mapping from logical axis to physical axis. batch_axis, fsdp_axis, and tensor_parallel_axes are preferred', 'type': collections.abc.Mapping[str, typing.Union[typing.Tuple[str], str]]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:         default_factory=dict
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'parameter_axis_resources': {'required': False, 'dest': 'trainer.parameter_axis_resources', 'default': {}, 'help': ' ', 'type': collections.abc.Mapping[str, typing.Union[typing.Tuple[str], str]]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'replica_ici_axis_size': {'required': False, 'dest': 'trainer.replica_ici_axis_size', 'default': 1, 'help': ' ', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'model_axis_size': {'required': False, 'dest': 'trainer.model_axis_size', 'default': 1, 'help': 'how many devices within each slice for sharding with DP. Fix TP=1, the rest of the devices is for FSDP.', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'replica_dcn_axis_size': {'required': False, 'dest': 'trainer.replica_dcn_axis_size', 'default': 1, 'help': 'how many slices in the multislice scheme for sharding with DP and TP. The rest of the devices is for FSDP.', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'train_batch_size': {'required': False, 'dest': 'trainer.train_batch_size', 'default': 512, 'help': 'Config related to batch sizes', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'per_device_parallelism': {'required': False, 'dest': 'trainer.per_device_parallelism', 'default': -1, 'help': 'how many examples to process in parallel on each device. -1 (default) means train_batch_size/num_devices', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'per_device_eval_parallelism': {'required': False, 'dest': 'trainer.per_device_eval_parallelism', 'default': -1, 'help': 'how many examples to process in parallel on each device. -1 (default) means same as per_device_parallelism', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'num_train_steps': {'required': False, 'dest': 'trainer.num_train_steps', 'default': 400000, 'help': 'number of training steps', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'steps_per_eval': {'required': False, 'dest': 'trainer.steps_per_eval', 'default': 1000, 'help': 'how often to evaluate', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'max_eval_batches': {'required': False, 'dest': 'trainer.max_eval_batches', 'default': None, 'help': 'max number of batches to evaluate on. None means all batches', 'type': typing.Optional[int]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'base_path': {'required': False, 'dest': 'trainer.checkpointer.base_path', 'default': 'checkpoints/', 'help': ' ', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_interval': {'required': False, 'dest': 'trainer.checkpointer.save_interval', 'default': datetime.timedelta(seconds=3600), 'help': ' ', 'type': <class 'datetime.timedelta'>}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:         default_factory=lambda: [dict(every=10000)]
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'keep': {'required': False, 'dest': 'trainer.checkpointer.keep', 'default': [{'every': 10000}], 'help': "TODO: I'd like to write this, but it's not supported by draccus\nkeep: List[CheckpointInterval] = field(default_factory=lambda: [CheckpointInterval(every=1000)])", 'type': typing.List[dict]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'load_checkpoint': {'required': False, 'dest': 'trainer.load_checkpoint', 'default': None, 'help': "if None (default), we'll load a checkpoint if it exists. If true, we must load a checkpoint", 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'load_checkpoint_path': {'required': False, 'dest': 'trainer.load_checkpoint_path', 'default': None, 'help': 'can be a parent (to find latest) or a specific checkpoint. if None, will set to checkpointer.base_path.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'initialize_from': {'required': False, 'dest': 'trainer.initialize_from', 'default': None, 'help': 'Levanter trainer checkpoint to initialize from', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:         default_factory=lambda: copy.deepcopy(DEFAULT_JAX_CONFIG)
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'jax_config': {'required': False, 'dest': 'trainer.jax_config', 'default': {'jax_threefry_partitionable': True, 'jax_softmax_custom_jvp': True}, 'help': ' ', 'type': typing.Dict[str, typing.Union[str, int, float, bool, NoneType]]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'coordinator_address': {'required': False, 'dest': 'trainer.distributed.coordinator_address', 'default': None, 'help': "if None, we'll use the default coordinator address (for TPU or GPU)", 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'num_processes': {'required': False, 'dest': 'trainer.distributed.num_processes', 'default': None, 'type': typing.Optional[int]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'process_id': {'required': False, 'dest': 'trainer.distributed.process_id', 'default': None, 'type': typing.Optional[int]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'local_device_ids': {'required': False, 'dest': 'trainer.distributed.local_device_ids', 'default': None, 'type': typing.Union[int, typing.List[int], NoneType]}
DEBUG:draccus.wrappers.field_metavar:Metavar for type <class 'str'>: str
DEBUG:draccus.help_formatter:action type: <class 'str'>, Result: str, nargs: None, default metavar: None
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'address': {'required': False, 'dest': 'trainer.ray.address', 'default': None, 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'start_workers': {'required': False, 'dest': 'trainer.ray.start_workers', 'default': True, 'help': ' ', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'auto_start_cluster': {'required': False, 'dest': 'trainer.ray.auto_start_cluster', 'default': True, 'help': ' ', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'require_accelerator': {'required': False, 'dest': 'trainer.require_accelerator', 'default': None, 'help': 'whether or not to require an accelerator (e.g. TPU or GPU).\ndefault depends on the platform: on macos False, else True', 'type': typing.Optional[bool]}
DEBUG:draccus.wrappers.docstring:Warning: Unable to parse attribute docstring:     @property
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'shutdown_at_exit': {'required': False, 'dest': 'trainer.shutdown_at_exit', 'default': False, 'help': 'whether or not to shutdown the tpu at exit. If a float, shutdown after that many seconds. True = 5 minutes', 'type': typing.Union[bool, float]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'max_tune_length': {'required': False, 'dest': 'max_tune_length', 'default': 2048, 'help': 'maximum length of the input to the model during tuning', 'type': <class 'int'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'train_data': {'required': False, 'dest': 'train_data', 'default': 'tatsu-lab/alpaca', 'help': 'Path to the training data, or huggingface dataset name.', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'train_data_cache_dir': {'required': False, 'dest': 'train_data_cache_dir', 'default': 'cache/', 'help': 'Path to cache the tokenized data. can be gcs', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'eval_data': {'required': False, 'dest': 'eval_data', 'default': None, 'help': 'Path to the training data, or huggingface dataset name.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'eval_data_cache_dir': {'required': False, 'dest': 'eval_data_cache_dir', 'default': 'cache/', 'help': 'Path to cache the tokenized data. can be gcs', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'model_name_or_path': {'required': False, 'dest': 'model_name_or_path', 'default': 'meta-llama/Llama-2-7b-hf', 'help': ' ', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'tokenizer_name_or_path': {'required': False, 'dest': 'tokenizer_name_or_path', 'default': 'meta-llama/Llama-2-7b-hf', 'help': ' ', 'type': <class 'str'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'trust_remote_code': {'required': False, 'dest': 'trust_remote_code', 'default': False, 'help': 'Trust remote code when loading from HuggingFace checkpoints.', 'type': <class 'bool'>}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'model_cache_dir': {'required': False, 'dest': 'model_cache_dir', 'default': None, 'help': 'Path to cache the model. must be local.', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'hf_save_path': {'required': False, 'dest': 'hf_save_path', 'default': 'alpaca_hf_ckpts', 'help': 'Path to save the HuggingFace checkpoint, can be gcs', 'type': typing.Optional[str]}
DEBUG:draccus.wrappers.field_wrapper:Arg options for field 'save_freq': {'required': False, 'dest': 'save_freq', 'default': None, 'type': typing.Optional[int]}
DEBUG:draccus.argparsing:
POST PROCESSING

DEBUG:draccus.argparsing:(raw) parsed args: Namespace(hf_save_path='/n/netscratch/amin_lab/Lab/slim/STP/storage/SFT', train_data='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/mathlib_leanworkbook.json', train_data_cache_dir='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/mathlib_leanworkbook_cache', eval_data='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/eval.json', eval_data_cache_dir='/n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/eval_cache', **{'trainer.checkpointer.base_path': '/n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt'})
DEBUG:draccus.parsers.decoding:from_dict for <class '__main__.TrainArgs'>
DEBUG:draccus.parsers.decoding:Decode name = optimizer, type = <class 'levanter.optim.config.OptimizerConfig'>
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.optim.config.AdamConfig'>
DEBUG:draccus.parsers.decoding:Decode name = learning_rate, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = weight_decay, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = min_lr_ratio, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = warmup, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = beta1, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = beta2, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = epsilon, type = <class 'float'>
DEBUG:draccus.parsers.decoding:Decode name = trainer, type = <class 'levanter.trainer.TrainerConfig'>
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.trainer.TrainerConfig'>
DEBUG:draccus.parsers.decoding:Decode name = mp, type = <class 'jmp._src.policy.Policy'>
DEBUG:draccus.parsers.decoding:Decode name = tracker, type = typing.Union[levanter.tracker.tracker.TrackerConfig, typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Union[levanter.tracker.tracker.TrackerConfig, typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]]
DEBUG:draccus.parsers.decoding:Decoding a Tuple field: typing.Tuple[levanter.tracker.tracker.TrackerConfig, ...]
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.tracker.wandb.WandbConfig'>
DEBUG:draccus.parsers.decoding:Decode name = project, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = name, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = tags, type = typing.List[str]
DEBUG:draccus.parsers.decoding:Decoding a List field: typing.List[str]
DEBUG:draccus.parsers.decoding:Decode name = tensor_parallel_axes, type = typing.Optional[typing.List[str]]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Optional[typing.List[str]]
DEBUG:draccus.parsers.decoding:Decode name = train_batch_size, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = per_device_parallelism, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = per_device_eval_parallelism, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = num_train_steps, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = steps_per_eval, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = checkpointer, type = <class 'levanter.checkpoint.CheckpointerConfig'>
DEBUG:draccus.parsers.decoding:from_dict for <class 'levanter.checkpoint.CheckpointerConfig'>
DEBUG:draccus.parsers.decoding:Decode name = base_path, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = max_tune_length, type = <class 'int'>
DEBUG:draccus.parsers.decoding:Decode name = train_data, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = train_data_cache_dir, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = eval_data, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = eval_data_cache_dir, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = model_name_or_path, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = tokenizer_name_or_path, type = <class 'str'>
DEBUG:draccus.parsers.decoding:Decode name = trust_remote_code, type = <class 'bool'>
DEBUG:draccus.parsers.decoding:Decode name = hf_save_path, type = typing.Optional[str]
DEBUG:draccus.parsers.decoding:Decode name = save_freq, type = typing.Optional[int]
DEBUG:draccus.parsers.decoding:Decoding a Union field: typing.Optional[int]
DEBUG:jax._src.clusters.cluster:Initializing distributed JAX environment via SlurmCluster
INFO:jax._src.distributed:JAX distributed initialized with visible devices: 0,1,2,3
INFO:jax._src.distributed:Starting JAX distributed service on [::]:61709
INFO:jax._src.distributed:Connecting to JAX distributed service on holygpu8a22404:61709
DEBUG:jax._src.xla_bridge:No jax_plugins namespace packages available
DEBUG:jax._src.xla_bridge:Initializing backend 'cpu'
DEBUG:jax._src.xla_bridge:Backend 'cpu' initialized
DEBUG:jax._src.xla_bridge:Initializing backend 'cuda'
DEBUG:jax._src.xla_bridge:Backend 'cuda' initialized
DEBUG:jax._src.xla_bridge:Initializing backend 'rocm'
DEBUG:jaxlib.xla_client:Custom call handler for CUDA is already register. Will not register a new one
DEBUG:jaxlib.xla_client:Custom call handler for ROCM is already register. Will not register a new one
INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
DEBUG:jax._src.xla_bridge:Initializing backend 'tpu'
INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
INFO:levanter.distributed:Initialized jax.distributed with 4 devices, 1 processes, coordinator_address=holygpu8a22404:61709, process_id=None, my device_ids=[0, 1, 2, 3].
DEBUG:jax._src.dispatch:Finished tracing + transforming convert_element_type for pjit in 0.0004355907440185547 sec
DEBUG:jax._src.interpreters.pxla:Compiling convert_element_type with global shapes and types [ShapedArray(int32[])]. Argument mapping: [UnspecifiedValue].
DEBUG:jax._src.dispatch:Finished jaxpr to MLIR module conversion jit(convert_element_type) in 0.09948897361755371 sec
DEBUG:jax._src.compiler:get_compile_options: num_replicas=1 num_partitions=1 device_assignment=[[cuda(id=0)]]
DEBUG:jax._src.compiler:get_compile_options XLA-AutoFDO profile: using XLA-AutoFDO profile version -1
DEBUG:jax._src.cache_key:get_cache_key hash of serialized computation: aaf26a1934941f9d5fc23bdd157aef9ad1e5b44e65088cf0f5026039585eb737
DEBUG:jax._src.cache_key:get_cache_key hash after serializing computation: aaf26a1934941f9d5fc23bdd157aef9ad1e5b44e65088cf0f5026039585eb737
DEBUG:jax._src.cache_key:get_cache_key hash of serialized jax_lib version: 93d9f249493a97c6a6b25282a73d3b88948ba77ae0f96ace478fafc61ea5e60a
DEBUG:jax._src.cache_key:get_cache_key hash after serializing jax_lib version: e7361916a5017f57eecdfe1d12edd043b599916dc09f6e68d252c2af2b9bece8
DEBUG:jax._src.cache_key:get_cache_key hash of serialized XLA flags: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
DEBUG:jax._src.cache_key:get_cache_key hash after serializing XLA flags: e7361916a5017f57eecdfe1d12edd043b599916dc09f6e68d252c2af2b9bece8
DEBUG:jax._src.cache_key:get_cache_key hash of serialized compile_options: 9bd5e65cbfe093c53b1a2c63e42e7494a6f2a4a29438cb64a4f455f096c4a5dd
DEBUG:jax._src.cache_key:get_cache_key hash after serializing compile_options: c2aa6cb924f759bf83a41328985b0416ed6ae309c3bc48689b30da626aee3a86
DEBUG:jax._src.cache_key:get_cache_key hash of serialized accelerator_config: b1c6929dcd3df3697abc2a954fe8aa70675c058e78f92731c190609e0c87a45d
DEBUG:jax._src.cache_key:get_cache_key hash after serializing accelerator_config: 036d1006ad4d161523ea21ff36e19feb2b734c5999b01db3c716afc97d57d02d
DEBUG:jax._src.cache_key:get_cache_key hash of serialized compression: 5c4a59db52b7103852ed48a22fcd2cf336a48c7a4de3211294af3477ef82f814
DEBUG:jax._src.cache_key:get_cache_key hash after serializing compression: 30c09a09479313d5ed7f4fb6fc04cd92f9dc2e1c2de283a7185b2441a5af5478
DEBUG:jax._src.cache_key:get_cache_key hash of serialized custom_hook: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
DEBUG:jax._src.cache_key:get_cache_key hash after serializing custom_hook: 30c09a09479313d5ed7f4fb6fc04cd92f9dc2e1c2de283a7185b2441a5af5478
DEBUG:jax._src.compilation_cache:get_executable_and_time: cache is disabled/not initialized
DEBUG:jax._src.compiler:Not writing persistent cache entry for 'jit_convert_element_type' because it took < 1.00 seconds to compile (0.29s)
DEBUG:jax._src.dispatch:Finished XLA compilation of jit(convert_element_type) in 0.3004631996154785 sec
DEBUG:jax._src.dispatch:Finished tracing + transforming _reduce_sum for pjit in 0.0023033618927001953 sec
DEBUG:jax._src.dispatch:Finished tracing + transforming _psum for pjit in 0.0029549598693847656 sec
DEBUG:jax._src.interpreters.pxla:Compiling _psum with global shapes and types [ShapedArray(int32[1])]. Argument mapping: [GSPMDSharding({replicated})].
DEBUG:jax._src.dispatch:Finished jaxpr to MLIR module conversion jit(_psum) in 0.013889074325561523 sec
DEBUG:jax._src.compiler:get_compile_options: num_replicas=1 num_partitions=4 device_assignment=[[cuda(id=0) cuda(id=1) cuda(id=2) cuda(id=3)]]
DEBUG:jax._src.compiler:get_compile_options XLA-AutoFDO profile: using XLA-AutoFDO profile version -1
DEBUG:jax._src.cache_key:get_cache_key hash of serialized computation: 944930179157a8cc8ccfc63c7b0b3925c9c20325812849965d040aa97bb5256d
DEBUG:jax._src.cache_key:get_cache_key hash after serializing computation: 944930179157a8cc8ccfc63c7b0b3925c9c20325812849965d040aa97bb5256d
DEBUG:jax._src.cache_key:get_cache_key hash of serialized jax_lib version: 93d9f249493a97c6a6b25282a73d3b88948ba77ae0f96ace478fafc61ea5e60a
DEBUG:jax._src.cache_key:get_cache_key hash after serializing jax_lib version: 4ff83414689c5d0255f8f315e0b9ca1264a2b829b72cf59224ce2c08b694811f
DEBUG:jax._src.cache_key:get_cache_key hash of serialized XLA flags: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
DEBUG:jax._src.cache_key:get_cache_key hash after serializing XLA flags: 4ff83414689c5d0255f8f315e0b9ca1264a2b829b72cf59224ce2c08b694811f
DEBUG:jax._src.cache_key:get_cache_key hash of serialized compile_options: e18a2ba9658a975f217482886cf9b2785a41c3f9dfb1a09ca6edc80effc68ecb
DEBUG:jax._src.cache_key:get_cache_key hash after serializing compile_options: fa2ce0c2af0ccfee4d021cb5eb14413be166f1ef70ec06d9384395b5f57d9518
DEBUG:jax._src.cache_key:get_cache_key hash of serialized accelerator_config: b1c6929dcd3df3697abc2a954fe8aa70675c058e78f92731c190609e0c87a45d
DEBUG:jax._src.cache_key:get_cache_key hash after serializing accelerator_config: 7e3a92e470172fa049e5dcfce91639da2de78b5d84a368677c5ed2d3a4b7a087
DEBUG:jax._src.cache_key:get_cache_key hash of serialized compression: 5c4a59db52b7103852ed48a22fcd2cf336a48c7a4de3211294af3477ef82f814
DEBUG:jax._src.cache_key:get_cache_key hash after serializing compression: 53022132e6e04d863e100ff9172ddbe9c5b5a9195bb42f8b6c14431657007b03
DEBUG:jax._src.cache_key:get_cache_key hash of serialized custom_hook: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
DEBUG:jax._src.cache_key:get_cache_key hash after serializing custom_hook: 53022132e6e04d863e100ff9172ddbe9c5b5a9195bb42f8b6c14431657007b03
DEBUG:jax._src.compilation_cache:get_executable_and_time: cache is disabled/not initialized
DEBUG:jax._src.compiler:Not writing persistent cache entry for 'jit__psum' because it took < 1.00 seconds to compile (0.03s)
DEBUG:jax._src.dispatch:Finished XLA compilation of jit(_psum) in 0.03480696678161621 sec
INFO:levanter.trainer:Setting run id to tsw6rwex
2025-05-24T03:51:56 - 0 - levanter.tracker.wandb - wandb.py:200 - INFO :: Setting wandb code_dir to /n/netscratch/amin_lab/Lab/slim
wandb: Currently logged in as: slimbarkallah23 (slimbarkallah23-CentraleSupÃ©lec). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /n/netscratch/amin_lab/Lab/slim/STP/wandb/run-20250524_035158-tsw6rwex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deepseek-sft
wandb: â­ï¸ View project at https://wandb.ai/slimbarkallah23-CentraleSup%C3%A9lec/STP_deepseek_03
wandb: ðŸš€ View run at https://wandb.ai/slimbarkallah23-CentraleSup%C3%A9lec/STP_deepseek_03/runs/tsw6rwex
2025-05-24T03:52:03 - 0 - levanter.distributed - distributed.py:218 - INFO :: Auto-discovered ray address using JAX coordinator address: holygpu8a22404:61709
2025-05-24T03:52:03 - 0 - levanter.distributed - distributed.py:232 - INFO :: Starting ray head on port 61949. We are process the coordinator holygpu8a22404.
2025-05-24T03:52:03 - 0 - levanter.distributed - distributed.py:233 - INFO :: Starting ray head with num_cpus set to 64.
2025-05-24 03:52:05,276	INFO usage_lib.py:472 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2025-05-24 03:52:05,277	INFO scripts.py:767 -- [37mLocal node IP[39m: [1m10.31.146.126[22m
2025-05-24 03:52:07,191	SUCC scripts.py:804 -- [32m--------------------[39m
2025-05-24 03:52:07,191	SUCC scripts.py:805 -- [32mRay runtime started.[39m
2025-05-24 03:52:07,191	SUCC scripts.py:806 -- [32m--------------------[39m
2025-05-24 03:52:07,191	INFO scripts.py:808 -- [36mNext steps[39m
2025-05-24 03:52:07,191	INFO scripts.py:811 -- To add another node to this Ray cluster, run
2025-05-24 03:52:07,191	INFO scripts.py:814 -- [1m  ray start --address='10.31.146.126:61949'[22m
2025-05-24 03:52:07,191	INFO scripts.py:823 -- To connect to this Ray cluster:
2025-05-24 03:52:07,191	INFO scripts.py:825 -- [35mimport[39m[26m ray
2025-05-24 03:52:07,191	INFO scripts.py:826 -- ray[35m.[39m[26minit()
2025-05-24 03:52:07,191	INFO scripts.py:838 -- To submit a Ray job using the Ray Jobs CLI:
2025-05-24 03:52:07,191	INFO scripts.py:839 -- [1m  RAY_ADDRESS='http://10.31.146.126:8265' ray job submit --working-dir . -- python my_script.py[22m
2025-05-24 03:52:07,191	INFO scripts.py:848 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html 
2025-05-24 03:52:07,191	INFO scripts.py:852 -- for more information on submitting Ray jobs to the Ray cluster.
2025-05-24 03:52:07,191	INFO scripts.py:857 -- To terminate the Ray runtime, run
2025-05-24 03:52:07,191	INFO scripts.py:858 -- [1m  ray stop[22m
2025-05-24 03:52:07,191	INFO scripts.py:861 -- To view the status of the cluster, use
2025-05-24 03:52:07,191	INFO scripts.py:862 --   [1mray status[22m[26m
2025-05-24 03:52:07,191	INFO scripts.py:866 -- To monitor and debug Ray, view the dashboard at 
2025-05-24 03:52:07,191	INFO scripts.py:867 --   [1m10.31.146.126:8265[22m[26m
2025-05-24 03:52:07,191	INFO scripts.py:874 -- [4mIf connection to the dashboard fails, check your firewall settings and network configuration.[24m
2025-05-24T03:52:07 - 0 - levanter.distributed - distributed.py:252 - INFO :: Successfully started ray head on port 61949.
2025-05-24T03:52:07 - 0 - levanter.distributed - distributed.py:267 - INFO :: ray.init(address='holygpu8a22404:61949', namespace='levanter', **{})
2025-05-24 03:52:07,361	INFO worker.py:1596 -- Connecting to existing Ray cluster at address: holygpu8a22404:61949...
2025-05-24 03:52:07,368	INFO worker.py:1772 -- Connected to Ray cluster. View the dashboard at [1m[32mhttp://10.31.146.126:8265 [39m[22m
2025-05-24T03:52:09 - 0 - __main__ - weighted_lm.py:183 - INFO :: Added 2 new tokens
2025-05-24T03:52:11 - 0 - __main__ - weighted_lm.py:189 - WARNING :: The tokenizers appear to be different. You may want to check this.
2025-05-24T03:52:11 - 0 - levanter.tracker.wandb - wandb.py:200 - INFO :: Setting wandb code_dir to /n/netscratch/amin_lab/Lab/slim
2025-05-24T03:52:11 - 0 - levanter.tracker.wandb - wandb.py:200 - INFO :: Setting wandb code_dir to /n/netscratch/amin_lab/Lab/slim
train:   0%|          | 0/230 [00:00<?, ?it/s]2025-05-24T03:52:12 - 0 - __main__ - weighted_lm.py:205 - INFO :: Loading training data.
2025-05-24T03:52:12 - 0 - levanter.data.shard_cache - shard_cache.py:1606 - INFO :: Loading cache from /n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/mathlib_leanworkbook_cache
2025-05-24T03:52:16 - 0 - __main__ - weighted_lm.py:209 - INFO :: Done loading training data.
2025-05-24T03:52:16 - 0 - __main__ - weighted_lm.py:216 - INFO :: Loading pretrained model from deepseek-ai/DeepSeek-Prover-V1.5-SFT

Loading weights:   0%|          | 0/116 [00:00<?, ?it/s][A[36m(ChunkCacheBuilder pid=2226636)[0m 2025-05-24 03:52:20,712 - levanter.data.shard_cache.builder::SFT/mathlib_leanworkbook_cache - INFO - Starting cache build for 1 shards

Loading weights:   2%|â–         | 2/116 [00:04<04:18,  2.27s/it][A
Loading weights:   3%|â–Ž         | 3/116 [00:06<03:41,  1.96s/it][A
Loading weights:   3%|â–Ž         | 4/116 [00:07<03:17,  1.76s/it][A
Loading weights:   5%|â–Œ         | 6/116 [00:08<01:52,  1.03s/it][A
Loading weights:   6%|â–Œ         | 7/116 [00:08<01:40,  1.08it/s][A
Loading weights:   7%|â–‹         | 8/116 [00:09<01:28,  1.22it/s][A
Loading weights:   9%|â–Š         | 10/116 [00:13<02:31,  1.43s/it][A
Loading weights:   9%|â–‰         | 11/116 [00:15<02:36,  1.49s/it][A
Loading weights:  10%|â–ˆ         | 12/116 [00:16<02:35,  1.50s/it][A
Loading weights:  12%|â–ˆâ–        | 14/116 [00:17<01:44,  1.02s/it][A
Loading weights:  13%|â–ˆâ–Ž        | 15/116 [00:18<01:36,  1.05it/s][A
Loading weights:  14%|â–ˆâ–        | 16/116 [00:18<01:25,  1.17it/s][A
Loading weights:  15%|â–ˆâ–        | 17/116 [00:19<01:16,  1.30it/s][A
Loading weights:  16%|â–ˆâ–‹        | 19/116 [00:23<02:14,  1.38s/it][A
Loading weights:  17%|â–ˆâ–‹        | 20/116 [00:25<02:22,  1.49s/it][A
Loading weights:  18%|â–ˆâ–Š        | 21/116 [00:27<02:20,  1.48s/it][A
Loading weights:  20%|â–ˆâ–‰        | 23/116 [00:27<01:33,  1.00s/it][A
Loading weights:  21%|â–ˆâ–ˆ        | 24/116 [00:28<01:24,  1.09it/s][A
Loading weights:  22%|â–ˆâ–ˆâ–       | 25/116 [00:29<01:17,  1.17it/s][A
Loading weights:  22%|â–ˆâ–ˆâ–       | 26/116 [00:29<01:09,  1.29it/s][A
Loading weights:  24%|â–ˆâ–ˆâ–       | 28/116 [00:34<02:00,  1.37s/it][A
Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 29/116 [00:35<02:01,  1.40s/it][A
Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 30/116 [00:36<02:00,  1.40s/it][A
Loading weights:  28%|â–ˆâ–ˆâ–Š       | 32/116 [00:37<01:20,  1.04it/s][A
Loading weights:  28%|â–ˆâ–ˆâ–Š       | 33/116 [00:38<01:13,  1.13it/s][A
Loading weights:  29%|â–ˆâ–ˆâ–‰       | 34/116 [00:38<01:05,  1.25it/s][A
Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 35/116 [00:39<01:00,  1.35it/s][A
Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 37/116 [00:43<01:46,  1.35s/it][A
Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 38/116 [00:45<01:47,  1.38s/it][A
Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 39/116 [00:46<01:47,  1.40s/it][A
Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 41/116 [00:47<01:11,  1.05it/s][A
Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 42/116 [00:47<01:05,  1.14it/s][A
Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 43/116 [00:48<00:58,  1.25it/s][A
Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 44/116 [00:49<00:53,  1.36it/s][A2025-05-24T03:53:10 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 1 | Docs: 8192

Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 46/116 [00:53<01:35,  1.36s/it][A
Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 47/116 [00:55<01:37,  1.42s/it][A
Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/116 [00:56<01:36,  1.43s/it][A
Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 50/116 [00:57<01:04,  1.02it/s][A
Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 51/116 [00:57<00:58,  1.12it/s][A
Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 52/116 [00:58<00:51,  1.24it/s][A
Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 53/116 [00:58<00:46,  1.37it/s][A
Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 55/116 [01:03<01:21,  1.34s/it][A
Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 56/116 [01:04<01:24,  1.40s/it][A
Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 57/116 [01:06<01:23,  1.41s/it][A
Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 59/116 [01:07<00:55,  1.02it/s][A
Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 60/116 [01:07<00:52,  1.06it/s][A
Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 61/116 [01:08<00:46,  1.19it/s][A
Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 62/116 [01:08<00:40,  1.32it/s][A
Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 64/116 [01:13<01:12,  1.39s/it][A
Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 65/116 [01:14<01:12,  1.42s/it][A2025-05-24T03:53:33 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 2 | Docs: 16384

Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 66/116 [01:16<01:11,  1.42s/it][A
Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 68/116 [01:16<00:46,  1.03it/s][A
Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 69/116 [01:17<00:42,  1.10it/s][A
Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 70/116 [01:18<00:37,  1.21it/s][A
Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 71/116 [01:18<00:33,  1.34it/s][A
Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 73/116 [01:23<00:59,  1.37s/it][A
Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 74/116 [01:24<00:59,  1.41s/it][A
Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 75/116 [01:26<00:57,  1.41s/it][A
Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 77/116 [01:26<00:37,  1.05it/s][A
Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 78/116 [01:27<00:33,  1.15it/s][A
Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 79/116 [01:27<00:29,  1.27it/s][A
Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 80/116 [01:28<00:25,  1.39it/s][A
Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 82/116 [01:32<00:46,  1.37s/it][A
Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 83/116 [01:34<00:46,  1.42s/it][A
Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 84/116 [01:35<00:45,  1.43s/it][A2025-05-24T03:53:53 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 3 | Docs: 24576

Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 86/116 [01:36<00:28,  1.04it/s][A
Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 87/116 [01:37<00:25,  1.14it/s][A
Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 88/116 [01:37<00:22,  1.23it/s][A
Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 89/116 [01:38<00:19,  1.35it/s][A
Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 91/116 [01:42<00:33,  1.34s/it][A
Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 92/116 [01:44<00:34,  1.42s/it][A
Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 93/116 [01:45<00:32,  1.42s/it][A
Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 95/116 [01:46<00:20,  1.04it/s][A
Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 96/116 [01:47<00:18,  1.10it/s][A
Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 97/116 [01:47<00:15,  1.23it/s][A
Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 98/116 [01:48<00:13,  1.35it/s][A
Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 100/116 [01:52<00:21,  1.35s/it][A
Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 101/116 [01:54<00:21,  1.42s/it][A
Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 102/116 [01:55<00:19,  1.42s/it][A2025-05-24T03:54:13 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 4 | Docs: 32768

Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 104/116 [01:56<00:11,  1.03it/s][A
Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 105/116 [01:56<00:10,  1.08it/s][A
Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 106/116 [01:57<00:08,  1.20it/s][A
Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 107/116 [01:58<00:06,  1.32it/s][A
Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 109/116 [02:02<00:09,  1.36s/it][A
Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 110/116 [02:04<00:08,  1.46s/it][A
Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 111/116 [02:05<00:07,  1.47s/it][A
Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 113/116 [02:06<00:02,  1.02it/s][A
Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 114/116 [02:06<00:01,  1.11it/s][A
Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 115/116 [02:07<00:00,  1.24it/s][A
Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [02:08<00:00,  1.34it/s][ALoading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [02:08<00:00,  1.10s/it]

Loading weights:   0%|          | 0/157 [00:00<?, ?it/s][A2025-05-24T03:54:38 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 5 | Docs: 40960

Loading weights:   1%|          | 1/157 [00:13<35:15, 13.56s/it][A
Loading weights:   1%|â–         | 2/157 [00:26<34:48, 13.48s/it][A
Loading weights:   3%|â–Ž         | 4/157 [00:31<16:19,  6.40s/it][A
Loading weights:   3%|â–Ž         | 5/157 [00:32<12:26,  4.91s/it][A2025-05-24T03:54:59 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 6 | Docs: 49152

Loading weights:   4%|â–         | 6/157 [00:34<09:40,  3.84s/it][A
Loading weights:   5%|â–Œ         | 8/157 [00:35<05:30,  2.22s/it][A
Loading weights:   6%|â–Œ         | 9/157 [00:35<04:30,  1.83s/it][A
Loading weights:   6%|â–‹         | 10/157 [00:36<03:38,  1.49s/it][A
Loading weights:   7%|â–‹         | 11/157 [00:36<02:59,  1.23s/it][A
Loading weights:   8%|â–Š         | 13/157 [00:41<03:59,  1.67s/it][A
Loading weights:   9%|â–‰         | 14/157 [00:42<03:52,  1.63s/it][A
Loading weights:  10%|â–‰         | 15/157 [00:44<03:44,  1.58s/it][A
Loading weights:  11%|â–ˆ         | 17/157 [00:44<02:29,  1.07s/it][A
Loading weights:  11%|â–ˆâ–        | 18/157 [00:45<02:15,  1.03it/s][A
Loading weights:  12%|â–ˆâ–        | 19/157 [00:46<01:59,  1.16it/s][A
Loading weights:  13%|â–ˆâ–Ž        | 20/157 [00:46<01:47,  1.27it/s][A
Loading weights:  14%|â–ˆâ–        | 22/157 [00:51<03:11,  1.42s/it][A2025-05-24T03:55:18 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 7 | Docs: 57344

Loading weights:  15%|â–ˆâ–        | 23/157 [00:52<03:17,  1.47s/it][A
Loading weights:  15%|â–ˆâ–Œ        | 24/157 [00:54<03:15,  1.47s/it][A
Loading weights:  17%|â–ˆâ–‹        | 26/157 [00:55<02:18,  1.05s/it][A
Loading weights:  17%|â–ˆâ–‹        | 27/157 [00:56<02:10,  1.00s/it][A
Loading weights:  18%|â–ˆâ–Š        | 28/157 [00:56<01:58,  1.09it/s][A
Loading weights:  18%|â–ˆâ–Š        | 29/157 [00:57<01:43,  1.23it/s][A
Loading weights:  20%|â–ˆâ–‰        | 31/157 [01:01<02:56,  1.40s/it][A
Loading weights:  20%|â–ˆâ–ˆ        | 32/157 [01:03<03:00,  1.45s/it][A
Loading weights:  21%|â–ˆâ–ˆ        | 33/157 [01:04<02:59,  1.45s/it][A
Loading weights:  22%|â–ˆâ–ˆâ–       | 35/157 [01:05<02:00,  1.01it/s][A
Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 36/157 [01:06<01:49,  1.10it/s][A
Loading weights:  24%|â–ˆâ–ˆâ–Ž       | 37/157 [01:06<01:37,  1.23it/s][A
Loading weights:  24%|â–ˆâ–ˆâ–       | 38/157 [01:07<01:27,  1.36it/s][A
Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 40/157 [01:11<02:38,  1.36s/it][A
Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 41/157 [01:12<02:41,  1.39s/it][A2025-05-24T03:55:39 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 8 | Docs: 65536

Loading weights:  27%|â–ˆâ–ˆâ–‹       | 42/157 [01:14<02:41,  1.40s/it][A
Loading weights:  28%|â–ˆâ–ˆâ–Š       | 44/157 [01:15<01:48,  1.04it/s][A
Loading weights:  29%|â–ˆâ–ˆâ–Š       | 45/157 [01:15<01:41,  1.11it/s][A
Loading weights:  29%|â–ˆâ–ˆâ–‰       | 46/157 [01:16<01:30,  1.23it/s][A
Loading weights:  30%|â–ˆâ–ˆâ–‰       | 47/157 [01:16<01:21,  1.35it/s][A
Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 49/157 [01:21<02:26,  1.36s/it][A
Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 50/157 [01:22<02:30,  1.40s/it][A
Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 51/157 [01:24<02:29,  1.41s/it][A
Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 53/157 [01:24<01:39,  1.04it/s][A
Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 54/157 [01:25<01:32,  1.11it/s][A
Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 55/157 [01:26<01:22,  1.24it/s][A
Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/157 [01:26<01:14,  1.36it/s][A
Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 58/157 [01:30<02:12,  1.34s/it][A
Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 59/157 [01:32<02:17,  1.40s/it][A2025-05-24T03:55:59 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 9 | Docs: 73728

Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/157 [01:34<02:16,  1.41s/it][A
Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 62/157 [01:34<01:31,  1.04it/s][A
Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 63/157 [01:35<01:24,  1.12it/s][A
Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 64/157 [01:35<01:15,  1.24it/s][A
Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 65/157 [01:36<01:07,  1.36it/s][A
Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 67/157 [01:40<01:59,  1.33s/it][A
Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/157 [01:42<02:03,  1.39s/it][A
Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 69/157 [01:43<02:03,  1.40s/it][A
Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 71/157 [01:44<01:21,  1.06it/s][A
Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/157 [01:45<01:16,  1.11it/s][A
Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 73/157 [01:45<01:08,  1.23it/s][A
Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/157 [01:46<01:01,  1.35it/s][A
Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/157 [01:50<01:53,  1.40s/it][A
Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 77/157 [01:52<01:54,  1.44s/it][A
Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 78/157 [01:53<01:53,  1.44s/it][A
Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/157 [01:54<01:14,  1.03it/s][A2025-05-24T03:56:20 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 10 | Docs: 81920

Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 81/157 [01:55<01:11,  1.07it/s][A
Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/157 [01:55<01:03,  1.19it/s][A
Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 83/157 [01:56<00:56,  1.31it/s][A
Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 84/157 [01:56<00:51,  1.43it/s][A
Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 86/157 [02:01<01:36,  1.36s/it][A
Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 87/157 [02:02<01:39,  1.42s/it][A
Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 88/157 [02:04<01:37,  1.42s/it][A
Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/157 [02:04<01:04,  1.05it/s][A
Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 91/157 [02:05<00:58,  1.12it/s][A
Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 92/157 [02:06<00:52,  1.23it/s][A
Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 93/157 [02:06<00:47,  1.35it/s][A
Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 95/157 [02:10<01:22,  1.33s/it][A
Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 96/157 [02:12<01:24,  1.39s/it][A
Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 97/157 [02:13<01:23,  1.40s/it][A
Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 99/157 [02:14<00:55,  1.05it/s][A
Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/157 [02:15<00:50,  1.13it/s][A
Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 101/157 [02:15<00:45,  1.23it/s][A
Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 102/157 [02:16<00:40,  1.36it/s][A2025-05-24T03:56:46 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 11 | Docs: 90112

Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 104/157 [02:20<01:12,  1.36s/it][A
Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 105/157 [02:22<01:12,  1.39s/it][A
Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 106/157 [02:23<01:11,  1.40s/it][A
Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 108/157 [02:24<00:47,  1.04it/s][A
Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 109/157 [02:24<00:42,  1.13it/s][A
Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 110/157 [02:25<00:37,  1.26it/s][A
Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 111/157 [02:25<00:33,  1.39it/s][A
Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 112/157 [02:26<00:24,  1.81it/s][A
Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 113/157 [02:30<01:11,  1.63s/it][A
Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 114/157 [02:32<01:10,  1.63s/it][A
Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 115/157 [02:33<01:05,  1.57s/it][A
Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 117/157 [02:34<00:40,  1.00s/it][A
Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 118/157 [02:34<00:36,  1.07it/s][A
Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 119/157 [02:35<00:31,  1.21it/s][A
Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 120/157 [02:35<00:27,  1.34it/s][A2025-05-24T03:57:05 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 12 | Docs: 98304

Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 122/157 [02:40<00:48,  1.38s/it][A
Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 123/157 [02:42<00:49,  1.46s/it][A
Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 124/157 [02:43<00:47,  1.45s/it][A
Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 126/157 [02:44<00:30,  1.03it/s][A
Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 127/157 [02:44<00:28,  1.05it/s][A
Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 128/157 [02:45<00:24,  1.18it/s][A
Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 129/157 [02:46<00:21,  1.32it/s][A
Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 131/157 [02:50<00:36,  1.42s/it][A
Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 132/157 [02:52<00:37,  1.48s/it][A
Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 133/157 [02:53<00:35,  1.48s/it][A
Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 135/157 [02:54<00:23,  1.05s/it][A
Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 136/157 [02:55<00:20,  1.00it/s][A
Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 137/157 [02:56<00:17,  1.14it/s][A
Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 138/157 [02:56<00:14,  1.27it/s][A2025-05-24T03:57:26 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 13 | Docs: 106496

Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 140/157 [03:01<00:23,  1.41s/it][A
Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 141/157 [03:02<00:23,  1.46s/it][A
Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 142/157 [03:04<00:21,  1.45s/it][A
Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 144/157 [03:04<00:12,  1.00it/s][A
Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 145/157 [03:05<00:10,  1.09it/s][A
Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 146/157 [03:05<00:09,  1.22it/s][A
Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 147/157 [03:06<00:07,  1.33it/s][A
Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 149/157 [03:10<00:11,  1.38s/it][A
Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 150/157 [03:12<00:09,  1.42s/it][A
Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 151/157 [03:13<00:08,  1.42s/it][A
Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 153/157 [03:14<00:03,  1.01it/s][A
Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 154/157 [03:15<00:02,  1.09it/s][A
Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 155/157 [03:15<00:01,  1.22it/s][A
Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 156/157 [03:16<00:00,  1.33it/s][ALoading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [03:16<00:00,  1.25s/it]
2025-05-24T03:57:42 - 0 - levanter.compat.hf_checkpoints - hf_checkpoints.py:559 - INFO :: Resizing model from 102400 to 100004 to match tokenizer vocab size
2025-05-24T03:57:42 - 0 - levanter.compat.hf_checkpoints - hf_checkpoints.py:559 - INFO :: Resizing model from 102400 to 100004 to match tokenizer vocab size
/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/jax/_src/interpreters/mlir.py:913: UserWarning: Some donated buffers were not usable: ShapedArray(float32[102400,1024]), ShapedArray(float32[102400,1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,2752]), ShapedArray(float32[11008,1024]), ShapedArray(float32[11008,1024]), ShapedArray(float32[1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]).
See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.
  warnings.warn("Some donated buffers were not usable:"
2025-05-24T03:57:43 - 0 - __main__ - weighted_lm.py:227 - INFO :: Loading eval data.
2025-05-24T03:57:43 - 0 - levanter.data.shard_cache - shard_cache.py:1606 - INFO :: Loading cache from /n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/eval_cache
2025-05-24T03:57:45 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 14 | Docs: 114688
2025-05-24T03:57:49 - 0 - __main__ - weighted_lm.py:234 - INFO :: Done loading eval data.
2025-05-24T03:57:49 - 0 - __main__ - weighted_lm.py:242 - INFO :: Creating trainer state.
2025-05-24T03:57:49 - 0 - __main__ - weighted_lm.py:244 - INFO :: Done.
2025-05-24T03:57:49 - 0 - __main__ - weighted_lm.py:259 - INFO :: Starting training.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/models/attention.py:266: UserWarning: transformer_engine is not installed. Please install it to use NVIDIA's optimized fused attention.. Falling back to the reference implementation.
  warnings.warn(f"{msg}. Falling back to the reference implementation.")
/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/models/attention.py:266: UserWarning: transformer_engine is not installed. Please install it to use NVIDIA's optimized fused attention.. Falling back to the reference implementation.
  warnings.warn(f"{msg}. Falling back to the reference implementation.")
/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/models/attention.py:266: UserWarning: transformer_engine is not installed. Please install it to use NVIDIA's optimized fused attention.. Falling back to the reference implementation.
  warnings.warn(f"{msg}. Falling back to the reference implementation.")
[36m(ChunkCacheBuilder pid=2233528)[0m 2025-05-24 03:57:53,014 - levanter.data.shard_cache.builder::SFT/eval_cache - INFO - Starting cache build for 1 shards
/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/models/attention.py:266: UserWarning: transformer_engine is not installed. Please install it to use NVIDIA's optimized fused attention.. Falling back to the reference implementation.
  warnings.warn(f"{msg}. Falling back to the reference implementation.")
2025-05-24 03:57:56.660975: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below 38.09GiB (40903051777 bytes) by rematerialization; only reduced to 44.97GiB (48285919196 bytes), down from 45.09GiB (48420136984 bytes) originally
2025-05-24T03:58:08 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 15 | Docs: 122880
2025-05-24T03:58:35 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 16 | Docs: 131072
2025-05-24T03:59:12 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 17 | Docs: 139264
2025-05-24T03:59:35 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 18 | Docs: 147456
2025-05-24T03:59:53 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 19 | Docs: 155648
2025-05-24T04:00:17 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 20 | Docs: 163840
2025-05-24T04:00:32 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 21 | Docs: 172032
train:   0%|          | 1/230 [08:28<32:20:09, 508.34s/it]train:   0%|          | 1/230 [08:28<32:20:09, 508.34s/it, loss=0.434]
eval: 0it [00:00, ?it/s][A2025-05-24T04:00:40 - 0 - ShardCache.SFT/eval_cache - shard_cache.py:1680 - WARNING :: Invalid state waiting for chunk 0 for 0 seconds
2025-05-24T04:00:57 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 22 | Docs: 180224
2025-05-24T04:01:19 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 23 | Docs: 188416
2025-05-24T04:01:20 - 0 - ShardCache.SFT/eval_cache - shard_cache.py:1680 - WARNING :: Invalid state waiting for chunk 0 for 0 seconds
2025-05-24T04:01:38 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 24 | Docs: 196608
2025-05-24T04:02:00 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 25 | Docs: 204800
2025-05-24T04:02:00 - 0 - ShardCache.SFT/eval_cache - shard_cache.py:1680 - WARNING :: Invalid state waiting for chunk 0 for 40 seconds
2025-05-24T04:02:20 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 26 | Docs: 212992
2025-05-24T04:02:40 - 0 - ShardCache.SFT/eval_cache - shard_cache.py:1680 - WARNING :: Invalid state waiting for chunk 0 for 80 seconds
2025-05-24T04:02:41 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 27 | Docs: 221184
2025-05-24T04:02:58 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 28 | Docs: 229376
2025-05-24T04:03:08 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 1 | Docs: 4096
2025-05-24T04:03:08 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 1 | Chunks: 1 | Docs: 4096
2025-05-24T04:03:08 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 1 | Chunks: 1 | Docs: 4096
2025-05-24T04:03:08 - 0 - levanter.data.shard_cache - shard_cache.py:781 - INFO :: Cache creation finished
[36m(ChunkCacheBroker pid=2233365)[0m 2025-05-24 04:03:08,099 - levanter.data.shard_cache - INFO - Finalizing cache /n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/eval_cache...
2025-05-24T04:03:15 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 0 | Chunks: 29 | Docs: 235430
2025-05-24T04:03:15 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 1 | Chunks: 29 | Docs: 235430
2025-05-24T04:03:15 - 0 - levanter.data.shard_cache - shard_cache.py:774 - INFO ::  done: Shards: 1 | Chunks: 29 | Docs: 235430
2025-05-24T04:03:15 - 0 - levanter.data.shard_cache - shard_cache.py:781 - INFO :: Cache creation finished
[36m(ChunkCacheBroker pid=2226420)[0m 2025-05-24 04:03:15,197 - levanter.data.shard_cache - INFO - Finalizing cache /n/netscratch/amin_lab/Lab/slim/STP/storage/data/SFT/mathlib_leanworkbook_cache...
/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/models/attention.py:266: UserWarning: transformer_engine is not installed. Please install it to use NVIDIA's optimized fused attention.. Falling back to the reference implementation.
  warnings.warn(f"{msg}. Falling back to the reference implementation.")
/n/netscratch/amin_lab/Lab/slim/STP/levanter/src/levanter/models/attention.py:266: UserWarning: transformer_engine is not installed. Please install it to use NVIDIA's optimized fused attention.. Falling back to the reference implementation.
  warnings.warn(f"{msg}. Falling back to the reference implementation.")

eval: 1it [02:45, 165.63s/it][A
eval: 2it [02:48, 69.94s/it] [A
eval: 3it [02:50, 39.01s/it][A
eval: 4it [02:52, 24.48s/it][A
eval: 5it [02:55, 16.45s/it][A
eval: 6it [02:57, 11.61s/it][A
eval: 7it [02:59,  8.53s/it][A
eval: 8it [03:01,  6.52s/it][A
eval: 9it [03:04,  5.17s/it][A
eval: 10it [03:06,  4.26s/it][A
eval: 11it [03:08,  3.63s/it][A
eval: 12it [03:10,  3.20s/it][A
eval: 13it [03:12,  2.90s/it][A
eval: 14it [03:15,  2.69s/it][A
eval: 15it [03:17,  2.55s/it][A
eval: 16it [03:19,  2.45s/it][A
eval: 17it [03:21,  2.38s/it][A
eval: 18it [03:23,  2.33s/it][A
eval: 19it [03:26,  2.29s/it][A
eval: 20it [03:28,  2.27s/it][A
eval: 21it [03:30,  2.25s/it][A
eval: 22it [03:32,  2.24s/it][A
eval: 23it [03:35,  2.23s/it][A
eval: 24it [03:37,  2.23s/it][A
eval: 25it [03:39,  2.22s/it][A
eval: 26it [03:41,  2.22s/it][A
eval: 27it [03:43,  2.22s/it][A
eval: 28it [03:46,  2.22s/it][A
eval: 29it [03:48,  2.22s/it][A
eval: 30it [03:50,  2.22s/it][A
eval: 31it [03:52,  2.22s/it][A
eval: 32it [03:54,  2.22s/it][A
eval: 33it [03:57,  2.22s/it][A
eval: 34it [03:59,  2.22s/it][A
eval: 35it [04:01,  2.22s/it][A
eval: 36it [04:03,  2.22s/it][A
eval: 37it [04:06,  2.22s/it][A
eval: 38it [04:08,  2.22s/it][A
eval: 39it [04:10,  2.22s/it][A
eval: 40it [04:12,  2.22s/it][A
eval: 41it [04:14,  2.22s/it][A
eval: 42it [04:17,  2.22s/it][A
eval: 43it [04:19,  2.22s/it][A
eval: 44it [04:21,  2.22s/it][A
eval: 45it [04:23,  2.22s/it][A
eval: 46it [04:26,  2.22s/it][A
eval: 47it [04:28,  2.22s/it][A
eval: 48it [04:30,  2.22s/it][A
eval: 49it [04:32,  2.22s/it][A
eval: 50it [04:34,  2.22s/it][A
eval: 51it [04:37,  2.22s/it][A
eval: 52it [04:39,  2.22s/it][A
eval: 53it [04:41,  2.22s/it][A
eval: 54it [04:43,  2.22s/it][A
eval: 55it [04:46,  2.22s/it][A
eval: 56it [04:48,  2.22s/it][A
eval: 57it [04:50,  2.22s/it][A
eval: 58it [04:52,  2.22s/it][A
eval: 59it [04:54,  2.22s/it][A
eval: 60it [04:57,  2.22s/it][A
eval: 61it [04:59,  2.22s/it][A
eval: 62it [05:01,  2.22s/it][A
eval: 63it [05:03,  2.22s/it][A
eval: 64it [05:06,  2.22s/it][A
eval: 65it [05:08,  2.22s/it][A
eval: 66it [05:10,  2.22s/it][A
eval: 67it [05:12,  2.22s/it][A
eval: 68it [05:14,  2.22s/it][A
eval: 69it [05:17,  2.22s/it][A
eval: 70it [05:19,  2.22s/it][A
eval: 71it [05:21,  2.22s/it][A
eval: 72it [05:23,  2.22s/it][A
eval: 73it [05:25,  2.22s/it][A
eval: 74it [05:28,  2.22s/it][A
eval: 75it [05:30,  2.22s/it][A
eval: 76it [05:32,  2.22s/it][A
eval: 77it [05:34,  2.22s/it][A
eval: 78it [05:37,  2.22s/it][A
eval: 79it [05:39,  2.22s/it][A
eval: 80it [05:41,  2.22s/it][A
eval: 81it [05:43,  2.22s/it][A
eval: 82it [05:45,  2.22s/it][A
eval: 83it [05:48,  2.22s/it][A
eval: 84it [05:50,  2.22s/it][A
eval: 85it [05:52,  2.22s/it][A
eval: 86it [05:54,  2.22s/it][A
eval: 87it [05:57,  2.22s/it][A
eval: 88it [05:59,  2.22s/it][A
eval: 89it [06:01,  2.22s/it][A
eval: 90it [06:03,  2.22s/it][A
eval: 91it [06:05,  2.22s/it][A
eval: 92it [06:08,  2.22s/it][A
eval: 93it [06:10,  2.22s/it][A
eval: 94it [06:12,  2.22s/it][A
eval: 95it [06:14,  2.22s/it][A
eval: 96it [06:17,  2.22s/it][A
eval: 97it [06:19,  2.22s/it][A
eval: 98it [06:21,  2.22s/it][A
eval: 99it [06:23,  2.22s/it][A
eval: 100it [06:25,  2.22s/it][A
eval: 101it [06:28,  2.22s/it][A
eval: 102it [06:30,  2.22s/it][A
eval: 103it [06:32,  2.22s/it][A
eval: 104it [06:34,  2.22s/it][A
eval: 105it [06:37,  2.22s/it][A
eval: 106it [06:39,  2.22s/it][A
eval: 107it [06:41,  2.22s/it][A
eval: 108it [06:43,  2.22s/it][A
eval: 109it [06:45,  2.22s/it][A
eval: 110it [06:48,  2.22s/it][A
eval: 111it [06:50,  2.22s/it][A
eval: 112it [06:52,  2.22s/it][A
eval: 113it [06:54,  2.22s/it][A
eval: 114it [06:57,  2.22s/it][A
eval: 115it [06:59,  2.22s/it][A
eval: 116it [07:01,  2.22s/it][A
eval: 117it [07:03,  2.22s/it][A
eval: 118it [07:05,  2.23s/it][A
eval: 119it [07:08,  2.23s/it][A
eval: 120it [07:10,  2.23s/it][A
eval: 121it [07:12,  2.23s/it][A
eval: 122it [07:14,  2.23s/it][A
eval: 123it [07:17,  2.23s/it][A
eval: 124it [07:19,  2.23s/it][A
eval: 125it [07:21,  2.23s/it][A
eval: 126it [07:23,  2.23s/it][A
eval: 127it [07:25,  2.23s/it][A
eval: 128it [07:28,  2.23s/it][Aeval: 128it [07:28,  3.50s/it]
2025-05-24T04:08:08 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.266
2025-05-24T04:08:08 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.266
train:   1%|          | 2/230 [18:36<35:55:55, 567.35s/it, loss=0.434]train:   1%|          | 2/230 [18:36<35:55:55, 567.35s/it, loss=0.441]train:   1%|â–         | 3/230 [21:17<24:03:47, 381.62s/it, loss=0.441]train:   1%|â–         | 3/230 [21:17<24:03:47, 381.62s/it, loss=0.438]train:   2%|â–         | 4/230 [23:57<18:27:44, 294.09s/it, loss=0.438]train:   2%|â–         | 4/230 [23:57<18:27:44, 294.09s/it, loss=0.366]train:   2%|â–         | 5/230 [26:36<15:20:47, 245.54s/it, loss=0.366]train:   2%|â–         | 5/230 [26:36<15:20:47, 245.54s/it, loss=0.299]train:   3%|â–Ž         | 6/230 [29:16<13:27:05, 216.19s/it, loss=0.299]train:   3%|â–Ž         | 6/230 [29:16<13:27:05, 216.19s/it, loss=0.228]train:   3%|â–Ž         | 7/230 [31:55<12:14:15, 197.56s/it, loss=0.228]train:   3%|â–Ž         | 7/230 [31:55<12:14:15, 197.56s/it, loss=0.206]train:   3%|â–Ž         | 8/230 [34:34<11:25:42, 185.33s/it, loss=0.206]train:   3%|â–Ž         | 8/230 [34:34<11:25:42, 185.33s/it, loss=0.18] train:   4%|â–         | 9/230 [37:13<10:52:29, 177.15s/it, loss=0.18]train:   4%|â–         | 9/230 [37:13<10:52:29, 177.15s/it, loss=0.178]train:   4%|â–         | 10/230 [39:52<10:29:00, 171.55s/it, loss=0.178]train:   4%|â–         | 10/230 [39:52<10:29:00, 171.55s/it, loss=0.171]train:   5%|â–         | 11/230 [42:31<10:12:07, 167.70s/it, loss=0.171]train:   5%|â–         | 11/230 [42:31<10:12:07, 167.70s/it, loss=0.16] train:   5%|â–Œ         | 12/230 [45:10<9:59:35, 165.02s/it, loss=0.16] train:   5%|â–Œ         | 12/230 [45:10<9:59:35, 165.02s/it, loss=0.174]train:   6%|â–Œ         | 13/230 [47:49<9:50:09, 163.18s/it, loss=0.174]train:   6%|â–Œ         | 13/230 [47:49<9:50:09, 163.18s/it, loss=0.179]train:   6%|â–Œ         | 14/230 [50:28<9:42:51, 161.90s/it, loss=0.179]train:   6%|â–Œ         | 14/230 [50:28<9:42:51, 161.90s/it, loss=0.146]train:   7%|â–‹         | 15/230 [53:07<9:36:43, 160.95s/it, loss=0.146]train:   7%|â–‹         | 15/230 [53:07<9:36:43, 160.95s/it, loss=0.142]train:   7%|â–‹         | 16/230 [55:46<9:31:50, 160.33s/it, loss=0.142]train:   7%|â–‹         | 16/230 [55:46<9:31:50, 160.33s/it, loss=0.171]train:   7%|â–‹         | 17/230 [58:25<9:27:40, 159.91s/it, loss=0.171]train:   7%|â–‹         | 17/230 [58:25<9:27:40, 159.91s/it, loss=0.162]train:   8%|â–Š         | 18/230 [1:01:03<9:23:58, 159.62s/it, loss=0.162]train:   8%|â–Š         | 18/230 [1:01:03<9:23:58, 159.62s/it, loss=0.15] train:   8%|â–Š         | 19/230 [1:03:42<9:20:40, 159.43s/it, loss=0.15]train:   8%|â–Š         | 19/230 [1:03:42<9:20:40, 159.43s/it, loss=0.158]train:   9%|â–Š         | 20/230 [1:06:21<9:17:23, 159.26s/it, loss=0.158]train:   9%|â–Š         | 20/230 [1:06:21<9:17:23, 159.26s/it, loss=0.156]train:   9%|â–‰         | 21/230 [1:09:00<9:14:16, 159.12s/it, loss=0.156]train:   9%|â–‰         | 21/230 [1:09:00<9:14:16, 159.12s/it, loss=0.153]2025-05-24T05:01:12 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 20.
2025-05-24T05:01:12 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 20 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-20
2025-05-24T05:01:12 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-20 for step 20
2025-05-24T05:01:12 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T05:01:12 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T05:01:41 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0

eval: 0it [00:00, ?it/s][A
eval: 1it [00:03,  3.02s/it][A
eval: 2it [00:05,  2.58s/it][A
eval: 3it [00:07,  2.44s/it][A
eval: 4it [00:09,  2.37s/it][A
eval: 5it [00:12,  2.33s/it][A2025-05-24T05:01:55 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T05:01:55 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-20 for step 20
2025-05-24T05:01:55 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!

eval: 6it [00:14,  2.30s/it][A
eval: 7it [00:16,  2.29s/it][A
eval: 8it [00:18,  2.28s/it][A
eval: 9it [00:21,  2.27s/it][A
eval: 10it [00:23,  2.26s/it][A
eval: 11it [00:25,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:30,  2.26s/it][A
eval: 14it [00:32,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:39,  2.26s/it][A
eval: 18it [00:41,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:48,  2.26s/it][A
eval: 22it [00:50,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:57,  2.26s/it][A
eval: 26it [00:59,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:06,  2.26s/it][A
eval: 30it [01:08,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:15,  2.26s/it][A
eval: 34it [01:17,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:22,  2.26s/it][A
eval: 37it [01:24,  2.26s/it][A
eval: 38it [01:26,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:31,  2.26s/it][A
eval: 41it [01:33,  2.26s/it][A
eval: 42it [01:35,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:40,  2.26s/it][A
eval: 45it [01:42,  2.26s/it][A
eval: 46it [01:44,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:49,  2.26s/it][A
eval: 49it [01:51,  2.26s/it][A
eval: 50it [01:53,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:58,  2.26s/it][A
eval: 53it [02:00,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:07,  2.26s/it][A
eval: 57it [02:09,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:16,  2.26s/it][A
eval: 61it [02:18,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:25,  2.26s/it][A
eval: 65it [02:27,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:32,  2.26s/it][A
eval: 68it [02:34,  2.26s/it][A
eval: 69it [02:36,  2.26s/it][A
eval: 70it [02:38,  2.26s/it][A
eval: 71it [02:41,  2.26s/it][A
eval: 72it [02:43,  2.26s/it][A
eval: 73it [02:45,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:50,  2.36s/it][A
eval: 76it [02:52,  2.33s/it][A
eval: 77it [02:54,  2.31s/it][A
eval: 78it [02:57,  2.29s/it][A
eval: 79it [02:59,  2.28s/it][A
eval: 80it [03:01,  2.27s/it][A
eval: 81it [03:03,  2.27s/it][A
eval: 82it [03:06,  2.27s/it][A
eval: 83it [03:08,  2.26s/it][A
eval: 84it [03:10,  2.26s/it][A
eval: 85it [03:12,  2.26s/it][A
eval: 86it [03:15,  2.26s/it][A
eval: 87it [03:17,  2.26s/it][A
eval: 88it [03:19,  2.26s/it][A
eval: 89it [03:21,  2.26s/it][A
eval: 90it [03:24,  2.26s/it][A
eval: 91it [03:26,  2.26s/it][A
eval: 92it [03:28,  2.26s/it][A
eval: 93it [03:31,  2.26s/it][A
eval: 94it [03:33,  2.26s/it][A
eval: 95it [03:35,  2.26s/it][A
eval: 96it [03:37,  2.25s/it][A
eval: 97it [03:40,  2.25s/it][A
eval: 98it [03:42,  2.25s/it][A
eval: 99it [03:44,  2.25s/it][A
eval: 100it [03:46,  2.25s/it][A
eval: 101it [03:49,  2.25s/it][A
eval: 102it [03:51,  2.26s/it][A
eval: 103it [03:53,  2.26s/it][A
eval: 104it [03:55,  2.26s/it][A
eval: 105it [03:58,  2.26s/it][A
eval: 106it [04:00,  2.26s/it][A
eval: 107it [04:02,  2.26s/it][A
eval: 108it [04:04,  2.26s/it][A
eval: 109it [04:07,  2.26s/it][A
eval: 110it [04:09,  2.26s/it][A
eval: 111it [04:11,  2.26s/it][A
eval: 112it [04:13,  2.26s/it][A
eval: 113it [04:16,  2.26s/it][A
eval: 114it [04:18,  2.26s/it][A
eval: 115it [04:20,  2.26s/it][A
eval: 116it [04:22,  2.26s/it][A
eval: 117it [04:25,  2.26s/it][A
eval: 118it [04:27,  2.26s/it][A
eval: 119it [04:29,  2.26s/it][A
eval: 120it [04:31,  2.26s/it][A
eval: 121it [04:34,  2.26s/it][A
eval: 122it [04:36,  2.25s/it][A
eval: 123it [04:38,  2.25s/it][A
eval: 124it [04:40,  2.25s/it][A
eval: 125it [04:43,  2.25s/it][A
eval: 126it [04:45,  2.25s/it][A
eval: 127it [04:47,  2.25s/it][A
eval: 128it [04:49,  2.26s/it][Aeval: 128it [04:49,  2.27s/it]
2025-05-24T05:06:31 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.182
2025-05-24T05:06:31 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.182
train:  10%|â–‰         | 22/230 [1:16:58<14:42:57, 254.70s/it, loss=0.153]train:  10%|â–‰         | 22/230 [1:16:58<14:42:57, 254.70s/it, loss=0.145]train:  10%|â–ˆ         | 23/230 [1:19:37<12:59:44, 226.01s/it, loss=0.145]train:  10%|â–ˆ         | 23/230 [1:19:37<12:59:44, 226.01s/it, loss=0.143]train:  10%|â–ˆ         | 24/230 [1:22:16<11:46:46, 205.86s/it, loss=0.143]train:  10%|â–ˆ         | 24/230 [1:22:16<11:46:46, 205.86s/it, loss=0.123]train:  11%|â–ˆ         | 25/230 [1:24:54<10:55:07, 191.74s/it, loss=0.123]train:  11%|â–ˆ         | 25/230 [1:24:54<10:55:07, 191.74s/it, loss=0.161]train:  11%|â–ˆâ–        | 26/230 [1:27:33<10:18:14, 181.84s/it, loss=0.161]train:  11%|â–ˆâ–        | 26/230 [1:27:33<10:18:14, 181.84s/it, loss=0.151]train:  12%|â–ˆâ–        | 27/230 [1:30:12<9:51:41, 174.88s/it, loss=0.151] train:  12%|â–ˆâ–        | 27/230 [1:30:12<9:51:41, 174.88s/it, loss=0.135]train:  12%|â–ˆâ–        | 28/230 [1:32:51<9:32:35, 170.08s/it, loss=0.135]train:  12%|â–ˆâ–        | 28/230 [1:32:51<9:32:35, 170.08s/it, loss=0.143]train:  13%|â–ˆâ–Ž        | 29/230 [1:35:29<9:18:19, 166.67s/it, loss=0.143]train:  13%|â–ˆâ–Ž        | 29/230 [1:35:29<9:18:19, 166.67s/it, loss=0.149]train:  13%|â–ˆâ–Ž        | 30/230 [1:38:08<9:07:35, 164.28s/it, loss=0.149]train:  13%|â–ˆâ–Ž        | 30/230 [1:38:08<9:07:35, 164.28s/it, loss=0.135]train:  13%|â–ˆâ–Ž        | 31/230 [1:40:47<8:59:27, 162.65s/it, loss=0.135]train:  13%|â–ˆâ–Ž        | 31/230 [1:40:47<8:59:27, 162.65s/it, loss=0.146]train:  14%|â–ˆâ–        | 32/230 [1:43:26<8:52:57, 161.50s/it, loss=0.146]train:  14%|â–ˆâ–        | 32/230 [1:43:26<8:52:57, 161.50s/it, loss=0.142]train:  14%|â–ˆâ–        | 33/230 [1:46:05<8:47:35, 160.69s/it, loss=0.142]train:  14%|â–ˆâ–        | 33/230 [1:46:05<8:47:35, 160.69s/it, loss=0.151]train:  15%|â–ˆâ–        | 34/230 [1:48:43<8:43:06, 160.14s/it, loss=0.151]train:  15%|â–ˆâ–        | 34/230 [1:48:43<8:43:06, 160.14s/it, loss=0.137]train:  15%|â–ˆâ–Œ        | 35/230 [1:51:22<8:39:06, 159.72s/it, loss=0.137]train:  15%|â–ˆâ–Œ        | 35/230 [1:51:22<8:39:06, 159.72s/it, loss=0.134]train:  16%|â–ˆâ–Œ        | 36/230 [1:54:01<8:35:33, 159.45s/it, loss=0.134]train:  16%|â–ˆâ–Œ        | 36/230 [1:54:01<8:35:33, 159.45s/it, loss=0.132]train:  16%|â–ˆâ–Œ        | 37/230 [1:56:40<8:32:18, 159.26s/it, loss=0.132]train:  16%|â–ˆâ–Œ        | 37/230 [1:56:40<8:32:18, 159.26s/it, loss=0.143]train:  17%|â–ˆâ–‹        | 38/230 [1:59:19<8:29:10, 159.12s/it, loss=0.143]train:  17%|â–ˆâ–‹        | 38/230 [1:59:19<8:29:10, 159.12s/it, loss=0.127]train:  17%|â–ˆâ–‹        | 39/230 [2:01:57<8:26:17, 159.04s/it, loss=0.127]train:  17%|â–ˆâ–‹        | 39/230 [2:01:57<8:26:17, 159.04s/it, loss=0.135]train:  17%|â–ˆâ–‹        | 40/230 [2:04:36<8:23:31, 159.01s/it, loss=0.135]train:  17%|â–ˆâ–‹        | 40/230 [2:04:36<8:23:31, 159.01s/it, loss=0.142]train:  18%|â–ˆâ–Š        | 41/230 [2:07:15<8:20:39, 158.94s/it, loss=0.142]train:  18%|â–ˆâ–Š        | 41/230 [2:07:15<8:20:39, 158.94s/it, loss=0.134]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.30s/it][A
eval: 3it [00:06,  2.30s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.28s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.27s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:25,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:35,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:44,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:53,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.26s/it][A
eval: 61it [02:17,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:24,  2.26s/it][A
eval: 65it [02:26,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:31,  2.26s/it][A
eval: 68it [02:33,  2.26s/it][A
eval: 69it [02:35,  2.26s/it][A
eval: 70it [02:38,  2.26s/it][A
eval: 71it [02:40,  2.26s/it][A
eval: 72it [02:42,  2.26s/it][A
eval: 73it [02:45,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:49,  2.26s/it][A
eval: 76it [02:51,  2.26s/it][A
eval: 77it [02:54,  2.26s/it][A
eval: 78it [02:56,  2.26s/it][A
eval: 79it [02:58,  2.26s/it][A
eval: 80it [03:00,  2.26s/it][A
eval: 81it [03:03,  2.26s/it][A
eval: 82it [03:05,  2.26s/it][A
eval: 83it [03:07,  2.26s/it][A
eval: 84it [03:09,  2.26s/it][A
eval: 85it [03:12,  2.26s/it][A
eval: 86it [03:14,  2.26s/it][A
eval: 87it [03:16,  2.26s/it][A
eval: 88it [03:18,  2.26s/it][A
eval: 89it [03:21,  2.26s/it][A
eval: 90it [03:23,  2.26s/it][A
eval: 91it [03:25,  2.26s/it][A
eval: 92it [03:27,  2.26s/it][A
eval: 93it [03:30,  2.26s/it][A
eval: 94it [03:32,  2.26s/it][A
eval: 95it [03:34,  2.26s/it][A
eval: 96it [03:36,  2.26s/it][A
eval: 97it [03:39,  2.26s/it][A
eval: 98it [03:41,  2.26s/it][A
eval: 99it [03:43,  2.26s/it][A
eval: 100it [03:45,  2.26s/it][A
eval: 101it [03:48,  2.26s/it][A
eval: 102it [03:50,  2.26s/it][A
eval: 103it [03:52,  2.26s/it][A
eval: 104it [03:54,  2.26s/it][A
eval: 105it [03:57,  2.26s/it][A
eval: 106it [03:59,  2.26s/it][A
eval: 107it [04:01,  2.26s/it][A
eval: 108it [04:03,  2.26s/it][A
eval: 109it [04:06,  2.26s/it][A
eval: 110it [04:08,  2.26s/it][A
eval: 111it [04:10,  2.26s/it][A
eval: 112it [04:13,  2.26s/it][A
eval: 113it [04:15,  2.26s/it][A
eval: 114it [04:17,  2.26s/it][A
eval: 115it [04:19,  2.26s/it][A
eval: 116it [04:22,  2.26s/it][A
eval: 117it [04:24,  2.26s/it][A
eval: 118it [04:26,  2.26s/it][A
eval: 119it [04:28,  2.26s/it][A
eval: 120it [04:31,  2.26s/it][A
eval: 121it [04:33,  2.26s/it][A
eval: 122it [04:35,  2.25s/it][A
eval: 123it [04:37,  2.25s/it][A
eval: 124it [04:40,  2.25s/it][A
eval: 125it [04:42,  2.25s/it][A
eval: 126it [04:44,  2.25s/it][A
eval: 127it [04:46,  2.25s/it][A
eval: 128it [04:49,  2.25s/it][Aeval: 128it [04:49,  2.26s/it]
2025-05-24T06:04:17 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.170
2025-05-24T06:04:17 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.170
train:  18%|â–ˆâ–Š        | 42/230 [2:14:43<12:49:40, 245.64s/it, loss=0.134]train:  18%|â–ˆâ–Š        | 42/230 [2:14:43<12:49:40, 245.64s/it, loss=0.144]2025-05-24T06:06:55 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 41.
2025-05-24T06:06:55 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 41 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-41
2025-05-24T06:06:55 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-41 for step 41
2025-05-24T06:06:55 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T06:06:55 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T06:06:55 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T06:07:24 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
2025-05-24T06:07:36 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T06:07:36 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-41 for step 41
Removing checkpoint step-20
2025-05-24T06:07:36 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T06:07:36 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-20 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-20
2025-05-24T06:07:40 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-20 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-20 in 4.49 seconds
train:  19%|â–ˆâ–Š        | 43/230 [2:17:51<11:51:35, 228.32s/it, loss=0.144]train:  19%|â–ˆâ–Š        | 43/230 [2:17:51<11:51:35, 228.32s/it, loss=0.124]train:  19%|â–ˆâ–‰        | 44/230 [2:20:30<10:43:16, 207.51s/it, loss=0.124]train:  19%|â–ˆâ–‰        | 44/230 [2:20:30<10:43:16, 207.51s/it, loss=0.129]train:  20%|â–ˆâ–‰        | 45/230 [2:23:09<9:54:44, 192.89s/it, loss=0.129] train:  20%|â–ˆâ–‰        | 45/230 [2:23:09<9:54:44, 192.89s/it, loss=0.135]train:  20%|â–ˆâ–ˆ        | 46/230 [2:25:48<9:20:10, 182.66s/it, loss=0.135]train:  20%|â–ˆâ–ˆ        | 46/230 [2:25:48<9:20:10, 182.66s/it, loss=0.124]train:  20%|â–ˆâ–ˆ        | 47/230 [2:28:26<8:55:20, 175.52s/it, loss=0.124]train:  20%|â–ˆâ–ˆ        | 47/230 [2:28:26<8:55:20, 175.52s/it, loss=0.137]train:  21%|â–ˆâ–ˆ        | 48/230 [2:31:05<8:37:12, 170.51s/it, loss=0.137]train:  21%|â–ˆâ–ˆ        | 48/230 [2:31:05<8:37:12, 170.51s/it, loss=0.13] train:  21%|â–ˆâ–ˆâ–       | 49/230 [2:33:44<8:23:50, 167.02s/it, loss=0.13]train:  21%|â–ˆâ–ˆâ–       | 49/230 [2:33:44<8:23:50, 167.02s/it, loss=0.137]train:  22%|â–ˆâ–ˆâ–       | 50/230 [2:36:23<8:13:43, 164.57s/it, loss=0.137]train:  22%|â–ˆâ–ˆâ–       | 50/230 [2:36:23<8:13:43, 164.57s/it, loss=0.129]train:  22%|â–ˆâ–ˆâ–       | 51/230 [2:39:02<8:05:53, 162.87s/it, loss=0.129]train:  22%|â–ˆâ–ˆâ–       | 51/230 [2:39:02<8:05:53, 162.87s/it, loss=0.118]train:  23%|â–ˆâ–ˆâ–Ž       | 52/230 [2:41:41<7:59:34, 161.65s/it, loss=0.118]train:  23%|â–ˆâ–ˆâ–Ž       | 52/230 [2:41:41<7:59:34, 161.65s/it, loss=0.131]train:  23%|â–ˆâ–ˆâ–Ž       | 53/230 [2:44:20<7:54:26, 160.83s/it, loss=0.131]train:  23%|â–ˆâ–ˆâ–Ž       | 53/230 [2:44:20<7:54:26, 160.83s/it, loss=0.131]train:  23%|â–ˆâ–ˆâ–Ž       | 54/230 [2:46:58<7:49:57, 160.21s/it, loss=0.131]train:  23%|â–ˆâ–ˆâ–Ž       | 54/230 [2:46:58<7:49:57, 160.21s/it, loss=0.118]train:  24%|â–ˆâ–ˆâ–       | 55/230 [2:49:37<7:46:08, 159.82s/it, loss=0.118]train:  24%|â–ˆâ–ˆâ–       | 55/230 [2:49:37<7:46:08, 159.82s/it, loss=0.128]train:  24%|â–ˆâ–ˆâ–       | 56/230 [2:52:16<7:42:31, 159.49s/it, loss=0.128]train:  24%|â–ˆâ–ˆâ–       | 56/230 [2:52:16<7:42:31, 159.49s/it, loss=0.128]train:  25%|â–ˆâ–ˆâ–       | 57/230 [2:54:55<7:39:15, 159.28s/it, loss=0.128]train:  25%|â–ˆâ–ˆâ–       | 57/230 [2:54:55<7:39:15, 159.28s/it, loss=0.117]train:  25%|â–ˆâ–ˆâ–Œ       | 58/230 [2:57:34<7:36:13, 159.15s/it, loss=0.117]train:  25%|â–ˆâ–ˆâ–Œ       | 58/230 [2:57:34<7:36:13, 159.15s/it, loss=0.136]train:  26%|â–ˆâ–ˆâ–Œ       | 59/230 [3:00:12<7:33:15, 159.04s/it, loss=0.136]train:  26%|â–ˆâ–ˆâ–Œ       | 59/230 [3:00:12<7:33:15, 159.04s/it, loss=0.123]train:  26%|â–ˆâ–ˆâ–Œ       | 60/230 [3:02:51<7:30:31, 159.01s/it, loss=0.123]train:  26%|â–ˆâ–ˆâ–Œ       | 60/230 [3:02:51<7:30:31, 159.01s/it, loss=0.135]train:  27%|â–ˆâ–ˆâ–‹       | 61/230 [3:05:30<7:27:42, 158.95s/it, loss=0.135]train:  27%|â–ˆâ–ˆâ–‹       | 61/230 [3:05:30<7:27:42, 158.95s/it, loss=0.134]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.30s/it][A
eval: 3it [00:06,  2.30s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.27s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.27s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:25,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:35,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:44,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:53,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.26s/it][A
eval: 61it [02:17,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:24,  2.26s/it][A
eval: 65it [02:26,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:31,  2.26s/it][A
eval: 68it [02:33,  2.26s/it][A
eval: 69it [02:35,  2.26s/it][A
eval: 70it [02:38,  2.26s/it][A
eval: 71it [02:40,  2.26s/it][A
eval: 72it [02:42,  2.26s/it][A
eval: 73it [02:45,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:49,  2.26s/it][A
eval: 76it [02:51,  2.26s/it][A
eval: 77it [02:54,  2.26s/it][A
eval: 78it [02:56,  2.26s/it][A
eval: 79it [02:58,  2.26s/it][A
eval: 80it [03:00,  2.26s/it][A
eval: 81it [03:03,  2.26s/it][A
eval: 82it [03:05,  2.26s/it][A
eval: 83it [03:07,  2.26s/it][A
eval: 84it [03:09,  2.26s/it][A
eval: 85it [03:12,  2.26s/it][A
eval: 86it [03:14,  2.26s/it][A
eval: 87it [03:16,  2.26s/it][A
eval: 88it [03:18,  2.26s/it][A
eval: 89it [03:21,  2.26s/it][A
eval: 90it [03:23,  2.26s/it][A
eval: 91it [03:25,  2.26s/it][A
eval: 92it [03:27,  2.26s/it][A
eval: 93it [03:30,  2.26s/it][A
eval: 94it [03:32,  2.26s/it][A
eval: 95it [03:34,  2.26s/it][A
eval: 96it [03:36,  2.26s/it][A
eval: 97it [03:39,  2.26s/it][A
eval: 98it [03:41,  2.26s/it][A
eval: 99it [03:43,  2.26s/it][A
eval: 100it [03:45,  2.26s/it][A
eval: 101it [03:48,  2.26s/it][A
eval: 102it [03:50,  2.26s/it][A
eval: 103it [03:52,  2.26s/it][A
eval: 104it [03:54,  2.26s/it][A
eval: 105it [03:57,  2.26s/it][A
eval: 106it [03:59,  2.26s/it][A
eval: 107it [04:01,  2.26s/it][A
eval: 108it [04:03,  2.26s/it][A
eval: 109it [04:06,  2.26s/it][A
eval: 110it [04:08,  2.26s/it][A
eval: 111it [04:10,  2.26s/it][A
eval: 112it [04:13,  2.26s/it][A
eval: 113it [04:15,  2.26s/it][A
eval: 114it [04:17,  2.26s/it][A
eval: 115it [04:19,  2.26s/it][A
eval: 116it [04:22,  2.26s/it][A
eval: 117it [04:24,  2.26s/it][A
eval: 118it [04:26,  2.26s/it][A
eval: 119it [04:28,  2.26s/it][A
eval: 120it [04:31,  2.26s/it][A
eval: 121it [04:33,  2.26s/it][A
eval: 122it [04:35,  2.26s/it][A
eval: 123it [04:37,  2.26s/it][A
eval: 124it [04:40,  2.26s/it][A
eval: 125it [04:42,  2.26s/it][A
eval: 126it [04:44,  2.26s/it][A
eval: 127it [04:46,  2.26s/it][A
eval: 128it [04:49,  2.26s/it][Aeval: 128it [04:49,  2.26s/it]
2025-05-24T07:02:32 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.165
2025-05-24T07:02:32 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.165
train:  27%|â–ˆâ–ˆâ–‹       | 62/230 [3:12:58<11:28:01, 245.72s/it, loss=0.134]train:  27%|â–ˆâ–ˆâ–‹       | 62/230 [3:12:58<11:28:01, 245.72s/it, loss=0.126]train:  27%|â–ˆâ–ˆâ–‹       | 63/230 [3:15:37<10:11:22, 219.65s/it, loss=0.126]train:  27%|â–ˆâ–ˆâ–‹       | 63/230 [3:15:37<10:11:22, 219.65s/it, loss=0.131]2025-05-24T07:07:49 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 62.
2025-05-24T07:07:49 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 62 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-62
2025-05-24T07:07:49 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-62 for step 62
2025-05-24T07:07:49 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T07:07:49 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T07:07:49 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T07:08:18 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
2025-05-24T07:08:27 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T07:08:27 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-62 for step 62
Removing checkpoint step-41
2025-05-24T07:08:27 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T07:08:27 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-41 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-41
2025-05-24T07:08:32 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-41 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-41 in 4.54 seconds
train:  28%|â–ˆâ–ˆâ–Š       | 64/230 [3:18:45<9:41:00, 210.00s/it, loss=0.131] train:  28%|â–ˆâ–ˆâ–Š       | 64/230 [3:18:45<9:41:00, 210.00s/it, loss=0.127]train:  28%|â–ˆâ–ˆâ–Š       | 65/230 [3:21:24<8:55:31, 194.74s/it, loss=0.127]train:  28%|â–ˆâ–ˆâ–Š       | 65/230 [3:21:24<8:55:31, 194.74s/it, loss=0.121]train:  29%|â–ˆâ–ˆâ–Š       | 66/230 [3:24:03<8:22:48, 183.96s/it, loss=0.121]train:  29%|â–ˆâ–ˆâ–Š       | 66/230 [3:24:03<8:22:48, 183.96s/it, loss=0.124]train:  29%|â–ˆâ–ˆâ–‰       | 67/230 [3:26:42<7:59:21, 176.45s/it, loss=0.124]train:  29%|â–ˆâ–ˆâ–‰       | 67/230 [3:26:42<7:59:21, 176.45s/it, loss=0.118]train:  30%|â–ˆâ–ˆâ–‰       | 68/230 [3:29:20<7:42:14, 171.20s/it, loss=0.118]train:  30%|â–ˆâ–ˆâ–‰       | 68/230 [3:29:20<7:42:14, 171.20s/it, loss=0.135]train:  30%|â–ˆâ–ˆâ–ˆ       | 69/230 [3:31:59<7:29:25, 167.49s/it, loss=0.135]train:  30%|â–ˆâ–ˆâ–ˆ       | 69/230 [3:31:59<7:29:25, 167.49s/it, loss=0.125]train:  30%|â–ˆâ–ˆâ–ˆ       | 70/230 [3:34:38<7:19:42, 164.89s/it, loss=0.125]train:  30%|â–ˆâ–ˆâ–ˆ       | 70/230 [3:34:38<7:19:42, 164.89s/it, loss=0.131]train:  31%|â–ˆâ–ˆâ–ˆ       | 71/230 [3:37:17<7:12:21, 163.16s/it, loss=0.131]train:  31%|â–ˆâ–ˆâ–ˆ       | 71/230 [3:37:17<7:12:21, 163.16s/it, loss=0.134]train:  31%|â–ˆâ–ˆâ–ˆâ–      | 72/230 [3:39:56<7:06:28, 161.96s/it, loss=0.134]train:  31%|â–ˆâ–ˆâ–ˆâ–      | 72/230 [3:39:56<7:06:28, 161.96s/it, loss=0.141]train:  32%|â–ˆâ–ˆâ–ˆâ–      | 73/230 [3:42:36<7:01:39, 161.14s/it, loss=0.141]train:  32%|â–ˆâ–ˆâ–ˆâ–      | 73/230 [3:42:36<7:01:39, 161.14s/it, loss=0.129]train:  32%|â–ˆâ–ˆâ–ˆâ–      | 74/230 [3:45:15<6:57:31, 160.58s/it, loss=0.129]train:  32%|â–ˆâ–ˆâ–ˆâ–      | 74/230 [3:45:15<6:57:31, 160.58s/it, loss=0.125]train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 75/230 [3:47:54<6:53:43, 160.15s/it, loss=0.125]train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 75/230 [3:47:54<6:53:43, 160.15s/it, loss=0.125]train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 76/230 [3:50:33<6:50:20, 159.87s/it, loss=0.125]train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 76/230 [3:50:33<6:50:20, 159.87s/it, loss=0.119]train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 77/230 [3:53:12<6:47:06, 159.65s/it, loss=0.119]train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 77/230 [3:53:12<6:47:06, 159.65s/it, loss=0.129]train:  34%|â–ˆâ–ˆâ–ˆâ–      | 78/230 [3:55:51<6:43:58, 159.46s/it, loss=0.129]train:  34%|â–ˆâ–ˆâ–ˆâ–      | 78/230 [3:55:51<6:43:58, 159.46s/it, loss=0.124]train:  34%|â–ˆâ–ˆâ–ˆâ–      | 79/230 [3:58:31<6:41:10, 159.41s/it, loss=0.124]train:  34%|â–ˆâ–ˆâ–ˆâ–      | 79/230 [3:58:31<6:41:10, 159.41s/it, loss=0.133]train:  35%|â–ˆâ–ˆâ–ˆâ–      | 80/230 [4:01:10<6:38:24, 159.36s/it, loss=0.133]train:  35%|â–ˆâ–ˆâ–ˆâ–      | 80/230 [4:01:10<6:38:24, 159.36s/it, loss=0.109]train:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 81/230 [4:03:49<6:35:34, 159.29s/it, loss=0.109]train:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 81/230 [4:03:49<6:35:34, 159.29s/it, loss=0.123]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.31s/it][A
eval: 3it [00:06,  2.30s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.28s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.27s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:25,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:35,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:44,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:53,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.26s/it][A
eval: 61it [02:17,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:24,  2.26s/it][A
eval: 65it [02:26,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:31,  2.26s/it][A
eval: 68it [02:33,  2.26s/it][A
eval: 69it [02:36,  2.26s/it][A
eval: 70it [02:38,  2.26s/it][A
eval: 71it [02:40,  2.26s/it][A
eval: 72it [02:42,  2.26s/it][A
eval: 73it [02:45,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:49,  2.26s/it][A
eval: 76it [02:51,  2.26s/it][A
eval: 77it [02:54,  2.26s/it][A
eval: 78it [02:56,  2.26s/it][A
eval: 79it [02:58,  2.26s/it][A
eval: 80it [03:00,  2.26s/it][A
eval: 81it [03:03,  2.26s/it][A
eval: 82it [03:05,  2.26s/it][A
eval: 83it [03:07,  2.26s/it][A
eval: 84it [03:09,  2.26s/it][A
eval: 85it [03:12,  2.26s/it][A
eval: 86it [03:14,  2.26s/it][A
eval: 87it [03:16,  2.26s/it][A
eval: 88it [03:18,  2.26s/it][A
eval: 89it [03:21,  2.26s/it][A
eval: 90it [03:23,  2.26s/it][A
eval: 91it [03:25,  2.26s/it][A
eval: 92it [03:27,  2.26s/it][A
eval: 93it [03:30,  2.26s/it][A
eval: 94it [03:32,  2.26s/it][A
eval: 95it [03:34,  2.26s/it][A
eval: 96it [03:36,  2.26s/it][A
eval: 97it [03:39,  2.26s/it][A
eval: 98it [03:41,  2.26s/it][A
eval: 99it [03:43,  2.26s/it][A
eval: 100it [03:45,  2.26s/it][A
eval: 101it [03:48,  2.26s/it][A
eval: 102it [03:50,  2.26s/it][A
eval: 103it [03:52,  2.26s/it][A
eval: 104it [03:55,  2.26s/it][A
eval: 105it [03:57,  2.26s/it][A
eval: 106it [03:59,  2.26s/it][A
eval: 107it [04:01,  2.26s/it][A
eval: 108it [04:04,  2.26s/it][A
eval: 109it [04:06,  2.26s/it][A
eval: 110it [04:08,  2.26s/it][A
eval: 111it [04:10,  2.26s/it][A
eval: 112it [04:13,  2.26s/it][A
eval: 113it [04:15,  2.26s/it][A
eval: 114it [04:17,  2.26s/it][A
eval: 115it [04:19,  2.26s/it][A
eval: 116it [04:22,  2.26s/it][A
eval: 117it [04:24,  2.26s/it][A
eval: 118it [04:26,  2.26s/it][A
eval: 119it [04:28,  2.26s/it][A
eval: 120it [04:31,  2.26s/it][A
eval: 121it [04:33,  2.26s/it][A
eval: 122it [04:35,  2.26s/it][A
eval: 123it [04:37,  2.26s/it][A
eval: 124it [04:40,  2.26s/it][A
eval: 125it [04:42,  2.26s/it][A
eval: 126it [04:44,  2.26s/it][A
eval: 127it [04:46,  2.26s/it][A
eval: 128it [04:49,  2.26s/it][Aeval: 128it [04:49,  2.26s/it]
2025-05-24T08:00:51 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.163
2025-05-24T08:00:51 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.163
train:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 82/230 [4:11:18<10:07:04, 246.11s/it, loss=0.123]train:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 82/230 [4:11:18<10:07:04, 246.11s/it, loss=0.118]train:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 83/230 [4:13:57<8:59:07, 220.05s/it, loss=0.118] train:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 83/230 [4:13:57<8:59:07, 220.05s/it, loss=0.115]train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 84/230 [4:16:36<8:11:05, 201.82s/it, loss=0.115]train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 84/230 [4:16:36<8:11:05, 201.82s/it, loss=0.127]2025-05-24T08:08:49 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 83.
2025-05-24T08:08:49 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 83 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-83
2025-05-24T08:08:49 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-83 for step 83
2025-05-24T08:08:49 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T08:08:49 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T08:08:49 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T08:09:17 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
2025-05-24T08:09:31 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T08:09:32 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-83 for step 83
Removing checkpoint step-62
2025-05-24T08:09:32 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T08:09:32 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-62 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-62
2025-05-24T08:09:36 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-62 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-62 in 4.56 seconds
train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 85/230 [4:19:44<7:57:46, 197.70s/it, loss=0.127]train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 85/230 [4:19:44<7:57:46, 197.70s/it, loss=0.121]train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 86/230 [4:22:24<7:26:53, 186.20s/it, loss=0.121]train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 86/230 [4:22:24<7:26:53, 186.20s/it, loss=0.127]train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 87/230 [4:25:03<7:04:31, 178.12s/it, loss=0.127]train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 87/230 [4:25:03<7:04:31, 178.12s/it, loss=0.117]train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 88/230 [4:27:42<6:48:13, 172.49s/it, loss=0.117]train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 88/230 [4:27:42<6:48:13, 172.49s/it, loss=0.128]train:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 89/230 [4:30:22<6:35:55, 168.48s/it, loss=0.128]train:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 89/230 [4:30:22<6:35:55, 168.48s/it, loss=0.117]train:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 90/230 [4:33:01<6:26:32, 165.66s/it, loss=0.117]train:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 90/230 [4:33:01<6:26:32, 165.66s/it, loss=0.119]train:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 91/230 [4:35:40<6:19:17, 163.72s/it, loss=0.119]train:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 91/230 [4:35:40<6:19:17, 163.72s/it, loss=0.117]train:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 92/230 [4:38:19<6:13:28, 162.38s/it, loss=0.117]train:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 92/230 [4:38:19<6:13:28, 162.38s/it, loss=0.123]train:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 93/230 [4:40:58<6:08:40, 161.46s/it, loss=0.123]train:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 93/230 [4:40:58<6:08:40, 161.46s/it, loss=0.115]train:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 94/230 [4:43:38<6:04:32, 160.83s/it, loss=0.115]train:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 94/230 [4:43:38<6:04:32, 160.83s/it, loss=0.144]train:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 95/230 [4:46:17<6:00:42, 160.32s/it, loss=0.144]train:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 95/230 [4:46:17<6:00:42, 160.32s/it, loss=0.126]train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 96/230 [4:48:56<5:57:15, 159.97s/it, loss=0.126]train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 96/230 [4:48:56<5:57:15, 159.97s/it, loss=0.112]train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 97/230 [4:51:35<5:54:07, 159.75s/it, loss=0.112]train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 97/230 [4:51:35<5:54:07, 159.75s/it, loss=0.116]train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 98/230 [4:54:14<5:51:04, 159.58s/it, loss=0.116]train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 98/230 [4:54:14<5:51:04, 159.58s/it, loss=0.115]train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 99/230 [4:56:54<5:48:09, 159.46s/it, loss=0.115]train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 99/230 [4:56:54<5:48:09, 159.46s/it, loss=0.142]train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 100/230 [4:59:33<5:45:17, 159.37s/it, loss=0.142]train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 100/230 [4:59:33<5:45:17, 159.37s/it, loss=0.12] train:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 101/230 [5:02:12<5:42:31, 159.31s/it, loss=0.12]train:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 101/230 [5:02:12<5:42:31, 159.31s/it, loss=0.13]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.30s/it][A
eval: 3it [00:06,  2.29s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.27s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.26s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:24,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:34,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:44,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:53,  2.25s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.25s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.25s/it][A
eval: 61it [02:17,  2.25s/it][A
eval: 62it [02:20,  2.25s/it][A
eval: 63it [02:22,  2.25s/it][A
eval: 64it [02:24,  2.25s/it][A
eval: 65it [02:26,  2.25s/it][A
eval: 66it [02:29,  2.25s/it][A
eval: 67it [02:31,  2.25s/it][A
eval: 68it [02:33,  2.25s/it][A
eval: 69it [02:35,  2.25s/it][A
eval: 70it [02:38,  2.25s/it][A
eval: 71it [02:40,  2.25s/it][A
eval: 72it [02:42,  2.25s/it][A
eval: 73it [02:44,  2.25s/it][A
eval: 74it [02:47,  2.25s/it][A
eval: 75it [02:49,  2.25s/it][A
eval: 76it [02:51,  2.25s/it][A
eval: 77it [02:53,  2.25s/it][A
eval: 78it [02:56,  2.25s/it][A
eval: 79it [02:58,  2.25s/it][A
eval: 80it [03:00,  2.25s/it][A
eval: 81it [03:02,  2.25s/it][A
eval: 82it [03:05,  2.25s/it][A
eval: 83it [03:07,  2.25s/it][A
eval: 84it [03:09,  2.25s/it][A
eval: 85it [03:11,  2.25s/it][A
eval: 86it [03:14,  2.25s/it][A
eval: 87it [03:16,  2.25s/it][A
eval: 88it [03:18,  2.25s/it][A
eval: 89it [03:20,  2.25s/it][A
eval: 90it [03:23,  2.25s/it][A
eval: 91it [03:25,  2.25s/it][A
eval: 92it [03:27,  2.25s/it][A
eval: 93it [03:29,  2.25s/it][A
eval: 94it [03:32,  2.25s/it][A
eval: 95it [03:34,  2.25s/it][A
eval: 96it [03:36,  2.25s/it][A
eval: 97it [03:38,  2.25s/it][A
eval: 98it [03:41,  2.25s/it][A
eval: 99it [03:43,  2.25s/it][A
eval: 100it [03:45,  2.25s/it][A
eval: 101it [03:47,  2.25s/it][A
eval: 102it [03:50,  2.25s/it][A
eval: 103it [03:52,  2.25s/it][A
eval: 104it [03:54,  2.25s/it][A
eval: 105it [03:56,  2.25s/it][A
eval: 106it [03:59,  2.25s/it][A
eval: 107it [04:01,  2.25s/it][A
eval: 108it [04:03,  2.25s/it][A
eval: 109it [04:05,  2.25s/it][A
eval: 110it [04:08,  2.25s/it][A
eval: 111it [04:10,  2.25s/it][A
eval: 112it [04:12,  2.25s/it][A
eval: 113it [04:14,  2.25s/it][A
eval: 114it [04:17,  2.25s/it][A
eval: 115it [04:19,  2.25s/it][A
eval: 116it [04:21,  2.25s/it][A
eval: 117it [04:24,  2.25s/it][A
eval: 118it [04:26,  2.25s/it][A
eval: 119it [04:28,  2.25s/it][A
eval: 120it [04:30,  2.25s/it][A
eval: 121it [04:33,  2.25s/it][A
eval: 122it [04:35,  2.25s/it][A
eval: 123it [04:37,  2.25s/it][A
eval: 124it [04:39,  2.25s/it][A
eval: 125it [04:42,  2.25s/it][A
eval: 126it [04:44,  2.25s/it][A
eval: 127it [04:46,  2.25s/it][A
eval: 128it [04:48,  2.25s/it][Aeval: 128it [04:48,  2.26s/it]
2025-05-24T08:59:13 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.163
2025-05-24T08:59:13 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.163
train:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 102/230 [5:09:40<8:44:38, 245.92s/it, loss=0.13]train:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 102/230 [5:09:40<8:44:38, 245.92s/it, loss=0.119]train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 103/230 [5:12:19<7:45:25, 219.89s/it, loss=0.119]train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 103/230 [5:12:19<7:45:25, 219.89s/it, loss=0.121]train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 104/230 [5:14:58<7:03:31, 201.68s/it, loss=0.121]train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 104/230 [5:14:58<7:03:31, 201.68s/it, loss=0.129]train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 105/230 [5:17:37<6:33:35, 188.92s/it, loss=0.129]train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 105/230 [5:17:37<6:33:35, 188.92s/it, loss=0.119]2025-05-24T09:09:50 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 104.
2025-05-24T09:09:50 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 104 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-104
2025-05-24T09:09:50 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-104 for step 104
2025-05-24T09:09:50 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T09:09:50 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T09:09:50 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T09:10:18 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
2025-05-24T09:10:27 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T09:10:27 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-104 for step 104
Removing checkpoint step-83
2025-05-24T09:10:27 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T09:10:27 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-83 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-83
2025-05-24T09:10:32 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-83 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-83 in 4.80 seconds
train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 106/230 [5:20:45<6:29:21, 188.40s/it, loss=0.119]train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 106/230 [5:20:45<6:29:21, 188.40s/it, loss=0.122]train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 107/230 [5:23:24<6:08:16, 179.65s/it, loss=0.122]train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 107/230 [5:23:24<6:08:16, 179.65s/it, loss=0.127]train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 108/230 [5:26:03<5:52:45, 173.49s/it, loss=0.127]train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 108/230 [5:26:03<5:52:45, 173.49s/it, loss=0.118]train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 109/230 [5:28:42<5:41:09, 169.17s/it, loss=0.118]train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 109/230 [5:28:42<5:41:09, 169.17s/it, loss=0.13] train:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 110/230 [5:31:21<5:32:17, 166.15s/it, loss=0.13]train:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 110/230 [5:31:21<5:32:17, 166.15s/it, loss=0.111]train:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 111/230 [5:34:00<5:25:27, 164.09s/it, loss=0.111]train:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 111/230 [5:34:00<5:25:27, 164.09s/it, loss=0.118]train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 112/230 [5:36:40<5:19:47, 162.61s/it, loss=0.118]train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 112/230 [5:36:40<5:19:47, 162.61s/it, loss=0.133]train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 113/230 [5:39:19<5:15:01, 161.55s/it, loss=0.133]train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 113/230 [5:39:19<5:15:01, 161.55s/it, loss=0.123]train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 114/230 [5:41:58<5:11:00, 160.87s/it, loss=0.123]train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 114/230 [5:41:58<5:11:00, 160.87s/it, loss=0.122]train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 115/230 [5:44:37<5:07:20, 160.35s/it, loss=0.122]train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 115/230 [5:44:37<5:07:20, 160.35s/it, loss=0.114]train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 116/230 [5:47:16<5:03:56, 159.97s/it, loss=0.114]train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 116/230 [5:47:16<5:03:56, 159.97s/it, loss=0.118]train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 117/230 [5:49:55<5:00:53, 159.76s/it, loss=0.118]train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 117/230 [5:49:55<5:00:53, 159.76s/it, loss=0.117]train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 118/230 [5:52:35<4:57:52, 159.58s/it, loss=0.117]train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 118/230 [5:52:35<4:57:52, 159.58s/it, loss=0.11] train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 119/230 [5:55:14<4:54:53, 159.40s/it, loss=0.11]train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 119/230 [5:55:14<4:54:53, 159.40s/it, loss=0.129]train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 120/230 [5:57:53<4:52:06, 159.33s/it, loss=0.129]train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 120/230 [5:57:53<4:52:06, 159.33s/it, loss=0.128]train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 121/230 [6:00:32<4:49:20, 159.27s/it, loss=0.128]train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 121/230 [6:00:32<4:49:20, 159.27s/it, loss=0.121]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.30s/it][A
eval: 3it [00:06,  2.29s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.27s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.26s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:24,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:34,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:44,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:53,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.26s/it][A
eval: 61it [02:17,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:24,  2.26s/it][A
eval: 65it [02:26,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:31,  2.26s/it][A
eval: 68it [02:33,  2.26s/it][A
eval: 69it [02:35,  2.26s/it][A
eval: 70it [02:38,  2.26s/it][A
eval: 71it [02:40,  2.26s/it][A
eval: 72it [02:42,  2.26s/it][A
eval: 73it [02:44,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:49,  2.26s/it][A
eval: 76it [02:51,  2.26s/it][A
eval: 77it [02:53,  2.26s/it][A
eval: 78it [02:56,  2.26s/it][A
eval: 79it [02:58,  2.26s/it][A
eval: 80it [03:00,  2.26s/it][A
eval: 81it [03:03,  2.26s/it][A
eval: 82it [03:05,  2.26s/it][A
eval: 83it [03:07,  2.26s/it][A
eval: 84it [03:09,  2.26s/it][A
eval: 85it [03:12,  2.26s/it][A
eval: 86it [03:14,  2.26s/it][A
eval: 87it [03:16,  2.26s/it][A
eval: 88it [03:18,  2.26s/it][A
eval: 89it [03:21,  2.26s/it][A
eval: 90it [03:23,  2.26s/it][A
eval: 91it [03:25,  2.26s/it][A
eval: 92it [03:27,  2.26s/it][A
eval: 93it [03:30,  2.26s/it][A
eval: 94it [03:32,  2.26s/it][A
eval: 95it [03:34,  2.26s/it][A
eval: 96it [03:36,  2.26s/it][A
eval: 97it [03:39,  2.26s/it][A
eval: 98it [03:41,  2.26s/it][A
eval: 99it [03:43,  2.26s/it][A
eval: 100it [03:45,  2.26s/it][A
eval: 101it [03:48,  2.26s/it][A
eval: 102it [03:50,  2.26s/it][A
eval: 103it [03:52,  2.26s/it][A
eval: 104it [03:54,  2.26s/it][A
eval: 105it [03:57,  2.26s/it][A
eval: 106it [03:59,  2.26s/it][A
eval: 107it [04:01,  2.26s/it][A
eval: 108it [04:03,  2.26s/it][A
eval: 109it [04:06,  2.26s/it][A
eval: 110it [04:08,  2.26s/it][A
eval: 111it [04:10,  2.26s/it][A
eval: 112it [04:12,  2.26s/it][A
eval: 113it [04:15,  2.26s/it][A
eval: 114it [04:17,  2.26s/it][A
eval: 115it [04:19,  2.26s/it][A
eval: 116it [04:22,  2.26s/it][A
eval: 117it [04:24,  2.26s/it][A
eval: 118it [04:26,  2.26s/it][A
eval: 119it [04:28,  2.26s/it][A
eval: 120it [04:31,  2.26s/it][A
eval: 121it [04:33,  2.26s/it][A
eval: 122it [04:35,  2.26s/it][A
eval: 123it [04:37,  2.26s/it][A
eval: 124it [04:40,  2.26s/it][A
eval: 125it [04:42,  2.26s/it][A
eval: 126it [04:44,  2.26s/it][A
eval: 127it [04:46,  2.26s/it][A
eval: 128it [04:49,  2.26s/it][Aeval: 128it [04:49,  2.26s/it]
2025-05-24T09:57:33 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.161
2025-05-24T09:57:33 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.161
train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 122/230 [6:08:00<7:22:43, 245.96s/it, loss=0.121]train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 122/230 [6:08:00<7:22:43, 245.96s/it, loss=0.129]train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 123/230 [6:10:39<6:32:11, 219.92s/it, loss=0.129]train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 123/230 [6:10:39<6:32:11, 219.92s/it, loss=0.114]train:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 124/230 [6:13:18<5:56:19, 201.69s/it, loss=0.114]train:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 124/230 [6:13:18<5:56:19, 201.69s/it, loss=0.116]train:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 125/230 [6:15:58<5:30:38, 188.93s/it, loss=0.116]train:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 125/230 [6:15:58<5:30:38, 188.93s/it, loss=0.113]train:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 126/230 [6:18:37<5:12:04, 180.05s/it, loss=0.113]train:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 126/230 [6:18:37<5:12:04, 180.05s/it, loss=0.116]2025-05-24T10:10:49 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 125.
2025-05-24T10:10:49 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 125 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-125
2025-05-24T10:10:49 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-125 for step 125
2025-05-24T10:10:49 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T10:10:49 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T10:10:49 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T10:11:17 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
2025-05-24T10:11:29 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T10:11:29 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-125 for step 125
Removing checkpoint step-104
2025-05-24T10:11:29 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T10:11:29 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-104 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-104
2025-05-24T10:11:33 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-104 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-104 in 4.69 seconds
train:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 127/230 [6:21:44<5:12:47, 182.21s/it, loss=0.116]train:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 127/230 [6:21:44<5:12:47, 182.21s/it, loss=0.125]train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 128/230 [6:24:24<4:58:06, 175.36s/it, loss=0.125]train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 128/230 [6:24:24<4:58:06, 175.36s/it, loss=0.137]train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 129/230 [6:27:03<4:46:57, 170.47s/it, loss=0.137]train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 129/230 [6:27:03<4:46:57, 170.47s/it, loss=0.122]train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 130/230 [6:29:42<4:38:30, 167.11s/it, loss=0.122]train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 130/230 [6:29:42<4:38:30, 167.11s/it, loss=0.118]train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 131/230 [6:32:21<4:31:44, 164.69s/it, loss=0.118]train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 131/230 [6:32:21<4:31:44, 164.69s/it, loss=0.119]train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 132/230 [6:35:00<4:26:17, 163.04s/it, loss=0.119]train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 132/230 [6:35:00<4:26:17, 163.04s/it, loss=0.114]train:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 133/230 [6:37:39<4:21:44, 161.90s/it, loss=0.114]train:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 133/230 [6:37:39<4:21:44, 161.90s/it, loss=0.121]train:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 134/230 [6:40:18<4:17:34, 160.98s/it, loss=0.121]train:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 134/230 [6:40:18<4:17:34, 160.98s/it, loss=0.126]train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 135/230 [6:42:57<4:13:55, 160.37s/it, loss=0.126]train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 135/230 [6:42:57<4:13:55, 160.37s/it, loss=0.116]train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 136/230 [6:45:36<4:10:40, 160.00s/it, loss=0.116]train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 136/230 [6:45:36<4:10:40, 160.00s/it, loss=0.141]train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 137/230 [6:48:15<4:07:35, 159.74s/it, loss=0.141]train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 137/230 [6:48:15<4:07:35, 159.74s/it, loss=0.126]train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 138/230 [6:50:55<4:04:39, 159.56s/it, loss=0.126]train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 138/230 [6:50:55<4:04:39, 159.56s/it, loss=0.117]train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 139/230 [6:53:34<4:01:46, 159.42s/it, loss=0.117]train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 139/230 [6:53:34<4:01:46, 159.42s/it, loss=0.136]train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 140/230 [6:56:13<3:58:58, 159.31s/it, loss=0.136]train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 140/230 [6:56:13<3:58:58, 159.31s/it, loss=0.115]train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 141/230 [6:58:52<3:56:09, 159.21s/it, loss=0.115]train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 141/230 [6:58:52<3:56:09, 159.21s/it, loss=0.12] 
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.30s/it][A
eval: 3it [00:06,  2.29s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.27s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.26s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:24,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:34,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:43,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:53,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.26s/it][A
eval: 61it [02:17,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:24,  2.26s/it][A
eval: 65it [02:26,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:31,  2.26s/it][A
eval: 68it [02:33,  2.26s/it][A
eval: 69it [02:35,  2.26s/it][A
eval: 70it [02:38,  2.26s/it][A
eval: 71it [02:40,  2.26s/it][A
eval: 72it [02:42,  2.26s/it][A
eval: 73it [02:44,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:49,  2.26s/it][A
eval: 76it [02:51,  2.26s/it][A
eval: 77it [02:53,  2.26s/it][A
eval: 78it [02:56,  2.26s/it][A
eval: 79it [02:58,  2.25s/it][A
eval: 80it [03:00,  2.26s/it][A
eval: 81it [03:02,  2.26s/it][A
eval: 82it [03:05,  2.26s/it][A
eval: 83it [03:07,  2.26s/it][A
eval: 84it [03:09,  2.26s/it][A
eval: 85it [03:12,  2.26s/it][A
eval: 86it [03:14,  2.26s/it][A
eval: 87it [03:16,  2.26s/it][A
eval: 88it [03:18,  2.26s/it][A
eval: 89it [03:21,  2.26s/it][A
eval: 90it [03:23,  2.26s/it][A
eval: 91it [03:25,  2.26s/it][A
eval: 92it [03:27,  2.26s/it][A
eval: 93it [03:30,  2.26s/it][A
eval: 94it [03:32,  2.26s/it][A
eval: 95it [03:34,  2.26s/it][A
eval: 96it [03:36,  2.26s/it][A
eval: 97it [03:39,  2.26s/it][A
eval: 98it [03:41,  2.26s/it][A
eval: 99it [03:43,  2.26s/it][A
eval: 100it [03:45,  2.26s/it][A
eval: 101it [03:48,  2.26s/it][A
eval: 102it [03:50,  2.26s/it][A
eval: 103it [03:52,  2.26s/it][A
eval: 104it [03:54,  2.26s/it][A
eval: 105it [03:57,  2.26s/it][A
eval: 106it [03:59,  2.26s/it][A
eval: 107it [04:01,  2.26s/it][A
eval: 108it [04:03,  2.26s/it][A
eval: 109it [04:06,  2.26s/it][A
eval: 110it [04:08,  2.26s/it][A
eval: 111it [04:10,  2.26s/it][A
eval: 112it [04:12,  2.26s/it][A
eval: 113it [04:15,  2.26s/it][A
eval: 114it [04:17,  2.26s/it][A
eval: 115it [04:19,  2.26s/it][A
eval: 116it [04:21,  2.26s/it][A
eval: 117it [04:24,  2.26s/it][A
eval: 118it [04:26,  2.26s/it][A
eval: 119it [04:28,  2.26s/it][A
eval: 120it [04:30,  2.26s/it][A
eval: 121it [04:33,  2.26s/it][A
eval: 122it [04:35,  2.26s/it][A
eval: 123it [04:37,  2.26s/it][A
eval: 124it [04:40,  2.26s/it][A
eval: 125it [04:42,  2.26s/it][A
eval: 126it [04:44,  2.26s/it][A
eval: 127it [04:46,  2.26s/it][A
eval: 128it [04:49,  2.26s/it][Aeval: 128it [04:49,  2.26s/it]
2025-05-24T10:55:53 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.161
2025-05-24T10:55:53 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.161
train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 142/230 [7:06:20<6:00:40, 245.92s/it, loss=0.12]train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 142/230 [7:06:20<6:00:40, 245.92s/it, loss=0.113]train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 143/230 [7:08:59<5:18:45, 219.83s/it, loss=0.113]train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 143/230 [7:08:59<5:18:45, 219.83s/it, loss=0.131]train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 144/230 [7:11:38<4:48:55, 201.58s/it, loss=0.131]train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 144/230 [7:11:38<4:48:55, 201.58s/it, loss=0.123]train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 145/230 [7:14:17<4:27:30, 188.82s/it, loss=0.123]train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 145/230 [7:14:17<4:27:30, 188.82s/it, loss=0.118]train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 146/230 [7:16:56<4:11:49, 179.88s/it, loss=0.118]train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 146/230 [7:16:56<4:11:49, 179.88s/it, loss=0.118]train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 147/230 [7:19:35<4:00:10, 173.62s/it, loss=0.118]train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 147/230 [7:19:35<4:00:10, 173.62s/it, loss=0.117]2025-05-24T11:11:47 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 146.
2025-05-24T11:11:47 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 146 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-146
2025-05-24T11:11:47 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-146 for step 146
2025-05-24T11:11:47 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T11:11:47 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T11:11:47 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T11:12:15 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
2025-05-24T11:12:23 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T11:12:23 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-146 for step 146
Removing checkpoint step-125
2025-05-24T11:12:23 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T11:12:23 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-125 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-125
2025-05-24T11:12:28 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-125 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-125 in 4.93 seconds
train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 148/230 [7:22:41<4:02:28, 177.42s/it, loss=0.117]train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 148/230 [7:22:41<4:02:28, 177.42s/it, loss=0.134]train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 149/230 [7:25:20<3:52:09, 171.97s/it, loss=0.134]train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 149/230 [7:25:20<3:52:09, 171.97s/it, loss=0.115]train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 150/230 [7:28:00<3:44:08, 168.10s/it, loss=0.115]train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 150/230 [7:28:00<3:44:08, 168.10s/it, loss=0.128]train:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 151/230 [7:30:39<3:37:43, 165.36s/it, loss=0.128]train:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 151/230 [7:30:39<3:37:43, 165.36s/it, loss=0.123]train:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 152/230 [7:33:18<3:32:30, 163.47s/it, loss=0.123]train:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 152/230 [7:33:18<3:32:30, 163.47s/it, loss=0.12] train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 153/230 [7:35:56<3:28:01, 162.10s/it, loss=0.12]train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 153/230 [7:35:56<3:28:01, 162.10s/it, loss=0.139]train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 154/230 [7:38:35<3:24:02, 161.09s/it, loss=0.139]train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 154/230 [7:38:35<3:24:02, 161.09s/it, loss=0.125]train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 155/230 [7:41:14<3:20:31, 160.43s/it, loss=0.125]train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 155/230 [7:41:14<3:20:31, 160.43s/it, loss=0.114]train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 156/230 [7:43:53<3:17:19, 159.99s/it, loss=0.114]train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 156/230 [7:43:53<3:17:19, 159.99s/it, loss=0.112]train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 157/230 [7:46:32<3:14:13, 159.63s/it, loss=0.112]train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 157/230 [7:46:32<3:14:13, 159.63s/it, loss=0.109]train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 158/230 [7:49:11<3:11:17, 159.41s/it, loss=0.109]train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 158/230 [7:49:11<3:11:17, 159.41s/it, loss=0.14] train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 159/230 [7:51:50<3:08:25, 159.23s/it, loss=0.14]train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 159/230 [7:51:50<3:08:25, 159.23s/it, loss=0.118]train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 160/230 [7:54:28<3:05:37, 159.10s/it, loss=0.118]train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 160/230 [7:54:28<3:05:37, 159.10s/it, loss=0.116]train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 161/230 [7:57:07<3:02:51, 159.01s/it, loss=0.116]train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 161/230 [7:57:07<3:02:51, 159.01s/it, loss=0.106]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.30s/it][A
eval: 3it [00:06,  2.30s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.27s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.27s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:25,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:34,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:44,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:53,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.26s/it][A
eval: 61it [02:17,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:24,  2.26s/it][A
eval: 65it [02:26,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:31,  2.26s/it][A
eval: 68it [02:33,  2.26s/it][A
eval: 69it [02:35,  2.26s/it][A
eval: 70it [02:38,  2.25s/it][A
eval: 71it [02:40,  2.25s/it][A
eval: 72it [02:42,  2.25s/it][A
eval: 73it [02:44,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:49,  2.26s/it][A
eval: 76it [02:51,  2.26s/it][A
eval: 77it [02:53,  2.26s/it][A
eval: 78it [02:56,  2.26s/it][A
eval: 79it [02:58,  2.25s/it][A
eval: 80it [03:00,  2.26s/it][A
eval: 81it [03:02,  2.26s/it][A
eval: 82it [03:05,  2.26s/it][A
eval: 83it [03:07,  2.26s/it][A
eval: 84it [03:09,  2.26s/it][A
eval: 85it [03:12,  2.26s/it][A
eval: 86it [03:14,  2.26s/it][A
eval: 87it [03:16,  2.26s/it][A
eval: 88it [03:18,  2.26s/it][A
eval: 89it [03:21,  2.26s/it][A
eval: 90it [03:23,  2.26s/it][A
eval: 91it [03:25,  2.26s/it][A
eval: 92it [03:27,  2.26s/it][A
eval: 93it [03:30,  2.26s/it][A
eval: 94it [03:32,  2.26s/it][A
eval: 95it [03:34,  2.26s/it][A
eval: 96it [03:36,  2.26s/it][A
eval: 97it [03:39,  2.26s/it][A
eval: 98it [03:41,  2.26s/it][A
eval: 99it [03:43,  2.26s/it][A
eval: 100it [03:45,  2.26s/it][A
eval: 101it [03:48,  2.26s/it][A
eval: 102it [03:50,  2.26s/it][A
eval: 103it [03:52,  2.26s/it][A
eval: 104it [03:54,  2.26s/it][A
eval: 105it [03:57,  2.26s/it][A
eval: 106it [03:59,  2.26s/it][A
eval: 107it [04:01,  2.26s/it][A
eval: 108it [04:03,  2.26s/it][A
eval: 109it [04:06,  2.26s/it][A
eval: 110it [04:08,  2.26s/it][A
eval: 111it [04:10,  2.26s/it][A
eval: 112it [04:12,  2.26s/it][A
eval: 113it [04:15,  2.26s/it][A
eval: 114it [04:17,  2.26s/it][A
eval: 115it [04:19,  2.26s/it][A
eval: 116it [04:21,  2.26s/it][A
eval: 117it [04:24,  2.25s/it][A
eval: 118it [04:26,  2.25s/it][A
eval: 119it [04:28,  2.26s/it][A
eval: 120it [04:30,  2.26s/it][A
eval: 121it [04:33,  2.25s/it][A
eval: 122it [04:35,  2.25s/it][A
eval: 123it [04:37,  2.25s/it][A
eval: 124it [04:39,  2.26s/it][A
eval: 125it [04:42,  2.26s/it][A
eval: 126it [04:44,  2.26s/it][A
eval: 127it [04:46,  2.26s/it][A
eval: 128it [04:49,  2.26s/it][Aeval: 128it [04:49,  2.26s/it]
2025-05-24T11:54:09 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.161
2025-05-24T11:54:09 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.161
train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 162/230 [8:04:35<4:38:27, 245.70s/it, loss=0.106]train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 162/230 [8:04:35<4:38:27, 245.70s/it, loss=0.125]train:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 163/230 [8:07:14<4:05:14, 219.62s/it, loss=0.125]train:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 163/230 [8:07:14<4:05:14, 219.62s/it, loss=0.118]train:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 164/230 [8:09:53<3:41:32, 201.40s/it, loss=0.118]train:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 164/230 [8:09:53<3:41:32, 201.40s/it, loss=0.108]train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 165/230 [8:12:32<3:24:22, 188.66s/it, loss=0.108]train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 165/230 [8:12:32<3:24:22, 188.66s/it, loss=0.124]train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 166/230 [8:15:11<3:11:40, 179.69s/it, loss=0.124]train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 166/230 [8:15:11<3:11:40, 179.69s/it, loss=0.128]train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 167/230 [8:17:49<3:02:07, 173.44s/it, loss=0.128]train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 167/230 [8:17:49<3:02:07, 173.44s/it, loss=0.115]train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 168/230 [8:20:28<2:54:41, 169.06s/it, loss=0.115]train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 168/230 [8:20:28<2:54:41, 169.06s/it, loss=0.133]2025-05-24T12:12:40 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 167.
2025-05-24T12:12:40 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 167 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-167
2025-05-24T12:12:40 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-167 for step 167
2025-05-24T12:12:40 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T12:12:40 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T12:12:40 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T12:13:09 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
2025-05-24T12:13:18 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T12:13:18 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-167 for step 167
Removing checkpoint step-146
2025-05-24T12:13:18 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T12:13:18 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-146 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-146
2025-05-24T12:13:23 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-146 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-146 in 4.90 seconds
train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 169/230 [8:23:35<2:57:23, 174.49s/it, loss=0.133]train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 169/230 [8:23:35<2:57:23, 174.49s/it, loss=0.117]train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 170/230 [8:26:14<2:49:51, 169.86s/it, loss=0.117]train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 170/230 [8:26:14<2:49:51, 169.86s/it, loss=0.112]train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 171/230 [8:28:53<2:43:45, 166.54s/it, loss=0.112]train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 171/230 [8:28:53<2:43:45, 166.54s/it, loss=0.114]train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 172/230 [8:31:32<2:38:44, 164.21s/it, loss=0.114]train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 172/230 [8:31:32<2:38:44, 164.21s/it, loss=0.115]train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 173/230 [8:34:11<2:34:26, 162.56s/it, loss=0.115]train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 173/230 [8:34:11<2:34:26, 162.56s/it, loss=0.131]train:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 174/230 [8:36:50<2:30:41, 161.45s/it, loss=0.131]train:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 174/230 [8:36:50<2:30:41, 161.45s/it, loss=0.0994]train:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 175/230 [8:39:28<2:27:15, 160.65s/it, loss=0.0994]train:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 175/230 [8:39:28<2:27:15, 160.65s/it, loss=0.119] train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 176/230 [8:42:07<2:24:01, 160.02s/it, loss=0.119]train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 176/230 [8:42:07<2:24:01, 160.02s/it, loss=0.119]train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 177/230 [8:44:46<2:21:00, 159.62s/it, loss=0.119]train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 177/230 [8:44:46<2:21:00, 159.62s/it, loss=0.11] train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 178/230 [8:47:24<2:18:05, 159.33s/it, loss=0.11]train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 178/230 [8:47:24<2:18:05, 159.33s/it, loss=0.137]train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 179/230 [8:50:03<2:15:18, 159.19s/it, loss=0.137]train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 179/230 [8:50:03<2:15:18, 159.19s/it, loss=0.106]train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 180/230 [8:52:42<2:12:33, 159.07s/it, loss=0.106]train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 180/230 [8:52:42<2:12:33, 159.07s/it, loss=0.106]train:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 181/230 [8:55:21<2:09:51, 159.01s/it, loss=0.106]train:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 181/230 [8:55:21<2:09:51, 159.01s/it, loss=0.114]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.30s/it][A
eval: 3it [00:06,  2.29s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.27s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.26s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:24,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:34,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:43,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:53,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.26s/it][A
eval: 61it [02:17,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:24,  2.26s/it][A
eval: 65it [02:26,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:31,  2.26s/it][A
eval: 68it [02:33,  2.26s/it][A
eval: 69it [02:35,  2.26s/it][A
eval: 70it [02:38,  2.26s/it][A
eval: 71it [02:40,  2.26s/it][A
eval: 72it [02:42,  2.26s/it][A
eval: 73it [02:44,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:49,  2.26s/it][A
eval: 76it [02:51,  2.26s/it][A
eval: 77it [02:53,  2.26s/it][A
eval: 78it [02:56,  2.26s/it][A
eval: 79it [02:58,  2.26s/it][A
eval: 80it [03:00,  2.26s/it][A
eval: 81it [03:02,  2.26s/it][A
eval: 82it [03:05,  2.26s/it][A
eval: 83it [03:07,  2.26s/it][A
eval: 84it [03:09,  2.26s/it][A
eval: 85it [03:12,  2.26s/it][A
eval: 86it [03:14,  2.26s/it][A
eval: 87it [03:16,  2.26s/it][A
eval: 88it [03:18,  2.26s/it][A
eval: 89it [03:21,  2.25s/it][A
eval: 90it [03:23,  2.25s/it][A
eval: 91it [03:25,  2.25s/it][A
eval: 92it [03:27,  2.25s/it][A
eval: 93it [03:30,  2.25s/it][A
eval: 94it [03:32,  2.25s/it][A
eval: 95it [03:34,  2.26s/it][A
eval: 96it [03:36,  2.26s/it][A
eval: 97it [03:39,  2.26s/it][A
eval: 98it [03:41,  2.26s/it][A
eval: 99it [03:43,  2.26s/it][A
eval: 100it [03:45,  2.26s/it][A
eval: 101it [03:48,  2.26s/it][A
eval: 102it [03:50,  2.26s/it][A
eval: 103it [03:52,  2.26s/it][A
eval: 104it [03:54,  2.26s/it][A
eval: 105it [03:57,  2.26s/it][A
eval: 106it [03:59,  2.26s/it][A
eval: 107it [04:01,  2.26s/it][A
eval: 108it [04:03,  2.26s/it][A
eval: 109it [04:06,  2.26s/it][A
eval: 110it [04:08,  2.26s/it][A
eval: 111it [04:10,  2.26s/it][A
eval: 112it [04:12,  2.26s/it][A
eval: 113it [04:15,  2.26s/it][A
eval: 114it [04:17,  2.26s/it][A
eval: 115it [04:19,  2.26s/it][A
eval: 116it [04:21,  2.26s/it][A
eval: 117it [04:24,  2.26s/it][A
eval: 118it [04:26,  2.26s/it][A
eval: 119it [04:28,  2.26s/it][A
eval: 120it [04:30,  2.26s/it][A
eval: 121it [04:33,  2.26s/it][A
eval: 122it [04:35,  2.26s/it][A
eval: 123it [04:37,  2.26s/it][A
eval: 124it [04:39,  2.26s/it][A
eval: 125it [04:42,  2.26s/it][A
eval: 126it [04:44,  2.26s/it][A
eval: 127it [04:46,  2.26s/it][A
eval: 128it [04:49,  2.26s/it][Aeval: 128it [04:49,  2.26s/it]
2025-05-24T12:52:22 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.160
2025-05-24T12:52:22 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.160
train:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 182/230 [9:02:49<3:16:33, 245.71s/it, loss=0.114]train:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 182/230 [9:02:49<3:16:33, 245.71s/it, loss=0.114]train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 183/230 [9:05:28<2:52:04, 219.66s/it, loss=0.114]train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 183/230 [9:05:28<2:52:04, 219.66s/it, loss=0.116]train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 184/230 [9:08:06<2:34:24, 201.40s/it, loss=0.116]train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 184/230 [9:08:06<2:34:24, 201.40s/it, loss=0.117]train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 185/230 [9:10:45<2:21:27, 188.61s/it, loss=0.117]train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 185/230 [9:10:45<2:21:27, 188.61s/it, loss=0.107]train:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 186/230 [9:13:24<2:11:45, 179.67s/it, loss=0.107]train:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 186/230 [9:13:24<2:11:45, 179.67s/it, loss=0.118]train:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 187/230 [9:16:03<2:04:16, 173.41s/it, loss=0.118]train:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 187/230 [9:16:03<2:04:16, 173.41s/it, loss=0.113]train:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 188/230 [9:18:42<1:58:19, 169.03s/it, loss=0.113]train:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 188/230 [9:18:42<1:58:19, 169.03s/it, loss=0.111]train:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 189/230 [9:21:20<1:53:24, 165.97s/it, loss=0.111]train:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 189/230 [9:21:20<1:53:24, 165.97s/it, loss=0.112]2025-05-24T13:13:33 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 188.
2025-05-24T13:13:33 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 188 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-188
2025-05-24T13:13:33 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-188 for step 188
2025-05-24T13:13:33 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T13:13:33 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T13:13:33 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T13:14:02 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
2025-05-24T13:14:12 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T13:14:12 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-188 for step 188
Removing checkpoint step-167
2025-05-24T13:14:12 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T13:14:12 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-167 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-167
2025-05-24T13:14:17 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-167 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-167 in 4.87 seconds
train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 190/230 [9:24:28<1:55:00, 172.50s/it, loss=0.112]train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 190/230 [9:24:28<1:55:00, 172.50s/it, loss=0.122]train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 191/230 [9:27:07<1:49:27, 168.41s/it, loss=0.122]train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 191/230 [9:27:07<1:49:27, 168.41s/it, loss=0.118]train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 192/230 [9:29:46<1:44:50, 165.54s/it, loss=0.118]train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 192/230 [9:29:46<1:44:50, 165.54s/it, loss=0.104]train:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 193/230 [9:32:25<1:40:49, 163.50s/it, loss=0.104]train:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 193/230 [9:32:25<1:40:49, 163.50s/it, loss=0.113]train:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 194/230 [9:35:04<1:37:15, 162.11s/it, loss=0.113]train:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 194/230 [9:35:04<1:37:15, 162.11s/it, loss=0.141]train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 195/230 [9:37:42<1:33:58, 161.10s/it, loss=0.141]train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 195/230 [9:37:42<1:33:58, 161.10s/it, loss=0.121]train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 196/230 [9:40:21<1:30:53, 160.39s/it, loss=0.121]train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 196/230 [9:40:21<1:30:53, 160.39s/it, loss=0.107]train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 197/230 [9:43:00<1:27:56, 159.88s/it, loss=0.107]train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 197/230 [9:43:00<1:27:56, 159.88s/it, loss=0.115]train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 198/230 [9:45:38<1:25:04, 159.52s/it, loss=0.115]train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 198/230 [9:45:38<1:25:04, 159.52s/it, loss=0.111]train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 199/230 [9:48:17<1:22:17, 159.28s/it, loss=0.111]train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 199/230 [9:48:17<1:22:17, 159.28s/it, loss=0.129]train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 200/230 [9:50:56<1:19:34, 159.14s/it, loss=0.129]train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 200/230 [9:50:56<1:19:34, 159.14s/it, loss=0.12] train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 201/230 [9:53:35<1:16:51, 159.03s/it, loss=0.12]train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 201/230 [9:53:35<1:16:51, 159.03s/it, loss=0.118]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.30s/it][A
eval: 3it [00:06,  2.29s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.27s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.26s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:24,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:34,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:34,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:43,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:52,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.26s/it][A
eval: 61it [02:17,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:24,  2.26s/it][A
eval: 65it [02:26,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:31,  2.26s/it][A
eval: 68it [02:33,  2.26s/it][A
eval: 69it [02:35,  2.26s/it][A
eval: 70it [02:38,  2.26s/it][A
eval: 71it [02:40,  2.26s/it][A
eval: 72it [02:42,  2.26s/it][A
eval: 73it [02:44,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:49,  2.26s/it][A
eval: 76it [02:51,  2.26s/it][A
eval: 77it [02:53,  2.26s/it][A
eval: 78it [02:56,  2.26s/it][A
eval: 79it [02:58,  2.26s/it][A
eval: 80it [03:00,  2.26s/it][A
eval: 81it [03:02,  2.26s/it][A
eval: 82it [03:05,  2.26s/it][A
eval: 83it [03:07,  2.26s/it][A
eval: 84it [03:09,  2.26s/it][A
eval: 85it [03:11,  2.26s/it][A
eval: 86it [03:14,  2.26s/it][A
eval: 87it [03:16,  2.26s/it][A
eval: 88it [03:18,  2.26s/it][A
eval: 89it [03:21,  2.26s/it][A
eval: 90it [03:23,  2.26s/it][A
eval: 91it [03:25,  2.26s/it][A
eval: 92it [03:27,  2.26s/it][A
eval: 93it [03:30,  2.26s/it][A
eval: 94it [03:32,  2.26s/it][A
eval: 95it [03:34,  2.26s/it][A
eval: 96it [03:36,  2.25s/it][A
eval: 97it [03:39,  2.26s/it][A
eval: 98it [03:41,  2.26s/it][A
eval: 99it [03:43,  2.26s/it][A
eval: 100it [03:45,  2.26s/it][A
eval: 101it [03:48,  2.25s/it][A
eval: 102it [03:50,  2.25s/it][A
eval: 103it [03:52,  2.26s/it][A
eval: 104it [03:54,  2.25s/it][A
eval: 105it [03:57,  2.26s/it][A
eval: 106it [03:59,  2.26s/it][A
eval: 107it [04:01,  2.26s/it][A
eval: 108it [04:03,  2.25s/it][A
eval: 109it [04:06,  2.25s/it][A
eval: 110it [04:08,  2.25s/it][A
eval: 111it [04:10,  2.25s/it][A
eval: 112it [04:12,  2.25s/it][A
eval: 113it [04:15,  2.25s/it][A
eval: 114it [04:17,  2.26s/it][A
eval: 115it [04:19,  2.26s/it][A
eval: 116it [04:21,  2.26s/it][A
eval: 117it [04:24,  2.26s/it][A
eval: 118it [04:26,  2.26s/it][A
eval: 119it [04:28,  2.26s/it][A
eval: 120it [04:30,  2.26s/it][A
eval: 121it [04:33,  2.26s/it][A
eval: 122it [04:35,  2.26s/it][A
eval: 123it [04:37,  2.26s/it][A
eval: 124it [04:39,  2.26s/it][A
eval: 125it [04:42,  2.26s/it][A
eval: 126it [04:44,  2.26s/it][A
eval: 127it [04:46,  2.26s/it][A
eval: 128it [04:48,  2.26s/it][Aeval: 128it [04:48,  2.26s/it]
2025-05-24T13:50:36 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.159
2025-05-24T13:50:36 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.159
train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 202/230 [10:01:02<1:54:38, 245.67s/it, loss=0.118]train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 202/230 [10:01:02<1:54:38, 245.67s/it, loss=0.114]train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 203/230 [10:03:41<1:38:48, 219.58s/it, loss=0.114]train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 203/230 [10:03:41<1:38:48, 219.58s/it, loss=0.138]train:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 204/230 [10:06:20<1:27:14, 201.33s/it, loss=0.138]train:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 204/230 [10:06:20<1:27:14, 201.33s/it, loss=0.114]train:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 205/230 [10:08:59<1:18:34, 188.58s/it, loss=0.114]train:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 205/230 [10:08:59<1:18:34, 188.58s/it, loss=0.121]train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 206/230 [10:11:38<1:11:51, 179.65s/it, loss=0.121]train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 206/230 [10:11:38<1:11:51, 179.65s/it, loss=0.117]train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 207/230 [10:14:16<1:06:28, 173.41s/it, loss=0.117]train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 207/230 [10:14:16<1:06:28, 173.41s/it, loss=0.127]train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 208/230 [10:16:55<1:01:58, 169.04s/it, loss=0.127]train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 208/230 [10:16:55<1:01:58, 169.04s/it, loss=0.123]train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 209/230 [10:19:34<58:05, 165.98s/it, loss=0.123]  train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 209/230 [10:19:34<58:05, 165.98s/it, loss=0.115]train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 210/230 [10:22:13<54:35, 163.77s/it, loss=0.115]train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 210/230 [10:22:13<54:35, 163.77s/it, loss=0.125]2025-05-24T14:14:25 - 0 - levanter.checkpoint - checkpoint.py:194 - INFO :: Saving temporary checkpoint at step 209.
2025-05-24T14:14:25 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 209 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-209
2025-05-24T14:14:25 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-209 for step 209
2025-05-24T14:14:25 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T14:14:25 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T14:14:25 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T14:14:53 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
2025-05-24T14:15:01 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T14:15:01 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-209 for step 209
Removing checkpoint step-188
2025-05-24T14:15:01 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T14:15:01 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-188 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-188
2025-05-24T14:15:06 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-188 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-188 in 4.85 seconds
train:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 211/230 [10:25:19<54:01, 170.59s/it, loss=0.125]train:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 211/230 [10:25:19<54:01, 170.59s/it, loss=0.101]train:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 212/230 [10:27:58<50:08, 167.13s/it, loss=0.101]train:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 212/230 [10:27:58<50:08, 167.13s/it, loss=0.121]train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 213/230 [10:30:37<46:39, 164.67s/it, loss=0.121]train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 213/230 [10:30:37<46:39, 164.67s/it, loss=0.111]train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 214/230 [10:33:16<43:26, 162.91s/it, loss=0.111]train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 214/230 [10:33:16<43:26, 162.91s/it, loss=0.121]train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 215/230 [10:35:55<40:25, 161.69s/it, loss=0.121]train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 215/230 [10:35:55<40:25, 161.69s/it, loss=0.121]train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 216/230 [10:38:34<37:31, 160.85s/it, loss=0.121]train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 216/230 [10:38:34<37:31, 160.85s/it, loss=0.121]train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 217/230 [10:41:13<34:43, 160.25s/it, loss=0.121]train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 217/230 [10:41:13<34:43, 160.25s/it, loss=0.112]train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 218/230 [10:43:52<31:58, 159.85s/it, loss=0.112]train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 218/230 [10:43:52<31:58, 159.85s/it, loss=0.137]train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 219/230 [10:46:30<29:15, 159.55s/it, loss=0.137]train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 219/230 [10:46:30<29:15, 159.55s/it, loss=0.127]train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 220/230 [10:49:09<26:33, 159.35s/it, loss=0.127]train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 220/230 [10:49:09<26:33, 159.35s/it, loss=0.127]train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 221/230 [10:51:48<23:52, 159.19s/it, loss=0.127]train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 221/230 [10:51:48<23:52, 159.19s/it, loss=0.108]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:02,  2.33s/it][A
eval: 2it [00:04,  2.30s/it][A
eval: 3it [00:06,  2.29s/it][A
eval: 4it [00:09,  2.29s/it][A
eval: 5it [00:11,  2.28s/it][A
eval: 6it [00:13,  2.27s/it][A
eval: 7it [00:15,  2.27s/it][A
eval: 8it [00:18,  2.26s/it][A
eval: 9it [00:20,  2.26s/it][A
eval: 10it [00:22,  2.26s/it][A
eval: 11it [00:24,  2.26s/it][A
eval: 12it [00:27,  2.26s/it][A
eval: 13it [00:29,  2.26s/it][A
eval: 14it [00:31,  2.26s/it][A
eval: 15it [00:33,  2.26s/it][A
eval: 16it [00:36,  2.26s/it][A
eval: 17it [00:38,  2.26s/it][A
eval: 18it [00:40,  2.26s/it][A
eval: 19it [00:43,  2.26s/it][A
eval: 20it [00:45,  2.26s/it][A
eval: 21it [00:47,  2.26s/it][A
eval: 22it [00:49,  2.26s/it][A
eval: 23it [00:52,  2.26s/it][A
eval: 24it [00:54,  2.26s/it][A
eval: 25it [00:56,  2.26s/it][A
eval: 26it [00:58,  2.26s/it][A
eval: 27it [01:01,  2.26s/it][A
eval: 28it [01:03,  2.26s/it][A
eval: 29it [01:05,  2.26s/it][A
eval: 30it [01:07,  2.26s/it][A
eval: 31it [01:10,  2.26s/it][A
eval: 32it [01:12,  2.26s/it][A
eval: 33it [01:14,  2.26s/it][A
eval: 34it [01:16,  2.26s/it][A
eval: 35it [01:19,  2.26s/it][A
eval: 36it [01:21,  2.26s/it][A
eval: 37it [01:23,  2.26s/it][A
eval: 38it [01:25,  2.26s/it][A
eval: 39it [01:28,  2.26s/it][A
eval: 40it [01:30,  2.26s/it][A
eval: 41it [01:32,  2.26s/it][A
eval: 42it [01:34,  2.26s/it][A
eval: 43it [01:37,  2.26s/it][A
eval: 44it [01:39,  2.26s/it][A
eval: 45it [01:41,  2.26s/it][A
eval: 46it [01:43,  2.26s/it][A
eval: 47it [01:46,  2.26s/it][A
eval: 48it [01:48,  2.26s/it][A
eval: 49it [01:50,  2.26s/it][A
eval: 50it [01:53,  2.26s/it][A
eval: 51it [01:55,  2.26s/it][A
eval: 52it [01:57,  2.26s/it][A
eval: 53it [01:59,  2.26s/it][A
eval: 54it [02:02,  2.26s/it][A
eval: 55it [02:04,  2.26s/it][A
eval: 56it [02:06,  2.26s/it][A
eval: 57it [02:08,  2.26s/it][A
eval: 58it [02:11,  2.26s/it][A
eval: 59it [02:13,  2.26s/it][A
eval: 60it [02:15,  2.26s/it][A
eval: 61it [02:17,  2.26s/it][A
eval: 62it [02:20,  2.26s/it][A
eval: 63it [02:22,  2.26s/it][A
eval: 64it [02:24,  2.26s/it][A
eval: 65it [02:26,  2.26s/it][A
eval: 66it [02:29,  2.26s/it][A
eval: 67it [02:31,  2.26s/it][A
eval: 68it [02:33,  2.26s/it][A
eval: 69it [02:35,  2.26s/it][A
eval: 70it [02:38,  2.26s/it][A
eval: 71it [02:40,  2.26s/it][A
eval: 72it [02:42,  2.26s/it][A
eval: 73it [02:44,  2.26s/it][A
eval: 74it [02:47,  2.26s/it][A
eval: 75it [02:49,  2.26s/it][A
eval: 76it [02:51,  2.26s/it][A
eval: 77it [02:53,  2.26s/it][A
eval: 78it [02:56,  2.26s/it][A
eval: 79it [02:58,  2.26s/it][A
eval: 80it [03:00,  2.26s/it][A
eval: 81it [03:02,  2.26s/it][A
eval: 82it [03:05,  2.26s/it][A
eval: 83it [03:07,  2.26s/it][A
eval: 84it [03:09,  2.26s/it][A
eval: 85it [03:12,  2.26s/it][A
eval: 86it [03:14,  2.26s/it][A
eval: 87it [03:16,  2.26s/it][A
eval: 88it [03:18,  2.26s/it][A
eval: 89it [03:21,  2.26s/it][A
eval: 90it [03:23,  2.26s/it][A
eval: 91it [03:25,  2.26s/it][A
eval: 92it [03:27,  2.26s/it][A
eval: 93it [03:30,  2.26s/it][A
eval: 94it [03:32,  2.26s/it][A
eval: 95it [03:34,  2.26s/it][A
eval: 96it [03:36,  2.26s/it][A
eval: 97it [03:39,  2.26s/it][A
eval: 98it [03:41,  2.26s/it][A
eval: 99it [03:43,  2.26s/it][A
eval: 100it [03:45,  2.26s/it][A
eval: 101it [03:48,  2.26s/it][A
eval: 102it [03:50,  2.26s/it][A
eval: 103it [03:52,  2.26s/it][A
eval: 104it [03:54,  2.26s/it][A
eval: 105it [03:57,  2.26s/it][A
eval: 106it [03:59,  2.26s/it][A
eval: 107it [04:01,  2.26s/it][A
eval: 108it [04:03,  2.26s/it][A
eval: 109it [04:06,  2.26s/it][A
eval: 110it [04:08,  2.26s/it][A
eval: 111it [04:10,  2.26s/it][A
eval: 112it [04:12,  2.25s/it][A
eval: 113it [04:15,  2.25s/it][A
eval: 114it [04:17,  2.25s/it][A
eval: 115it [04:19,  2.25s/it][A
eval: 116it [04:21,  2.25s/it][A
eval: 117it [04:24,  2.25s/it][A
eval: 118it [04:26,  2.25s/it][A
eval: 119it [04:28,  2.25s/it][A
eval: 120it [04:30,  2.26s/it][A
eval: 121it [04:33,  2.26s/it][A
eval: 122it [04:35,  2.25s/it][A
eval: 123it [04:37,  2.25s/it][A
eval: 124it [04:39,  2.26s/it][A
eval: 125it [04:42,  2.26s/it][A
eval: 126it [04:44,  2.26s/it][A
eval: 127it [04:46,  2.26s/it][A
eval: 128it [04:49,  2.26s/it][Aeval: 128it [04:49,  2.26s/it]
2025-05-24T14:48:49 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.158
2025-05-24T14:48:49 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.158
train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 222/230 [10:59:16<32:46, 245.78s/it, loss=0.108]train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 222/230 [10:59:16<32:46, 245.78s/it, loss=0.122]train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 223/230 [11:01:55<25:37, 219.69s/it, loss=0.122]train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 223/230 [11:01:55<25:37, 219.69s/it, loss=0.12] train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 224/230 [11:04:33<20:08, 201.40s/it, loss=0.12]train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 224/230 [11:04:33<20:08, 201.40s/it, loss=0.0985]train:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 225/230 [11:07:12<15:43, 188.61s/it, loss=0.0985]train:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 225/230 [11:07:12<15:43, 188.61s/it, loss=0.105] train:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 226/230 [11:09:51<11:58, 179.62s/it, loss=0.105]train:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 226/230 [11:09:51<11:58, 179.62s/it, loss=0.119]train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 227/230 [11:12:30<08:40, 173.37s/it, loss=0.119]train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 227/230 [11:12:30<08:40, 173.37s/it, loss=0.127]train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 228/230 [11:15:08<05:37, 168.93s/it, loss=0.127]train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 228/230 [11:15:08<05:37, 168.93s/it, loss=0.122]train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 229/230 [11:17:47<02:45, 165.90s/it, loss=0.122]train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 229/230 [11:17:47<02:45, 165.90s/it, loss=0.127]train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [11:20:29<00:00, 164.75s/it, loss=0.127]train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [11:20:29<00:00, 164.75s/it, loss=0.104]2025-05-24T15:12:41 - 0 - levanter.checkpoint - checkpoint.py:192 - INFO :: Saving checkpoint at step 229.
2025-05-24T15:12:41 - 0 - levanter.checkpoint - checkpoint.py:245 - INFO :: Saving checkpoint at step 229 to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-229
2025-05-24T15:12:41 - 0 - levanter.checkpoint - checkpoint.py:285 - INFO :: Saving checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-229 for step 229
2025-05-24T15:12:41 - 0 - jax.experimental.array_serialization.serialization - serialization.py:595 - INFO :: Waiting for previous serialization to finish.
2025-05-24T15:12:41 - 0 - jax.experimental.array_serialization.serialization - serialization.py:551 - INFO :: Thread joined successfully
2025-05-24T15:12:41 - 0 - jax.experimental.array_serialization.serialization - serialization.py:554 - INFO :: Error check finished successfully
2025-05-24T15:13:10 - 0 - jax.experimental.array_serialization.serialization - serialization.py:496 - INFO :: Starting commit to storage layer by process: 0
train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [11:20:58<00:00, 164.75s/it, loss=0.104]
eval: 0it [00:00, ?it/s][A
eval: 1it [00:03,  3.93s/it][A
eval: 2it [00:06,  2.95s/it][A2025-05-24T15:13:18 - 0 - jax.experimental.array_serialization.serialization - serialization.py:501 - INFO :: Finished committing to storage layer by process: 0
2025-05-24T15:13:18 - 0 - levanter.checkpoint - checkpoint.py:293 - INFO :: Saved checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-229 for step 229
Removing checkpoint step-209
2025-05-24T15:13:18 - 0 - jax.experimental.array_serialization.serialization - serialization.py:516 - INFO :: on_commit_callback successfully ran!
2025-05-24T15:13:18 - 0 - levanter.checkpoint - checkpoint.py:235 - INFO :: Deleting old checkpoint step-209 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-209

eval: 3it [00:08,  2.64s/it][A
eval: 4it [00:10,  2.49s/it][A2025-05-24T15:13:23 - 0 - levanter.checkpoint - checkpoint.py:239 - INFO :: Deleted old checkpoint step-209 from /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT_ckpt/tsw6rwex/step-209 in 4.83 seconds

eval: 5it [00:12,  2.41s/it][A
eval: 6it [00:15,  2.36s/it][A
eval: 7it [00:17,  2.33s/it][A
eval: 8it [00:19,  2.31s/it][A
eval: 9it [00:22,  2.30s/it][A
eval: 10it [00:24,  2.29s/it][A
eval: 11it [00:26,  2.29s/it][A
eval: 12it [00:28,  2.29s/it][A
eval: 13it [00:31,  2.28s/it][A
eval: 14it [00:33,  2.28s/it][A
eval: 15it [00:35,  2.28s/it][A
eval: 16it [00:38,  2.28s/it][A
eval: 17it [00:40,  2.28s/it][A
eval: 18it [00:42,  2.27s/it][A
eval: 19it [00:44,  2.27s/it][A
eval: 20it [00:47,  2.27s/it][A
eval: 21it [00:49,  2.26s/it][A
eval: 22it [00:51,  2.26s/it][A
eval: 23it [00:53,  2.26s/it][A
eval: 24it [00:56,  2.26s/it][A
eval: 25it [00:58,  2.26s/it][A
eval: 26it [01:00,  2.26s/it][A
eval: 27it [01:02,  2.26s/it][A
eval: 28it [01:05,  2.26s/it][A
eval: 29it [01:07,  2.26s/it][A
eval: 30it [01:09,  2.26s/it][A
eval: 31it [01:11,  2.26s/it][A
eval: 32it [01:14,  2.26s/it][A
eval: 33it [01:16,  2.26s/it][A
eval: 34it [01:18,  2.26s/it][A
eval: 35it [01:20,  2.26s/it][A
eval: 36it [01:23,  2.26s/it][A
eval: 37it [01:25,  2.26s/it][A
eval: 38it [01:27,  2.25s/it][A
eval: 39it [01:29,  2.26s/it][A
eval: 40it [01:32,  2.25s/it][A
eval: 41it [01:34,  2.26s/it][A
eval: 42it [01:36,  2.26s/it][A
eval: 43it [01:38,  2.26s/it][A
eval: 44it [01:41,  2.26s/it][A
eval: 45it [01:43,  2.26s/it][A
eval: 46it [01:45,  2.26s/it][A
eval: 47it [01:47,  2.26s/it][A
eval: 48it [01:50,  2.26s/it][A
eval: 49it [01:52,  2.26s/it][A
eval: 50it [01:54,  2.26s/it][A
eval: 51it [01:57,  2.26s/it][A
eval: 52it [01:59,  2.26s/it][A
eval: 53it [02:01,  2.26s/it][A
eval: 54it [02:03,  2.26s/it][A
eval: 55it [02:06,  2.26s/it][A
eval: 56it [02:08,  2.26s/it][A
eval: 57it [02:10,  2.26s/it][A
eval: 58it [02:12,  2.26s/it][A
eval: 59it [02:15,  2.26s/it][A
eval: 60it [02:17,  2.26s/it][A
eval: 61it [02:19,  2.26s/it][A
eval: 62it [02:21,  2.26s/it][A
eval: 63it [02:24,  2.26s/it][A
eval: 64it [02:26,  2.26s/it][A
eval: 65it [02:28,  2.26s/it][A
eval: 66it [02:30,  2.26s/it][A
eval: 67it [02:33,  2.26s/it][A
eval: 68it [02:35,  2.26s/it][A
eval: 69it [02:37,  2.26s/it][A
eval: 70it [02:39,  2.25s/it][A
eval: 71it [02:42,  2.26s/it][A
eval: 72it [02:44,  2.25s/it][A
eval: 73it [02:46,  2.26s/it][A
eval: 74it [02:48,  2.26s/it][A
eval: 75it [02:51,  2.26s/it][A
eval: 76it [02:53,  2.25s/it][A
eval: 77it [02:55,  2.25s/it][A
eval: 78it [02:57,  2.25s/it][A
eval: 79it [03:00,  2.25s/it][A
eval: 80it [03:02,  2.25s/it][A
eval: 81it [03:04,  2.25s/it][A
eval: 82it [03:06,  2.25s/it][A
eval: 83it [03:09,  2.25s/it][A
eval: 84it [03:11,  2.25s/it][A
eval: 85it [03:13,  2.25s/it][A
eval: 86it [03:15,  2.25s/it][A
eval: 87it [03:18,  2.25s/it][A
eval: 88it [03:20,  2.25s/it][A
eval: 89it [03:22,  2.25s/it][A
eval: 90it [03:24,  2.25s/it][A
eval: 91it [03:27,  2.26s/it][A
eval: 92it [03:29,  2.26s/it][A
eval: 93it [03:31,  2.26s/it][A
eval: 94it [03:34,  2.26s/it][A
eval: 95it [03:36,  2.26s/it][A
eval: 96it [03:38,  2.26s/it][A
eval: 97it [03:40,  2.25s/it][A
eval: 98it [03:43,  2.26s/it][A
eval: 99it [03:45,  2.26s/it][A
eval: 100it [03:47,  2.26s/it][A
eval: 101it [03:49,  2.25s/it][A
eval: 102it [03:52,  2.26s/it][A
eval: 103it [03:54,  2.26s/it][A
eval: 104it [03:56,  2.26s/it][A
eval: 105it [03:58,  2.26s/it][A
eval: 106it [04:01,  2.26s/it][A
eval: 107it [04:03,  2.26s/it][A
eval: 108it [04:05,  2.26s/it][A
eval: 109it [04:07,  2.26s/it][A
eval: 110it [04:10,  2.26s/it][A
eval: 111it [04:12,  2.26s/it][A
eval: 112it [04:14,  2.25s/it][A
eval: 113it [04:16,  2.25s/it][A
eval: 114it [04:19,  2.25s/it][A
eval: 115it [04:21,  2.25s/it][A
eval: 116it [04:23,  2.25s/it][A
eval: 117it [04:25,  2.25s/it][A
eval: 118it [04:28,  2.25s/it][A
eval: 119it [04:30,  2.25s/it][A
eval: 120it [04:32,  2.25s/it][A
eval: 121it [04:34,  2.25s/it][A
eval: 122it [04:37,  2.25s/it][A
eval: 123it [04:39,  2.25s/it][A
eval: 124it [04:41,  2.25s/it][A
eval: 125it [04:43,  2.25s/it][A
eval: 126it [04:46,  2.25s/it][A
eval: 127it [04:48,  2.25s/it][A
eval: 128it [04:50,  2.25s/it][Aeval: 128it [04:50,  2.27s/it]
2025-05-24T15:18:01 - 0 - levanter.eval - eval.py:127 - INFO :: eval loss: 0.158
2025-05-24T15:18:01 - 0 - levanter.eval - eval.py:142 - INFO :: val loss: 0.158
2025-05-24T15:18:01 - 0 - levanter.compat.hf_checkpoints - hf_checkpoints.py:621 - INFO :: Saving HF-compatible checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT/tsw6rwex/step-229
2025-05-24T15:18:01 - 0 - levanter.compat.hf_checkpoints - hf_checkpoints.py:635 - INFO :: Saving tokenizer
2025-05-24T15:18:55 - 0 - levanter.compat.hf_checkpoints - hf_checkpoints.py:706 - INFO :: Saved a sharded checkpoint with 3 shards, max size 10000000000 bytes
2025-05-24T15:18:55 - 0 - levanter.compat.hf_checkpoints - hf_checkpoints.py:708 - INFO :: Finished saving HF-compatible checkpoint to /n/netscratch/amin_lab/Lab/slim/STP/storage/SFT/tsw6rwex/step-229
2025-05-24 15:18:58,728	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/raylet --store_socket_name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_id=e365d3cda685b5107aef0db7831a536d44c6a7a57c29a437691b5853 --node_ip_address=10.31.146.126 --maximum_startup_concurrency=64 --static_resource_list=node:10.31.146.126,1.0,node:__internal_head__,1.0,accelerator_type:A100,1,CPU,64,GPU,4,memory,853645253632,object_store_memory,200000000000 "--python_worker_command=/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/workers/setup_worker.py -s /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.31.146.126 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/plasma_store --raylet-name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/raylet --redis-address=None --metrics-agent-port=52804 --runtime-env-agent-port=60969 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=60969 --gcs-address=10.31.146.126:61949 --session-name=session_2025-05-24_03-52-05_277343_2221075 --temp-dir=/tmp/ray --webui=10.31.146.126:8265 --cluster-id=e2794795fb351f75bb3b1ab992dcbdfe35cd736a606f2867450dea3a RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.31.146.126:61949 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/plasma_store -Dray.raylet.socket-name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.31.146.126 -Dray.home=/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/../.. -Dray.logging.dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs -Dray.session-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/cpp/lib --temp_dir=/tmp/ray --session_dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075 --log_dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --resource_dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/runtime_resources --metrics-agent-port=52804 --metrics_export_port=60273 --runtime_env_agent_port=60969 --object_store_memory=200000000000 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.31.146.126:61949 --session-name=session_2025-05-24_03-52-05_277343_2221075 --labels= --cluster-id=e2794795fb351f75bb3b1ab992dcbdfe35cd736a606f2867450dea3a --head --num_prestart_python_workers=64 "--dashboard_agent_command=/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/dashboard/agent.py --node-ip-address=10.31.146.126 --metrics-export-port=60273 --dashboard-agent-port=52804 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/plasma_store --raylet-name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/raylet --temp-dir=/tmp/ray --session-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075 --log-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2025-05-24_03-52-05_277343_2221075 --gcs-address=10.31.146.126:61949" "--runtime_env_agent_command=/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/runtime_env/agent/main.py --node-ip-address=10.31.146.126 --runtime-env-agent-port=60969 --gcs-address=10.31.146.126:61949 --runtime-env-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/runtime_resources --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --log-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --temp-dir=/tmp/ray"[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,735	INFO scripts.py:1144 -- 1/1 stopped.2025-05-24 15:18:58,817	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/autoscaler/_private/monitor.py --logs-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.31.146.126:61949 --monitor-ip=10.31.146.126[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,817	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075 --logs-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --gcs-address=10.31.146.126:61949 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,818	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -m ray.util.client.server --address=10.31.146.126:61949 --host=0.0.0.0 --port=10001 --mode=proxy --runtime-env-agent-address=http://10.31.146.126:60969[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,821	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,822	VINFO scripts.py:1108 -- Killed `[1mray::IDLE "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,824	VINFO scripts.py:1122 -- Attempted to stop `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075 --logs-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --gcs-address=10.31.146.126:61949 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5[22m[26m`, but process was already dead.
2025-05-24 15:18:58,827	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/dashboard/agent.py --node-ip-address=10.31.146.126 --metrics-export-port=60273 --dashboard-agent-port=52804 --listen-port=52365 --node-manager-port=37055 --object-store-name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/plasma_store --raylet-name=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/sockets/raylet --temp-dir=/tmp/ray --session-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075 --log-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2025-05-24_03-52-05_277343_2221075 --gcs-address=10.31.146.126:61949 --agent-id 424238335[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,828	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/dashboard/dashboard.py --host=0.0.0.0 --port=8265 --port-retries=0 --temp-dir=/tmp/ray --log-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --session-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.31.146.126:61949 --node-ip-address=10.31.146.126[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,829	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/bin/python3.12 -u /n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/_private/runtime_env/agent/main.py --node-ip-address=10.31.146.126 --runtime-env-agent-port=60969 --gcs-address=10.31.146.126:61949 --runtime-env-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/runtime_resources --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --log-dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --temp-dir=/tmp/ray[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,831	INFO scripts.py:1144 -- 1/8 stopped.2025-05-24 15:18:58,838	INFO scripts.py:1144 -- 2/8 stopped.2025-05-24 15:18:58,838	INFO scripts.py:1144 -- 3/8 stopped.2025-05-24 15:18:58,838	INFO scripts.py:1144 -- 4/8 stopped.2025-05-24 15:18:58,838	INFO scripts.py:1144 -- 5/8 stopped.2025-05-24 15:18:58,838	INFO scripts.py:1144 -- 6/8 stopped.2025-05-24 15:18:58,889	INFO scripts.py:1144 -- 7/8 stopped.2025-05-24 15:18:58,889	INFO scripts.py:1144 -- 8/8 stopped.2025-05-24 15:18:58,966	VINFO scripts.py:1108 -- Killed `[1m/n/netscratch/amin_lab/Lab/slim/env/lib/python3.12/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/session_2025-05-24_03-52-05_277343_2221075/logs --config_list=eyJvYmplY3Rfc3BpbGxpbmdfY29uZmlnIjogIntcInR5cGVcIjogXCJmaWxlc3lzdGVtXCIsIFwicGFyYW1zXCI6IHtcImRpcmVjdG9yeV9wYXRoXCI6IFwiL3RtcC9yYXkvc2Vzc2lvbl8yMDI1LTA1LTI0XzAzLTUyLTA1XzI3NzM0M18yMjIxMDc1XCJ9fSIsICJpc19leHRlcm5hbF9zdG9yYWdlX3R5cGVfZnMiOiB0cnVlfQ== --gcs_server_port=61949 --metrics-agent-port=52804 --node-ip-address=10.31.146.126 --session-name=session_2025-05-24_03-52-05_277343_2221075 --ray-commit=fc87217e031b4e551cbb3d3ffc75f8c0fb57886a[22m[26m` [2m(via SIGKILL)[22m[26m 
2025-05-24 15:18:58,972	INFO scripts.py:1144 -- 1/1 stopped.2025-05-24 15:18:58,973	SUCC scripts.py:1189 -- [32mStopped all 10 Ray processes.[39m
wandb: - 0.032 MB of 0.372 MB uploaded (0.004 MB deduped)wandb: \ 0.372 MB of 0.372 MB uploaded (0.004 MB deduped)wandb: 
wandb: Run history:
wandb:              eval/loading_time â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–
wandb:                      eval/loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–
wandb:                eval/macro_loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–
wandb:                eval/total_time â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  eval/val/loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–
wandb:                    global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            optim/learning_rate â–â–‚â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            throughput/duration â–†â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆ
wandb: throughput/examples_per_second â–ƒâ–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–
wandb:   throughput/gflops_per_second â–ƒâ–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–
wandb:           throughput/hook_time â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        throughput/loading_time â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:   throughput/tokens_per_second â–ƒâ–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–
wandb:        throughput/total_gflops â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:        throughput/total_tokens â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                     train/loss â–ˆâ–„â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:                        backend gpu
wandb:              eval/loading_time 1.65283
wandb:                      eval/loss 0.1579
wandb:                eval/macro_loss 0.1579
wandb:                eval/total_time 290.70507
wandb:                  eval/val/loss 0.1579
wandb:                    global_step 229
wandb:                    num_devices 4
wandb:                      num_hosts 1
wandb:            optim/learning_rate 0.0001
wandb:            throughput/duration 160.95355
wandb: throughput/examples_per_second 6.36208
wandb:   throughput/gflops_per_second 920784.82293
wandb:           throughput/hook_time 0.0056
wandb:        throughput/loading_time 1.10495
wandb:   throughput/tokens_per_second 26059.09618
wandb:        throughput/total_gflops 33938620879.07633
wandb:        throughput/total_tokens 960495616
wandb:                     train/loss 0.1036
wandb: 
wandb: ðŸš€ View run deepseek-sft at: https://wandb.ai/slimbarkallah23-CentraleSup%C3%A9lec/STP_deepseek_03/runs/tsw6rwex
wandb: â­ï¸ View project at: https://wandb.ai/slimbarkallah23-CentraleSup%C3%A9lec/STP_deepseek_03
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250524_035158-tsw6rwex/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
